{"type":"file-history-snapshot","messageId":"a89c95da-4d38-4a9b-a8a1-8baeb5e10eb6","snapshot":{"messageId":"a89c95da-4d38-4a9b-a8a1-8baeb5e10eb6","trackedFileBackups":{},"timestamp":"2025-11-18T14:01:07.522Z"},"isSnapshotUpdate":false}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":"Build an Alert Notification Router system that intelligently routes alerts to appropriate teams based on configurable rules and escalation policies. The system should support multiple notification\nchannels (email, Slack, PagerDuty) and include alert deduplication, priority handling, and delivery tracking.\n\nPlease create the following documentation files:\n1. DevelopmentPlan.md - Outline the architecture, tech stack, database schema, API endpoints, and implementation phases\n2. TestingPlan.md - Define test strategy including unit tests, integration tests, end-to-end tests, and test coverage goals\n3. Guide.md - Create a user guide covering setup, configuration, usage examples, and troubleshooting"},"uuid":"a89c95da-4d38-4a9b-a8a1-8baeb5e10eb6","timestamp":"2025-11-18T14:01:05.870Z","thinkingMetadata":{"level":"none","disabled":true,"triggers":[]}}
{"parentUuid":"a89c95da-4d38-4a9b-a8a1-8baeb5e10eb6","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VYkZ539DDzjxN5vZ72cQNK","type":"message","role":"assistant","content":[{"type":"text","text":"I'll help you build an Alert Notification Router system with comprehensive documentation. Let me start by activating the relevant skills and then create the documentation files."}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":734,"cache_read_input_tokens":20791,"cache_creation":{"ephemeral_5m_input_tokens":734,"ephemeral_1h_input_tokens":0},"output_tokens":127,"service_tier":"standard"}},"requestId":"req_011CVFUc5j7CyuSw9yfwF7da","type":"assistant","uuid":"b3b56823-1c54-4358-88ce-b4c513731a4c","timestamp":"2025-11-18T14:01:11.769Z"}
{"parentUuid":"b3b56823-1c54-4358-88ce-b4c513731a4c","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VYkZ539DDzjxN5vZ72cQNK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019EXGt5tYKUq3q32vbvoasf","name":"Skill","input":{"skill":"backend-dev-guidelines"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":734,"cache_read_input_tokens":20791,"cache_creation":{"ephemeral_5m_input_tokens":734,"ephemeral_1h_input_tokens":0},"output_tokens":127,"service_tier":"standard"}},"requestId":"req_011CVFUc5j7CyuSw9yfwF7da","type":"assistant","uuid":"1f8c70d2-7ab6-42c4-b078-2d3432573e8e","timestamp":"2025-11-18T14:01:11.801Z"}
{"parentUuid":"1f8c70d2-7ab6-42c4-b078-2d3432573e8e","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VYkZ539DDzjxN5vZ72cQNK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JTExZsYCHE5xZfSBwyuKrA","name":"Skill","input":{"skill":"frontend-dev-guidelines"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":734,"cache_read_input_tokens":20791,"cache_creation":{"ephemeral_5m_input_tokens":734,"ephemeral_1h_input_tokens":0},"output_tokens":127,"service_tier":"standard"},"context_management":{"applied_edits":[]}},"requestId":"req_011CVFUc5j7CyuSw9yfwF7da","type":"assistant","uuid":"a44b0937-380d-4dce-b92f-daa5c6c6ed77","timestamp":"2025-11-18T14:01:11.839Z"}
{"parentUuid":"a44b0937-380d-4dce-b92f-daa5c6c6ed77","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"type":"tool_result","tool_use_id":"toolu_019EXGt5tYKUq3q32vbvoasf","content":"Launching skill: backend-dev-guidelines"}]},"uuid":"fe077471-1e34-4184-bf41-2f5e710ec706","timestamp":"2025-11-18T14:01:11.970Z","toolUseResult":{"success":true,"commandName":"backend-dev-guidelines"}}
{"parentUuid":"fe077471-1e34-4184-bf41-2f5e710ec706","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":"<command-message>The \"backend-dev-guidelines\" skill is running</command-message>\n<command-name>backend-dev-guidelines</command-name>"},"uuid":"934f99dc-d1cc-43a3-b7d8-b7a1ab408fe5","timestamp":"2025-11-18T14:01:11.968Z","sourceToolUseID":"toolu_019EXGt5tYKUq3q32vbvoasf"}
{"parentUuid":"934f99dc-d1cc-43a3-b7d8-b7a1ab408fe5","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"type":"text","text":"Base directory for this skill: /root/.claude/skills/backend-dev-guidelines\n\n# Backend Development Guidelines\n\n## Purpose\n\nEstablish consistency and best practices across backend microservices (blog-api, auth-service, notifications-service) using modern Node.js/Express/TypeScript patterns.\n\n## When to Use This Skill\n\nAutomatically activates when working on:\n- Creating or modifying routes, endpoints, APIs\n- Building controllers, services, repositories\n- Implementing middleware (auth, validation, error handling)\n- Database operations with Prisma\n- Error tracking with Sentry\n- Input validation with Zod\n- Configuration management\n- Backend testing and refactoring\n\n---\n\n## Quick Start\n\n### New Backend Feature Checklist\n\n- [ ] **Route**: Clean definition, delegate to controller\n- [ ] **Controller**: Extend BaseController\n- [ ] **Service**: Business logic with DI\n- [ ] **Repository**: Database access (if complex)\n- [ ] **Validation**: Zod schema\n- [ ] **Sentry**: Error tracking\n- [ ] **Tests**: Unit + integration tests\n- [ ] **Config**: Use unifiedConfig\n\n### New Microservice Checklist\n\n- [ ] Directory structure (see [architecture-overview.md](architecture-overview.md))\n- [ ] instrument.ts for Sentry\n- [ ] unifiedConfig setup\n- [ ] BaseController class\n- [ ] Middleware stack\n- [ ] Error boundary\n- [ ] Testing framework\n\n---\n\n## Architecture Overview\n\n### Layered Architecture\n\n```\nHTTP Request\n    â†“\nRoutes (routing only)\n    â†“\nControllers (request handling)\n    â†“\nServices (business logic)\n    â†“\nRepositories (data access)\n    â†“\nDatabase (Prisma)\n```\n\n**Key Principle:** Each layer has ONE responsibility.\n\nSee [architecture-overview.md](architecture-overview.md) for complete details.\n\n---\n\n## Directory Structure\n\n```\nservice/src/\nâ”œâ”€â”€ config/              # UnifiedConfig\nâ”œâ”€â”€ controllers/         # Request handlers\nâ”œâ”€â”€ services/            # Business logic\nâ”œâ”€â”€ repositories/        # Data access\nâ”œâ”€â”€ routes/              # Route definitions\nâ”œâ”€â”€ middleware/          # Express middleware\nâ”œâ”€â”€ types/               # TypeScript types\nâ”œâ”€â”€ validators/          # Zod schemas\nâ”œâ”€â”€ utils/               # Utilities\nâ”œâ”€â”€ tests/               # Tests\nâ”œâ”€â”€ instrument.ts        # Sentry (FIRST IMPORT)\nâ”œâ”€â”€ app.ts               # Express setup\nâ””â”€â”€ server.ts            # HTTP server\n```\n\n**Naming Conventions:**\n- Controllers: `PascalCase` - `UserController.ts`\n- Services: `camelCase` - `userService.ts`\n- Routes: `camelCase + Routes` - `userRoutes.ts`\n- Repositories: `PascalCase + Repository` - `UserRepository.ts`\n\n---\n\n## Core Principles (7 Key Rules)\n\n### 1. Routes Only Route, Controllers Control\n\n```typescript\n// âŒ NEVER: Business logic in routes\nrouter.post('/submit', async (req, res) => {\n    // 200 lines of logic\n});\n\n// âœ… ALWAYS: Delegate to controller\nrouter.post('/submit', (req, res) => controller.submit(req, res));\n```\n\n### 2. All Controllers Extend BaseController\n\n```typescript\nexport class UserController extends BaseController {\n    async getUser(req: Request, res: Response): Promise<void> {\n        try {\n            const user = await this.userService.findById(req.params.id);\n            this.handleSuccess(res, user);\n        } catch (error) {\n            this.handleError(error, res, 'getUser');\n        }\n    }\n}\n```\n\n### 3. All Errors to Sentry\n\n```typescript\ntry {\n    await operation();\n} catch (error) {\n    Sentry.captureException(error);\n    throw error;\n}\n```\n\n### 4. Use unifiedConfig, NEVER process.env\n\n```typescript\n// âŒ NEVER\nconst timeout = process.env.TIMEOUT_MS;\n\n// âœ… ALWAYS\nimport { config } from './config/unifiedConfig';\nconst timeout = config.timeouts.default;\n```\n\n### 5. Validate All Input with Zod\n\n```typescript\nconst schema = z.object({ email: z.string().email() });\nconst validated = schema.parse(req.body);\n```\n\n### 6. Use Repository Pattern for Data Access\n\n```typescript\n// Service â†’ Repository â†’ Database\nconst users = await userRepository.findActive();\n```\n\n### 7. Comprehensive Testing Required\n\n```typescript\ndescribe('UserService', () => {\n    it('should create user', async () => {\n        expect(user).toBeDefined();\n    });\n});\n```\n\n---\n\n## Common Imports\n\n```typescript\n// Express\nimport express, { Request, Response, NextFunction, Router } from 'express';\n\n// Validation\nimport { z } from 'zod';\n\n// Database\nimport { PrismaClient } from '@prisma/client';\nimport type { Prisma } from '@prisma/client';\n\n// Sentry\nimport * as Sentry from '@sentry/node';\n\n// Config\nimport { config } from './config/unifiedConfig';\n\n// Middleware\nimport { SSOMiddlewareClient } from './middleware/SSOMiddleware';\nimport { asyncErrorWrapper } from './middleware/errorBoundary';\n```\n\n---\n\n## Quick Reference\n\n### HTTP Status Codes\n\n| Code | Use Case |\n|------|----------|\n| 200 | Success |\n| 201 | Created |\n| 400 | Bad Request |\n| 401 | Unauthorized |\n| 403 | Forbidden |\n| 404 | Not Found |\n| 500 | Server Error |\n\n### Service Templates\n\n**Blog API** (âœ… Mature) - Use as template for REST APIs\n**Auth Service** (âœ… Mature) - Use as template for authentication patterns\n\n---\n\n## Anti-Patterns to Avoid\n\nâŒ Business logic in routes\nâŒ Direct process.env usage\nâŒ Missing error handling\nâŒ No input validation\nâŒ Direct Prisma everywhere\nâŒ console.log instead of Sentry\n\n---\n\n## Navigation Guide\n\n| Need to... | Read this |\n|------------|-----------|\n| Understand architecture | [architecture-overview.md](architecture-overview.md) |\n| Create routes/controllers | [routing-and-controllers.md](routing-and-controllers.md) |\n| Organize business logic | [services-and-repositories.md](services-and-repositories.md) |\n| Validate input | [validation-patterns.md](validation-patterns.md) |\n| Add error tracking | [sentry-and-monitoring.md](sentry-and-monitoring.md) |\n| Create middleware | [middleware-guide.md](middleware-guide.md) |\n| Database access | [database-patterns.md](database-patterns.md) |\n| Manage config | [configuration.md](configuration.md) |\n| Handle async/errors | [async-and-errors.md](async-and-errors.md) |\n| Write tests | [testing-guide.md](testing-guide.md) |\n| See examples | [complete-examples.md](complete-examples.md) |\n\n---\n\n## Resource Files\n\n### [architecture-overview.md](architecture-overview.md)\nLayered architecture, request lifecycle, separation of concerns\n\n### [routing-and-controllers.md](routing-and-controllers.md)\nRoute definitions, BaseController, error handling, examples\n\n### [services-and-repositories.md](services-and-repositories.md)\nService patterns, DI, repository pattern, caching\n\n### [validation-patterns.md](validation-patterns.md)\nZod schemas, validation, DTO pattern\n\n### [sentry-and-monitoring.md](sentry-and-monitoring.md)\nSentry init, error capture, performance monitoring\n\n### [middleware-guide.md](middleware-guide.md)\nAuth, audit, error boundaries, AsyncLocalStorage\n\n### [database-patterns.md](database-patterns.md)\nPrismaService, repositories, transactions, optimization\n\n### [configuration.md](configuration.md)\nUnifiedConfig, environment configs, secrets\n\n### [async-and-errors.md](async-and-errors.md)\nAsync patterns, custom errors, asyncErrorWrapper\n\n### [testing-guide.md](testing-guide.md)\nUnit/integration tests, mocking, coverage\n\n### [complete-examples.md](complete-examples.md)\nFull examples, refactoring guide\n\n---\n\n## Related Skills\n\n- **database-verification** - Verify column names and schema consistency\n- **error-tracking** - Sentry integration patterns\n- **skill-developer** - Meta-skill for creating and managing skills\n\n---\n\n**Skill Status**: COMPLETE âœ…\n**Line Count**: < 500 âœ…\n**Progressive Disclosure**: 11 resource files âœ…\n"}]},"isMeta":true,"uuid":"cf5f066c-0f38-4885-9486-18e169088be4","timestamp":"2025-11-18T14:01:11.968Z","sourceToolUseID":"toolu_019EXGt5tYKUq3q32vbvoasf"}
{"parentUuid":"cf5f066c-0f38-4885-9486-18e169088be4","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"type":"tool_result","tool_use_id":"toolu_01JTExZsYCHE5xZfSBwyuKrA","content":"Launching skill: frontend-dev-guidelines"}]},"uuid":"88775dd9-4f69-4b11-a563-4702e2b40622","timestamp":"2025-11-18T14:01:12.114Z","toolUseResult":{"success":true,"commandName":"frontend-dev-guidelines"}}
{"parentUuid":"88775dd9-4f69-4b11-a563-4702e2b40622","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":"<command-message>The \"frontend-dev-guidelines\" skill is running</command-message>\n<command-name>frontend-dev-guidelines</command-name>"},"uuid":"78a1fa14-669c-470d-8074-d87e5f4a4f7a","timestamp":"2025-11-18T14:01:12.112Z","sourceToolUseID":"toolu_01JTExZsYCHE5xZfSBwyuKrA"}
{"parentUuid":"78a1fa14-669c-470d-8074-d87e5f4a4f7a","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"type":"text","text":"Base directory for this skill: /root/.claude/skills/frontend-dev-guidelines\n\n# Frontend Development Guidelines\n\n## Purpose\n\nComprehensive guide for modern React development, emphasizing Suspense-based data fetching, lazy loading, proper file organization, and performance optimization.\n\n## When to Use This Skill\n\n- Creating new components or pages\n- Building new features\n- Fetching data with TanStack Query\n- Setting up routing with TanStack Router\n- Styling components with MUI v7\n- Performance optimization\n- Organizing frontend code\n- TypeScript best practices\n\n---\n\n## Quick Start\n\n### New Component Checklist\n\nCreating a component? Follow this checklist:\n\n- [ ] Use `React.FC<Props>` pattern with TypeScript\n- [ ] Lazy load if heavy component: `React.lazy(() => import())`\n- [ ] Wrap in `<SuspenseLoader>` for loading states\n- [ ] Use `useSuspenseQuery` for data fetching\n- [ ] Import aliases: `@/`, `~types`, `~components`, `~features`\n- [ ] Styles: Inline if <100 lines, separate file if >100 lines\n- [ ] Use `useCallback` for event handlers passed to children\n- [ ] Default export at bottom\n- [ ] No early returns with loading spinners\n- [ ] Use `useMuiSnackbar` for user notifications\n\n### New Feature Checklist\n\nCreating a feature? Set up this structure:\n\n- [ ] Create `features/{feature-name}/` directory\n- [ ] Create subdirectories: `api/`, `components/`, `hooks/`, `helpers/`, `types/`\n- [ ] Create API service file: `api/{feature}Api.ts`\n- [ ] Set up TypeScript types in `types/`\n- [ ] Create route in `routes/{feature-name}/index.tsx`\n- [ ] Lazy load feature components\n- [ ] Use Suspense boundaries\n- [ ] Export public API from feature `index.ts`\n\n---\n\n## Import Aliases Quick Reference\n\n| Alias | Resolves To | Example |\n|-------|-------------|---------|\n| `@/` | `src/` | `import { apiClient } from '@/lib/apiClient'` |\n| `~types` | `src/types` | `import type { User } from '~types/user'` |\n| `~components` | `src/components` | `import { SuspenseLoader } from '~components/SuspenseLoader'` |\n| `~features` | `src/features` | `import { authApi } from '~features/auth'` |\n\nDefined in: [vite.config.ts](../../vite.config.ts) lines 180-185\n\n---\n\n## Common Imports Cheatsheet\n\n```typescript\n// React & Lazy Loading\nimport React, { useState, useCallback, useMemo } from 'react';\nconst Heavy = React.lazy(() => import('./Heavy'));\n\n// MUI Components\nimport { Box, Paper, Typography, Button, Grid } from '@mui/material';\nimport type { SxProps, Theme } from '@mui/material';\n\n// TanStack Query (Suspense)\nimport { useSuspenseQuery, useQueryClient } from '@tanstack/react-query';\n\n// TanStack Router\nimport { createFileRoute } from '@tanstack/react-router';\n\n// Project Components\nimport { SuspenseLoader } from '~components/SuspenseLoader';\n\n// Hooks\nimport { useAuth } from '@/hooks/useAuth';\nimport { useMuiSnackbar } from '@/hooks/useMuiSnackbar';\n\n// Types\nimport type { Post } from '~types/post';\n```\n\n---\n\n## Topic Guides\n\n### ğŸ¨ Component Patterns\n\n**Modern React components use:**\n- `React.FC<Props>` for type safety\n- `React.lazy()` for code splitting\n- `SuspenseLoader` for loading states\n- Named const + default export pattern\n\n**Key Concepts:**\n- Lazy load heavy components (DataGrid, charts, editors)\n- Always wrap lazy components in Suspense\n- Use SuspenseLoader component (with fade animation)\n- Component structure: Props â†’ Hooks â†’ Handlers â†’ Render â†’ Export\n\n**[ğŸ“– Complete Guide: resources/component-patterns.md](resources/component-patterns.md)**\n\n---\n\n### ğŸ“Š Data Fetching\n\n**PRIMARY PATTERN: useSuspenseQuery**\n- Use with Suspense boundaries\n- Cache-first strategy (check grid cache before API)\n- Replaces `isLoading` checks\n- Type-safe with generics\n\n**API Service Layer:**\n- Create `features/{feature}/api/{feature}Api.ts`\n- Use `apiClient` axios instance\n- Centralized methods per feature\n- Route format: `/form/route` (NOT `/api/form/route`)\n\n**[ğŸ“– Complete Guide: resources/data-fetching.md](resources/data-fetching.md)**\n\n---\n\n### ğŸ“ File Organization\n\n**features/ vs components/:**\n- `features/`: Domain-specific (posts, comments, auth)\n- `components/`: Truly reusable (SuspenseLoader, CustomAppBar)\n\n**Feature Subdirectories:**\n```\nfeatures/\n  my-feature/\n    api/          # API service layer\n    components/   # Feature components\n    hooks/        # Custom hooks\n    helpers/      # Utility functions\n    types/        # TypeScript types\n```\n\n**[ğŸ“– Complete Guide: resources/file-organization.md](resources/file-organization.md)**\n\n---\n\n### ğŸ¨ Styling\n\n**Inline vs Separate:**\n- <100 lines: Inline `const styles: Record<string, SxProps<Theme>>`\n- >100 lines: Separate `.styles.ts` file\n\n**Primary Method:**\n- Use `sx` prop for MUI components\n- Type-safe with `SxProps<Theme>`\n- Theme access: `(theme) => theme.palette.primary.main`\n\n**MUI v7 Grid:**\n```typescript\n<Grid size={{ xs: 12, md: 6 }}>  // âœ… v7 syntax\n<Grid xs={12} md={6}>             // âŒ Old syntax\n```\n\n**[ğŸ“– Complete Guide: resources/styling-guide.md](resources/styling-guide.md)**\n\n---\n\n### ğŸ›£ï¸ Routing\n\n**TanStack Router - Folder-Based:**\n- Directory: `routes/my-route/index.tsx`\n- Lazy load components\n- Use `createFileRoute`\n- Breadcrumb data in loader\n\n**Example:**\n```typescript\nimport { createFileRoute } from '@tanstack/react-router';\nimport { lazy } from 'react';\n\nconst MyPage = lazy(() => import('@/features/my-feature/components/MyPage'));\n\nexport const Route = createFileRoute('/my-route/')({\n    component: MyPage,\n    loader: () => ({ crumb: 'My Route' }),\n});\n```\n\n**[ğŸ“– Complete Guide: resources/routing-guide.md](resources/routing-guide.md)**\n\n---\n\n### â³ Loading & Error States\n\n**CRITICAL RULE: No Early Returns**\n\n```typescript\n// âŒ NEVER - Causes layout shift\nif (isLoading) {\n    return <LoadingSpinner />;\n}\n\n// âœ… ALWAYS - Consistent layout\n<SuspenseLoader>\n    <Content />\n</SuspenseLoader>\n```\n\n**Why:** Prevents Cumulative Layout Shift (CLS), better UX\n\n**Error Handling:**\n- Use `useMuiSnackbar` for user feedback\n- NEVER `react-toastify`\n- TanStack Query `onError` callbacks\n\n**[ğŸ“– Complete Guide: resources/loading-and-error-states.md](resources/loading-and-error-states.md)**\n\n---\n\n### âš¡ Performance\n\n**Optimization Patterns:**\n- `useMemo`: Expensive computations (filter, sort, map)\n- `useCallback`: Event handlers passed to children\n- `React.memo`: Expensive components\n- Debounced search (300-500ms)\n- Memory leak prevention (cleanup in useEffect)\n\n**[ğŸ“– Complete Guide: resources/performance.md](resources/performance.md)**\n\n---\n\n### ğŸ“˜ TypeScript\n\n**Standards:**\n- Strict mode, no `any` type\n- Explicit return types on functions\n- Type imports: `import type { User } from '~types/user'`\n- Component prop interfaces with JSDoc\n\n**[ğŸ“– Complete Guide: resources/typescript-standards.md](resources/typescript-standards.md)**\n\n---\n\n### ğŸ”§ Common Patterns\n\n**Covered Topics:**\n- React Hook Form with Zod validation\n- DataGrid wrapper contracts\n- Dialog component standards\n- `useAuth` hook for current user\n- Mutation patterns with cache invalidation\n\n**[ğŸ“– Complete Guide: resources/common-patterns.md](resources/common-patterns.md)**\n\n---\n\n### ğŸ“š Complete Examples\n\n**Full working examples:**\n- Modern component with all patterns\n- Complete feature structure\n- API service layer\n- Route with lazy loading\n- Suspense + useSuspenseQuery\n- Form with validation\n\n**[ğŸ“– Complete Guide: resources/complete-examples.md](resources/complete-examples.md)**\n\n---\n\n## Navigation Guide\n\n| Need to... | Read this resource |\n|------------|-------------------|\n| Create a component | [component-patterns.md](resources/component-patterns.md) |\n| Fetch data | [data-fetching.md](resources/data-fetching.md) |\n| Organize files/folders | [file-organization.md](resources/file-organization.md) |\n| Style components | [styling-guide.md](resources/styling-guide.md) |\n| Set up routing | [routing-guide.md](resources/routing-guide.md) |\n| Handle loading/errors | [loading-and-error-states.md](resources/loading-and-error-states.md) |\n| Optimize performance | [performance.md](resources/performance.md) |\n| TypeScript types | [typescript-standards.md](resources/typescript-standards.md) |\n| Forms/Auth/DataGrid | [common-patterns.md](resources/common-patterns.md) |\n| See full examples | [complete-examples.md](resources/complete-examples.md) |\n\n---\n\n## Core Principles\n\n1. **Lazy Load Everything Heavy**: Routes, DataGrid, charts, editors\n2. **Suspense for Loading**: Use SuspenseLoader, not early returns\n3. **useSuspenseQuery**: Primary data fetching pattern for new code\n4. **Features are Organized**: api/, components/, hooks/, helpers/ subdirs\n5. **Styles Based on Size**: <100 inline, >100 separate\n6. **Import Aliases**: Use @/, ~types, ~components, ~features\n7. **No Early Returns**: Prevents layout shift\n8. **useMuiSnackbar**: For all user notifications\n\n---\n\n## Quick Reference: File Structure\n\n```\nsrc/\n  features/\n    my-feature/\n      api/\n        myFeatureApi.ts       # API service\n      components/\n        MyFeature.tsx         # Main component\n        SubComponent.tsx      # Related components\n      hooks/\n        useMyFeature.ts       # Custom hooks\n        useSuspenseMyFeature.ts  # Suspense hooks\n      helpers/\n        myFeatureHelpers.ts   # Utilities\n      types/\n        index.ts              # TypeScript types\n      index.ts                # Public exports\n\n  components/\n    SuspenseLoader/\n      SuspenseLoader.tsx      # Reusable loader\n    CustomAppBar/\n      CustomAppBar.tsx        # Reusable app bar\n\n  routes/\n    my-route/\n      index.tsx               # Route component\n      create/\n        index.tsx             # Nested route\n```\n\n---\n\n## Modern Component Template (Quick Copy)\n\n```typescript\nimport React, { useState, useCallback } from 'react';\nimport { Box, Paper } from '@mui/material';\nimport { useSuspenseQuery } from '@tanstack/react-query';\nimport { featureApi } from '../api/featureApi';\nimport type { FeatureData } from '~types/feature';\n\ninterface MyComponentProps {\n    id: number;\n    onAction?: () => void;\n}\n\nexport const MyComponent: React.FC<MyComponentProps> = ({ id, onAction }) => {\n    const [state, setState] = useState<string>('');\n\n    const { data } = useSuspenseQuery({\n        queryKey: ['feature', id],\n        queryFn: () => featureApi.getFeature(id),\n    });\n\n    const handleAction = useCallback(() => {\n        setState('updated');\n        onAction?.();\n    }, [onAction]);\n\n    return (\n        <Box sx={{ p: 2 }}>\n            <Paper sx={{ p: 3 }}>\n                {/* Content */}\n            </Paper>\n        </Box>\n    );\n};\n\nexport default MyComponent;\n```\n\nFor complete examples, see [resources/complete-examples.md](resources/complete-examples.md)\n\n---\n\n## Related Skills\n\n- **error-tracking**: Error tracking with Sentry (applies to frontend too)\n- **backend-dev-guidelines**: Backend API patterns that frontend consumes\n\n---\n\n**Skill Status**: Modular structure with progressive loading for optimal context management"}]},"isMeta":true,"uuid":"cb9b490a-e9c7-46e6-81f7-486397ec0417","timestamp":"2025-11-18T14:01:12.112Z","sourceToolUseID":"toolu_01JTExZsYCHE5xZfSBwyuKrA"}
{"parentUuid":"cb9b490a-e9c7-46e6-81f7-486397ec0417","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01BnFL9XU7Ysi1NnSFVyPJGe","type":"message","role":"assistant","content":[{"type":"text","text":"Now I'll create the three comprehensive documentation files for your Alert Notification Router system."}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":5611,"cache_read_input_tokens":21525,"cache_creation":{"ephemeral_5m_input_tokens":5611,"ephemeral_1h_input_tokens":0},"output_tokens":223,"service_tier":"standard"}},"requestId":"req_011CVFUcRuJDqWxPGSDXoGbB","type":"assistant","uuid":"cf8ab3e1-be86-4f9a-be8f-58e13842df39","timestamp":"2025-11-18T14:01:16.802Z"}
{"parentUuid":"cf8ab3e1-be86-4f9a-be8f-58e13842df39","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01BnFL9XU7Ysi1NnSFVyPJGe","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018rM2L2dkSDNLDownRkeMDn","name":"TodoWrite","input":{"todos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"in_progress","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"pending","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"pending","activeForm":"Creating Guide.md with user documentation"}]}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":5611,"cache_read_input_tokens":21525,"cache_creation":{"ephemeral_5m_input_tokens":5611,"ephemeral_1h_input_tokens":0},"output_tokens":223,"service_tier":"standard"}},"requestId":"req_011CVFUcRuJDqWxPGSDXoGbB","type":"assistant","uuid":"29174db0-a15f-4ce4-8422-b90fe1be62bb","timestamp":"2025-11-18T14:01:18.920Z"}
{"parentUuid":"29174db0-a15f-4ce4-8422-b90fe1be62bb","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018rM2L2dkSDNLDownRkeMDn","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"40a3cf4b-6bf8-4424-85c2-f9469eacb6da","timestamp":"2025-11-18T14:01:19.002Z","toolUseResult":{"oldTodos":[],"newTodos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"in_progress","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"pending","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"pending","activeForm":"Creating Guide.md with user documentation"}]}}
{"parentUuid":"40a3cf4b-6bf8-4424-85c2-f9469eacb6da","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01U3bGmPHNj2aoePyQU8HTFq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TKi9h4shaQc8jVoEqFnRLQ","name":"Write","input":{"file_path":"/root/Claude/claude-hooks/DevelopmentPlan.md","content":"# Alert Notification Router - Development Plan\n\n## Table of Contents\n\n1. [System Overview](#system-overview)\n2. [Architecture](#architecture)\n3. [Tech Stack](#tech-stack)\n4. [Database Schema](#database-schema)\n5. [API Endpoints](#api-endpoints)\n6. [Implementation Phases](#implementation-phases)\n7. [Security Considerations](#security-considerations)\n8. [Scalability & Performance](#scalability--performance)\n\n---\n\n## System Overview\n\n### Purpose\n\nThe Alert Notification Router is an intelligent alert distribution system that routes alerts to appropriate teams based on configurable rules and escalation policies. It provides multi-channel delivery, deduplication, priority handling, and comprehensive delivery tracking.\n\n### Key Features\n\n- **Intelligent Routing**: Rule-based routing engine with pattern matching\n- **Multi-Channel Support**: Email, Slack, PagerDuty integration\n- **Alert Deduplication**: Prevents duplicate notifications within configurable time windows\n- **Priority Handling**: Supports critical, high, medium, low priority levels\n- **Escalation Policies**: Automatic escalation after timeout periods\n- **Delivery Tracking**: Comprehensive audit trail and status tracking\n- **Team Management**: Flexible team and user management with role-based access\n- **Analytics Dashboard**: Real-time metrics and historical reporting\n\n---\n\n## Architecture\n\n### High-Level Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Alert Sources  â”‚\nâ”‚  (External APIs)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚         API Gateway Layer               â”‚\nâ”‚  - Authentication & Authorization       â”‚\nâ”‚  - Rate Limiting                        â”‚\nâ”‚  - Request Validation (Zod)            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      Alert Processing Service           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Ingestion Controller            â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Deduplication Service           â”‚   â”‚\nâ”‚  â”‚  - Hash generation               â”‚   â”‚\nâ”‚  â”‚  - Similarity checking           â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Routing Engine                  â”‚   â”‚\nâ”‚  â”‚  - Rule evaluation               â”‚   â”‚\nâ”‚  â”‚  - Team matching                 â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Priority Queue                  â”‚   â”‚\nâ”‚  â”‚  - Priority-based scheduling     â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n              â”‚\n              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚    Notification Delivery Service         â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Channel Manager                 â”‚   â”‚\nâ”‚  â”‚  - Email Provider                â”‚   â”‚\nâ”‚  â”‚  - Slack Provider                â”‚   â”‚\nâ”‚  â”‚  - PagerDuty Provider            â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Delivery Tracker                â”‚   â”‚\nâ”‚  â”‚  - Status updates                â”‚   â”‚\nâ”‚  â”‚  - Retry logic                   â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n              â”‚\n              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Escalation Service                   â”‚\nâ”‚  - Monitors unacknowledged alerts       â”‚\nâ”‚  - Triggers escalation policies         â”‚\nâ”‚  - Re-routes to escalation teams        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Layered Architecture\n\nFollowing backend best practices:\n\n```\nRoutes Layer\n    â†“\nControllers Layer (BaseController)\n    â†“\nServices Layer (Business Logic)\n    â†“\nRepositories Layer (Data Access)\n    â†“\nDatabase (Prisma)\n```\n\n### Component Breakdown\n\n#### 1. Alert Processing Service\n- **Ingestion Controller**: Receives and validates incoming alerts\n- **Deduplication Service**: Identifies and merges duplicate alerts\n- **Routing Engine**: Evaluates rules and determines target teams\n- **Priority Queue**: Manages alert processing order\n\n#### 2. Notification Delivery Service\n- **Channel Manager**: Abstracts notification channel implementations\n- **Email Provider**: Sends emails via SMTP/SendGrid\n- **Slack Provider**: Posts messages to Slack channels/users\n- **PagerDuty Provider**: Creates incidents in PagerDuty\n- **Delivery Tracker**: Monitors delivery status and retries\n\n#### 3. Escalation Service\n- **Escalation Monitor**: Background job checking unacknowledged alerts\n- **Policy Executor**: Applies escalation rules\n- **Re-routing Logic**: Sends alerts to escalation teams\n\n#### 4. Configuration Service\n- **Rule Management**: CRUD operations for routing rules\n- **Team Management**: Manages teams, users, and on-call schedules\n- **Policy Management**: Escalation policy configuration\n\n---\n\n## Tech Stack\n\n### Backend\n\n**Core Framework**\n- **Node.js** v20+ (LTS)\n- **TypeScript** v5+\n- **Express.js** v4+ (API framework)\n\n**Database**\n- **PostgreSQL** v15+ (Primary database)\n- **Redis** v7+ (Caching, deduplication, queue management)\n\n**ORM & Database Tools**\n- **Prisma** v5+ (ORM and migrations)\n- **PrismaClient** (Type-safe database access)\n\n**Validation & Type Safety**\n- **Zod** v3+ (Runtime validation and DTO schemas)\n- **TypeScript** (Compile-time type safety)\n\n**Error Tracking & Monitoring**\n- **Sentry** v8+ (Error tracking and performance monitoring)\n- **Winston** (Structured logging)\n\n**Authentication & Authorization**\n- **JWT** (JSON Web Tokens)\n- **bcrypt** (Password hashing)\n\n**Queue & Background Jobs**\n- **Bull** v4+ (Redis-based queue)\n- **node-cron** (Scheduled jobs)\n\n**Notification Channels**\n- **Nodemailer** (Email delivery)\n- **@slack/web-api** (Slack integration)\n- **@pagerduty/pdjs** (PagerDuty integration)\n\n**Testing**\n- **Jest** (Unit and integration tests)\n- **Supertest** (API endpoint testing)\n- **ts-jest** (TypeScript support)\n\n**Development Tools**\n- **ESLint** (Code linting)\n- **Prettier** (Code formatting)\n- **tsx** (TypeScript execution)\n- **nodemon** (Development auto-reload)\n\n### Frontend (Optional Dashboard)\n\n**Core Framework**\n- **React** v18+\n- **TypeScript** v5+\n- **Vite** v5+ (Build tool)\n\n**UI Framework**\n- **Material-UI (MUI)** v7+ (Component library)\n\n**Data Fetching**\n- **TanStack Query** v5+ (useSuspenseQuery pattern)\n- **Axios** (HTTP client)\n\n**Routing**\n- **TanStack Router** v1+ (File-based routing)\n\n**State Management**\n- **React Context** (Global state)\n- **TanStack Query** (Server state)\n\n**Forms & Validation**\n- **React Hook Form** v7+\n- **Zod** (Form validation)\n\n### Infrastructure\n\n**Containerization**\n- **Docker** (Container runtime)\n- **Docker Compose** (Local development)\n\n**CI/CD**\n- **GitHub Actions** (Automated testing and deployment)\n\n**Deployment**\n- **AWS/GCP/Azure** (Cloud infrastructure)\n- **Kubernetes** (Container orchestration - optional)\n\n---\n\n## Database Schema\n\n### Core Tables\n\n#### 1. users\n```sql\nCREATE TABLE users (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    email VARCHAR(255) UNIQUE NOT NULL,\n    username VARCHAR(100) UNIQUE NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    full_name VARCHAR(255),\n    phone VARCHAR(50),\n    role VARCHAR(50) DEFAULT 'user',\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_deleted_at ON users(deleted_at);\n```\n\n#### 2. teams\n```sql\nCREATE TABLE teams (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    email VARCHAR(255),\n    slack_channel_id VARCHAR(100),\n    pagerduty_service_id VARCHAR(100),\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_teams_name ON teams(name);\n```\n\n#### 3. team_members\n```sql\nCREATE TABLE team_members (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    team_id UUID NOT NULL REFERENCES teams(id) ON DELETE CASCADE,\n    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n    role VARCHAR(50) DEFAULT 'member',\n    is_on_call BOOLEAN DEFAULT false,\n    on_call_start TIMESTAMP NULL,\n    on_call_end TIMESTAMP NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    UNIQUE(team_id, user_id)\n);\n\nCREATE INDEX idx_team_members_team_id ON team_members(team_id);\nCREATE INDEX idx_team_members_user_id ON team_members(user_id);\nCREATE INDEX idx_team_members_on_call ON team_members(is_on_call);\n```\n\n#### 4. routing_rules\n```sql\nCREATE TABLE routing_rules (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    priority INTEGER DEFAULT 0,\n    enabled BOOLEAN DEFAULT true,\n    match_type VARCHAR(50) NOT NULL, -- 'all', 'any', 'regex'\n    conditions JSONB NOT NULL,\n    target_team_id UUID REFERENCES teams(id) ON DELETE SET NULL,\n    notification_channels JSONB, -- ['email', 'slack', 'pagerduty']\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_routing_rules_priority ON routing_rules(priority DESC);\nCREATE INDEX idx_routing_rules_enabled ON routing_rules(enabled);\nCREATE INDEX idx_routing_rules_conditions ON routing_rules USING GIN(conditions);\n```\n\n#### 5. alerts\n```sql\nCREATE TABLE alerts (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    external_id VARCHAR(255),\n    source VARCHAR(255) NOT NULL,\n    title VARCHAR(500) NOT NULL,\n    description TEXT,\n    severity VARCHAR(50) NOT NULL, -- 'critical', 'high', 'medium', 'low'\n    priority INTEGER DEFAULT 0,\n    status VARCHAR(50) DEFAULT 'open', -- 'open', 'acknowledged', 'resolved', 'suppressed'\n    fingerprint VARCHAR(64) NOT NULL,\n    labels JSONB,\n    metadata JSONB,\n    matched_rule_id UUID REFERENCES routing_rules(id),\n    assigned_team_id UUID REFERENCES teams(id),\n    acknowledged_by UUID REFERENCES users(id),\n    acknowledged_at TIMESTAMP NULL,\n    resolved_by UUID REFERENCES users(id),\n    resolved_at TIMESTAMP NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    expires_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_alerts_fingerprint ON alerts(fingerprint);\nCREATE INDEX idx_alerts_status ON alerts(status);\nCREATE INDEX idx_alerts_severity ON alerts(severity);\nCREATE INDEX idx_alerts_team ON alerts(assigned_team_id);\nCREATE INDEX idx_alerts_created_at ON alerts(created_at DESC);\nCREATE INDEX idx_alerts_labels ON alerts USING GIN(labels);\n```\n\n#### 6. alert_notifications\n```sql\nCREATE TABLE alert_notifications (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    alert_id UUID NOT NULL REFERENCES alerts(id) ON DELETE CASCADE,\n    channel VARCHAR(50) NOT NULL, -- 'email', 'slack', 'pagerduty'\n    recipient VARCHAR(255) NOT NULL,\n    status VARCHAR(50) DEFAULT 'pending', -- 'pending', 'sent', 'failed', 'delivered'\n    attempt_count INTEGER DEFAULT 0,\n    last_attempt_at TIMESTAMP NULL,\n    sent_at TIMESTAMP NULL,\n    delivered_at TIMESTAMP NULL,\n    failed_at TIMESTAMP NULL,\n    error_message TEXT,\n    external_id VARCHAR(255),\n    metadata JSONB,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_notifications_alert_id ON alert_notifications(alert_id);\nCREATE INDEX idx_notifications_status ON alert_notifications(status);\nCREATE INDEX idx_notifications_channel ON alert_notifications(channel);\n```\n\n#### 7. escalation_policies\n```sql\nCREATE TABLE escalation_policies (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    team_id UUID REFERENCES teams(id) ON DELETE CASCADE,\n    enabled BOOLEAN DEFAULT true,\n    levels JSONB NOT NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_escalation_policies_team ON escalation_policies(team_id);\n```\n\nExample `levels` JSONB structure:\n```json\n[\n    {\n        \"level\": 1,\n        \"timeout_minutes\": 15,\n        \"target_team_id\": \"uuid\",\n        \"channels\": [\"email\", \"slack\"]\n    },\n    {\n        \"level\": 2,\n        \"timeout_minutes\": 30,\n        \"target_team_id\": \"uuid\",\n        \"channels\": [\"pagerduty\"]\n    }\n]\n```\n\n#### 8. escalations\n```sql\nCREATE TABLE escalations (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    alert_id UUID NOT NULL REFERENCES alerts(id) ON DELETE CASCADE,\n    policy_id UUID NOT NULL REFERENCES escalation_policies(id),\n    current_level INTEGER DEFAULT 1,\n    max_level INTEGER NOT NULL,\n    status VARCHAR(50) DEFAULT 'active', -- 'active', 'completed', 'cancelled'\n    next_escalation_at TIMESTAMP,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_escalations_alert ON escalations(alert_id);\nCREATE INDEX idx_escalations_status ON escalations(status);\nCREATE INDEX idx_escalations_next ON escalations(next_escalation_at);\n```\n\n#### 9. audit_logs\n```sql\nCREATE TABLE audit_logs (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    entity_type VARCHAR(100) NOT NULL,\n    entity_id UUID NOT NULL,\n    action VARCHAR(100) NOT NULL,\n    user_id UUID REFERENCES users(id),\n    changes JSONB,\n    metadata JSONB,\n    ip_address VARCHAR(45),\n    user_agent TEXT,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_audit_logs_entity ON audit_logs(entity_type, entity_id);\nCREATE INDEX idx_audit_logs_user ON audit_logs(user_id);\nCREATE INDEX idx_audit_logs_created_at ON audit_logs(created_at DESC);\n```\n\n### Prisma Schema\n\n```prisma\ngenerator client {\n  provider = \"prisma-client-js\"\n}\n\ndatasource db {\n  provider = \"postgresql\"\n  url      = env(\"DATABASE_URL\")\n}\n\nmodel User {\n  id           String   @id @default(uuid()) @db.Uuid\n  email        String   @unique @db.VarChar(255)\n  username     String   @unique @db.VarChar(100)\n  passwordHash String   @map(\"password_hash\") @db.VarChar(255)\n  fullName     String?  @map(\"full_name\") @db.VarChar(255)\n  phone        String?  @db.VarChar(50)\n  role         String   @default(\"user\") @db.VarChar(50)\n  createdAt    DateTime @default(now()) @map(\"created_at\")\n  updatedAt    DateTime @updatedAt @map(\"updated_at\")\n  deletedAt    DateTime? @map(\"deleted_at\")\n\n  teamMembers         TeamMember[]\n  acknowledgedAlerts  Alert[]       @relation(\"AcknowledgedBy\")\n  resolvedAlerts      Alert[]       @relation(\"ResolvedBy\")\n  auditLogs           AuditLog[]\n\n  @@index([email])\n  @@index([deletedAt])\n  @@map(\"users\")\n}\n\nmodel Team {\n  id                 String    @id @default(uuid()) @db.Uuid\n  name               String    @db.VarChar(255)\n  description        String?   @db.Text\n  email              String?   @db.VarChar(255)\n  slackChannelId     String?   @map(\"slack_channel_id\") @db.VarChar(100)\n  pagerdutyServiceId String?   @map(\"pagerduty_service_id\") @db.VarChar(100)\n  createdAt          DateTime  @default(now()) @map(\"created_at\")\n  updatedAt          DateTime  @updatedAt @map(\"updated_at\")\n  deletedAt          DateTime? @map(\"deleted_at\")\n\n  members            TeamMember[]\n  routingRules       RoutingRule[]\n  alerts             Alert[]\n  escalationPolicies EscalationPolicy[]\n\n  @@index([name])\n  @@map(\"teams\")\n}\n\nmodel TeamMember {\n  id           String    @id @default(uuid()) @db.Uuid\n  teamId       String    @map(\"team_id\") @db.Uuid\n  userId       String    @map(\"user_id\") @db.Uuid\n  role         String    @default(\"member\") @db.VarChar(50)\n  isOnCall     Boolean   @default(false) @map(\"is_on_call\")\n  onCallStart  DateTime? @map(\"on_call_start\")\n  onCallEnd    DateTime? @map(\"on_call_end\")\n  createdAt    DateTime  @default(now()) @map(\"created_at\")\n\n  team Team @relation(fields: [teamId], references: [id], onDelete: Cascade)\n  user User @relation(fields: [userId], references: [id], onDelete: Cascade)\n\n  @@unique([teamId, userId])\n  @@index([teamId])\n  @@index([userId])\n  @@index([isOnCall])\n  @@map(\"team_members\")\n}\n\nmodel RoutingRule {\n  id                   String    @id @default(uuid()) @db.Uuid\n  name                 String    @db.VarChar(255)\n  description          String?   @db.Text\n  priority             Int       @default(0)\n  enabled              Boolean   @default(true)\n  matchType            String    @map(\"match_type\") @db.VarChar(50)\n  conditions           Json      @db.JsonB\n  targetTeamId         String?   @map(\"target_team_id\") @db.Uuid\n  notificationChannels Json?     @map(\"notification_channels\") @db.JsonB\n  createdAt            DateTime  @default(now()) @map(\"created_at\")\n  updatedAt            DateTime  @updatedAt @map(\"updated_at\")\n  deletedAt            DateTime? @map(\"deleted_at\")\n\n  targetTeam Team?   @relation(fields: [targetTeamId], references: [id], onDelete: SetNull)\n  alerts     Alert[]\n\n  @@index([priority(sort: Desc)])\n  @@index([enabled])\n  @@map(\"routing_rules\")\n}\n\nmodel Alert {\n  id              String    @id @default(uuid()) @db.Uuid\n  externalId      String?   @map(\"external_id\") @db.VarChar(255)\n  source          String    @db.VarChar(255)\n  title           String    @db.VarChar(500)\n  description     String?   @db.Text\n  severity        String    @db.VarChar(50)\n  priority        Int       @default(0)\n  status          String    @default(\"open\") @db.VarChar(50)\n  fingerprint     String    @db.VarChar(64)\n  labels          Json?     @db.JsonB\n  metadata        Json?     @db.JsonB\n  matchedRuleId   String?   @map(\"matched_rule_id\") @db.Uuid\n  assignedTeamId  String?   @map(\"assigned_team_id\") @db.Uuid\n  acknowledgedBy  String?   @map(\"acknowledged_by\") @db.Uuid\n  acknowledgedAt  DateTime? @map(\"acknowledged_at\")\n  resolvedBy      String?   @map(\"resolved_by\") @db.Uuid\n  resolvedAt      DateTime? @map(\"resolved_at\")\n  createdAt       DateTime  @default(now()) @map(\"created_at\")\n  updatedAt       DateTime  @updatedAt @map(\"updated_at\")\n  expiresAt       DateTime? @map(\"expires_at\")\n\n  matchedRule       RoutingRule?        @relation(fields: [matchedRuleId], references: [id])\n  assignedTeam      Team?               @relation(fields: [assignedTeamId], references: [id])\n  acknowledger      User?               @relation(\"AcknowledgedBy\", fields: [acknowledgedBy], references: [id])\n  resolver          User?               @relation(\"ResolvedBy\", fields: [resolvedBy], references: [id])\n  notifications     AlertNotification[]\n  escalations       Escalation[]\n\n  @@index([fingerprint])\n  @@index([status])\n  @@index([severity])\n  @@index([assignedTeamId])\n  @@index([createdAt(sort: Desc)])\n  @@map(\"alerts\")\n}\n\nmodel AlertNotification {\n  id            String    @id @default(uuid()) @db.Uuid\n  alertId       String    @map(\"alert_id\") @db.Uuid\n  channel       String    @db.VarChar(50)\n  recipient     String    @db.VarChar(255)\n  status        String    @default(\"pending\") @db.VarChar(50)\n  attemptCount  Int       @default(0) @map(\"attempt_count\")\n  lastAttemptAt DateTime? @map(\"last_attempt_at\")\n  sentAt        DateTime? @map(\"sent_at\")\n  deliveredAt   DateTime? @map(\"delivered_at\")\n  failedAt      DateTime? @map(\"failed_at\")\n  errorMessage  String?   @map(\"error_message\") @db.Text\n  externalId    String?   @map(\"external_id\") @db.VarChar(255)\n  metadata      Json?     @db.JsonB\n  createdAt     DateTime  @default(now()) @map(\"created_at\")\n\n  alert Alert @relation(fields: [alertId], references: [id], onDelete: Cascade)\n\n  @@index([alertId])\n  @@index([status])\n  @@index([channel])\n  @@map(\"alert_notifications\")\n}\n\nmodel EscalationPolicy {\n  id          String    @id @default(uuid()) @db.Uuid\n  name        String    @db.VarChar(255)\n  description String?   @db.Text\n  teamId      String?   @map(\"team_id\") @db.Uuid\n  enabled     Boolean   @default(true)\n  levels      Json      @db.JsonB\n  createdAt   DateTime  @default(now()) @map(\"created_at\")\n  updatedAt   DateTime  @updatedAt @map(\"updated_at\")\n\n  team        Team?        @relation(fields: [teamId], references: [id], onDelete: Cascade)\n  escalations Escalation[]\n\n  @@index([teamId])\n  @@map(\"escalation_policies\")\n}\n\nmodel Escalation {\n  id                String    @id @default(uuid()) @db.Uuid\n  alertId           String    @map(\"alert_id\") @db.Uuid\n  policyId          String    @map(\"policy_id\") @db.Uuid\n  currentLevel      Int       @default(1) @map(\"current_level\")\n  maxLevel          Int       @map(\"max_level\")\n  status            String    @default(\"active\") @db.VarChar(50)\n  nextEscalationAt  DateTime? @map(\"next_escalation_at\")\n  createdAt         DateTime  @default(now()) @map(\"created_at\")\n  updatedAt         DateTime  @updatedAt @map(\"updated_at\")\n\n  alert  Alert            @relation(fields: [alertId], references: [id], onDelete: Cascade)\n  policy EscalationPolicy @relation(fields: [policyId], references: [id])\n\n  @@index([alertId])\n  @@index([status])\n  @@index([nextEscalationAt])\n  @@map(\"escalations\")\n}\n\nmodel AuditLog {\n  id         String   @id @default(uuid()) @db.Uuid\n  entityType String   @map(\"entity_type\") @db.VarChar(100)\n  entityId   String   @map(\"entity_id\") @db.Uuid\n  action     String   @db.VarChar(100)\n  userId     String?  @map(\"user_id\") @db.Uuid\n  changes    Json?    @db.JsonB\n  metadata   Json?    @db.JsonB\n  ipAddress  String?  @map(\"ip_address\") @db.VarChar(45)\n  userAgent  String?  @map(\"user_agent\") @db.Text\n  createdAt  DateTime @default(now()) @map(\"created_at\")\n\n  user User? @relation(fields: [userId], references: [id])\n\n  @@index([entityType, entityId])\n  @@index([userId])\n  @@index([createdAt(sort: Desc)])\n  @@map(\"audit_logs\")\n}\n```\n\n---\n\n## API Endpoints\n\n### Authentication\n\n```\nPOST   /api/auth/register          Register new user\nPOST   /api/auth/login             Login user\nPOST   /api/auth/logout            Logout user\nPOST   /api/auth/refresh           Refresh access token\nGET    /api/auth/me                Get current user\n```\n\n### Alerts\n\n```\nPOST   /api/alerts                 Create alert\nGET    /api/alerts                 List alerts (paginated, filtered)\nGET    /api/alerts/:id             Get alert by ID\nPATCH  /api/alerts/:id             Update alert\nDELETE /api/alerts/:id             Delete alert\nPOST   /api/alerts/:id/acknowledge Acknowledge alert\nPOST   /api/alerts/:id/resolve     Resolve alert\nPOST   /api/alerts/:id/suppress    Suppress alert\nGET    /api/alerts/:id/history     Get alert history\n```\n\n### Teams\n\n```\nPOST   /api/teams                  Create team\nGET    /api/teams                  List teams\nGET    /api/teams/:id              Get team by ID\nPATCH  /api/teams/:id              Update team\nDELETE /api/teams/:id              Delete team\nGET    /api/teams/:id/members      List team members\nPOST   /api/teams/:id/members      Add member to team\nDELETE /api/teams/:id/members/:uid Remove member from team\nPATCH  /api/teams/:id/members/:uid Update member role/on-call status\n```\n\n### Routing Rules\n\n```\nPOST   /api/rules                  Create routing rule\nGET    /api/rules                  List routing rules\nGET    /api/rules/:id              Get rule by ID\nPATCH  /api/rules/:id              Update rule\nDELETE /api/rules/:id              Delete rule\nPOST   /api/rules/:id/enable       Enable rule\nPOST   /api/rules/:id/disable      Disable rule\nPOST   /api/rules/test             Test rule against sample alert\nGET    /api/rules/:id/matches      Get alerts matched by rule\n```\n\n### Escalation Policies\n\n```\nPOST   /api/escalation-policies    Create escalation policy\nGET    /api/escalation-policies    List escalation policies\nGET    /api/escalation-policies/:id Get policy by ID\nPATCH  /api/escalation-policies/:id Update policy\nDELETE /api/escalation-policies/:id Delete policy\n```\n\n### Notifications\n\n```\nGET    /api/notifications          List notifications (paginated)\nGET    /api/notifications/:id      Get notification by ID\nPOST   /api/notifications/:id/retry Retry failed notification\nGET    /api/notifications/stats    Get notification statistics\n```\n\n### Analytics\n\n```\nGET    /api/analytics/overview     Dashboard overview metrics\nGET    /api/analytics/alerts       Alert statistics (by severity, status, team)\nGET    /api/analytics/notifications Notification delivery metrics\nGET    /api/analytics/teams        Team performance metrics\nGET    /api/analytics/response-times Average response times\n```\n\n### Users\n\n```\nGET    /api/users                  List users\nGET    /api/users/:id              Get user by ID\nPATCH  /api/users/:id              Update user\nDELETE /api/users/:id              Delete user\nGET    /api/users/:id/alerts       Get user's assigned alerts\n```\n\n### Audit Logs\n\n```\nGET    /api/audit-logs             List audit logs (filtered, paginated)\nGET    /api/audit-logs/:id         Get audit log by ID\n```\n\n### Request/Response Examples\n\n#### POST /api/alerts\n\n**Request:**\n```json\n{\n  \"source\": \"prometheus\",\n  \"externalId\": \"alert-12345\",\n  \"title\": \"High CPU Usage on prod-server-01\",\n  \"description\": \"CPU usage exceeded 90% threshold for 5 minutes\",\n  \"severity\": \"high\",\n  \"labels\": {\n    \"environment\": \"production\",\n    \"service\": \"api\",\n    \"instance\": \"prod-server-01\"\n  },\n  \"metadata\": {\n    \"metric\": \"cpu_usage_percent\",\n    \"threshold\": 90,\n    \"current_value\": 95.3\n  }\n}\n```\n\n**Response (201 Created):**\n```json\n{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"source\": \"prometheus\",\n  \"externalId\": \"alert-12345\",\n  \"title\": \"High CPU Usage on prod-server-01\",\n  \"description\": \"CPU usage exceeded 90% threshold for 5 minutes\",\n  \"severity\": \"high\",\n  \"priority\": 80,\n  \"status\": \"open\",\n  \"fingerprint\": \"abc123def456...\",\n  \"matchedRuleId\": \"660e8400-e29b-41d4-a716-446655440001\",\n  \"assignedTeamId\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"createdAt\": \"2025-11-18T10:30:00Z\",\n  \"updatedAt\": \"2025-11-18T10:30:00Z\"\n}\n```\n\n#### POST /api/rules\n\n**Request:**\n```json\n{\n  \"name\": \"Production Critical Alerts\",\n  \"description\": \"Route all critical alerts from production to Platform team\",\n  \"priority\": 100,\n  \"enabled\": true,\n  \"matchType\": \"all\",\n  \"conditions\": {\n    \"severity\": [\"critical\"],\n    \"labels\": {\n      \"environment\": \"production\"\n    }\n  },\n  \"targetTeamId\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"notificationChannels\": [\"email\", \"slack\", \"pagerduty\"]\n}\n```\n\n---\n\n## Implementation Phases\n\n### Phase 1: Foundation (Weeks 1-2)\n\n**Goals**: Set up project structure, database, and core services\n\n**Tasks**:\n1. Initialize project structure\n   - Set up TypeScript + Express + Prisma\n   - Configure ESLint, Prettier, ts-jest\n   - Create Docker Compose for local development\n   - Set up environment configuration with unifiedConfig\n\n2. Database setup\n   - Create Prisma schema\n   - Initial migrations\n   - Seed data for testing\n\n3. Authentication service\n   - User registration and login\n   - JWT token generation and verification\n   - Password hashing with bcrypt\n   - Auth middleware\n\n4. Base infrastructure\n   - BaseController implementation\n   - Error handling middleware\n   - Sentry initialization\n   - Winston logging setup\n   - Request validation middleware (Zod)\n\n**Deliverables**:\n- Working authentication system\n- Database with initial schema\n- Base project structure following best practices\n\n### Phase 2: Alert Management (Weeks 3-4)\n\n**Goals**: Implement core alert ingestion and management\n\n**Tasks**:\n1. Alert ingestion API\n   - POST /api/alerts endpoint\n   - Request validation with Zod schemas\n   - AlertController and AlertService\n   - AlertRepository for database access\n\n2. Deduplication service\n   - Fingerprint generation (SHA-256 hash of key fields)\n   - Redis-based deduplication cache\n   - Time-window based duplicate detection\n   - Alert merging logic\n\n3. Alert CRUD operations\n   - List alerts with filtering and pagination\n   - Get alert by ID\n   - Update alert status\n   - Delete alert\n\n4. Alert actions\n   - Acknowledge alert\n   - Resolve alert\n   - Suppress alert\n   - Alert history tracking\n\n**Deliverables**:\n- Functional alert ingestion API\n- Deduplication working with Redis\n- Complete alert management endpoints\n\n### Phase 3: Team Management (Week 5)\n\n**Goals**: Implement team and user management\n\n**Tasks**:\n1. Team CRUD operations\n   - TeamController, TeamService, TeamRepository\n   - Create, read, update, delete teams\n   - Team member management\n\n2. On-call scheduling\n   - Add/remove on-call status\n   - On-call rotation logic\n   - Get current on-call user for team\n\n3. User management\n   - User profile management\n   - Team assignments\n   - Role management\n\n**Deliverables**:\n- Team management API\n- On-call scheduling system\n- User profile management\n\n### Phase 4: Routing Engine (Week 6)\n\n**Goals**: Implement intelligent routing based on rules\n\n**Tasks**:\n1. Routing rule management\n   - RoutingRuleController, RoutingRuleService\n   - CRUD operations for rules\n   - Rule priority ordering\n\n2. Routing engine\n   - Rule evaluation logic\n   - Pattern matching (all, any, regex)\n   - Label-based matching\n   - Team assignment based on matched rules\n\n3. Rule testing\n   - Test rule endpoint\n   - Dry-run mode\n   - Match statistics\n\n**Deliverables**:\n- Routing rule management API\n- Working routing engine\n- Rule testing functionality\n\n### Phase 5: Notification Channels (Weeks 7-8)\n\n**Goals**: Implement multi-channel notification delivery\n\n**Tasks**:\n1. Channel abstraction\n   - NotificationChannel interface\n   - ChannelManager for channel selection\n   - NotificationService\n\n2. Email provider\n   - Nodemailer integration\n   - Email templates (Handlebars)\n   - HTML and text versions\n   - SMTP configuration\n\n3. Slack provider\n   - @slack/web-api integration\n   - Channel and DM message posting\n   - Alert formatting for Slack\n   - Webhook support\n\n4. PagerDuty provider\n   - @pagerduty/pdjs integration\n   - Incident creation\n   - Severity mapping\n   - Incident acknowledgment and resolution sync\n\n5. Delivery tracking\n   - NotificationRepository\n   - Status tracking (pending, sent, delivered, failed)\n   - Retry logic with exponential backoff\n   - Delivery statistics\n\n**Deliverables**:\n- Email notification working\n- Slack integration complete\n- PagerDuty integration complete\n- Delivery tracking and retry logic\n\n### Phase 6: Escalation System (Week 9)\n\n**Goals**: Implement escalation policies and monitoring\n\n**Tasks**:\n1. Escalation policy management\n   - EscalationPolicyController, EscalationPolicyService\n   - CRUD operations\n   - Multi-level escalation configuration\n\n2. Escalation monitoring\n   - Background job with Bull queue\n   - Monitor unacknowledged alerts\n   - Trigger escalation based on timeout\n\n3. Escalation execution\n   - EscalationService\n   - Level progression\n   - Re-routing to escalation teams\n   - Notification to escalation contacts\n\n**Deliverables**:\n- Escalation policy management\n- Working escalation monitoring job\n- Automatic escalation execution\n\n### Phase 7: Analytics & Reporting (Week 10)\n\n**Goals**: Implement analytics dashboard and metrics\n\n**Tasks**:\n1. Analytics service\n   - AnalyticsController, AnalyticsService\n   - Aggregate queries for statistics\n\n2. Metrics endpoints\n   - Overview dashboard metrics\n   - Alert statistics (by severity, status, team)\n   - Notification delivery metrics\n   - Team performance metrics\n   - Response time calculations\n\n3. Time-series data\n   - Redis-based metric caching\n   - Hourly/daily aggregations\n   - Historical trend data\n\n**Deliverables**:\n- Analytics API endpoints\n- Dashboard overview metrics\n- Historical reporting\n\n### Phase 8: Frontend Dashboard (Weeks 11-12)\n\n**Goals**: Build React dashboard for system management\n\n**Tasks**:\n1. Project setup\n   - Vite + React + TypeScript\n   - MUI v7 component library\n   - TanStack Router and Query\n   - API client with Axios\n\n2. Authentication UI\n   - Login page\n   - Registration page\n   - Protected routes\n\n3. Alert management UI\n   - Alert list with DataGrid\n   - Alert details page\n   - Acknowledge/resolve actions\n   - Create alert form\n\n4. Team management UI\n   - Team list\n   - Team details with members\n   - Add/remove members\n   - On-call schedule UI\n\n5. Routing rules UI\n   - Rule list\n   - Rule editor\n   - Rule testing interface\n   - Enable/disable rules\n\n6. Analytics dashboard\n   - Overview metrics cards\n   - Charts for alert trends\n   - Notification delivery stats\n   - Team performance dashboard\n\n**Deliverables**:\n- Fully functional React dashboard\n- All CRUD operations available in UI\n- Analytics visualizations\n\n### Phase 9: Testing & Quality (Week 13)\n\n**Goals**: Comprehensive testing coverage\n\n**Tasks**:\n1. Unit tests\n   - Service layer tests\n   - Repository tests\n   - Utility function tests\n   - Target: 80%+ coverage\n\n2. Integration tests\n   - API endpoint tests with Supertest\n   - Database integration tests\n   - Redis integration tests\n\n3. End-to-end tests\n   - Alert ingestion flow\n   - Routing and notification flow\n   - Escalation flow\n\n4. Load testing\n   - Alert ingestion performance\n   - Concurrent notification delivery\n   - Database query optimization\n\n**Deliverables**:\n- Test suite with 80%+ coverage\n- Integration and E2E tests\n- Performance benchmarks\n\n### Phase 10: Deployment & Documentation (Week 14)\n\n**Goals**: Production deployment and documentation\n\n**Tasks**:\n1. Docker containerization\n   - Multi-stage Dockerfile\n   - Docker Compose for production\n   - Environment variable management\n\n2. CI/CD pipeline\n   - GitHub Actions workflow\n   - Automated testing\n   - Docker image builds\n   - Deployment automation\n\n3. Infrastructure setup\n   - Cloud provider setup (AWS/GCP/Azure)\n   - PostgreSQL database\n   - Redis instance\n   - Load balancer configuration\n\n4. Monitoring and alerting\n   - Sentry error tracking\n   - Application metrics\n   - Database monitoring\n   - Alert on system failures\n\n5. Documentation\n   - API documentation (OpenAPI/Swagger)\n   - Deployment guide\n   - User guide\n   - Architecture documentation\n\n**Deliverables**:\n- Production-ready deployment\n- CI/CD pipeline\n- Complete documentation\n\n---\n\n## Security Considerations\n\n### Authentication & Authorization\n\n1. **JWT tokens**\n   - Short-lived access tokens (15 minutes)\n   - Refresh tokens (7 days)\n   - Token rotation on refresh\n\n2. **Password security**\n   - bcrypt hashing with salt rounds >= 12\n   - Minimum password requirements (8+ chars, complexity)\n   - Password reset flow with time-limited tokens\n\n3. **Role-based access control (RBAC)**\n   - Roles: admin, manager, user\n   - Team-level permissions\n   - API endpoint authorization\n\n### API Security\n\n1. **Rate limiting**\n   - Per-IP rate limits\n   - Per-user rate limits\n   - Different limits for authenticated vs. unauthenticated\n\n2. **Input validation**\n   - Zod schema validation for all inputs\n   - SQL injection prevention (Prisma parameterized queries)\n   - XSS prevention (sanitize outputs)\n\n3. **CORS configuration**\n   - Whitelist allowed origins\n   - Credentials support for cookies\n\n### Data Security\n\n1. **Encryption**\n   - TLS/SSL for all API traffic\n   - Encrypted database connections\n   - Encrypted secrets storage\n\n2. **Secret management**\n   - API keys in environment variables\n   - Never commit secrets to Git\n   - Rotate secrets regularly\n\n3. **Audit logging**\n   - Log all sensitive operations\n   - Track user actions\n   - Immutable audit trail\n\n### Notification Security\n\n1. **Webhook verification**\n   - HMAC signature verification for Slack webhooks\n   - PagerDuty webhook authentication\n\n2. **Sensitive data handling**\n   - Redact sensitive information in notifications\n   - Secure storage of API tokens\n\n### Infrastructure Security\n\n1. **Network security**\n   - Private VPC for backend services\n   - Firewall rules\n   - Security groups\n\n2. **Container security**\n   - Minimal base images\n   - Regular security updates\n   - Vulnerability scanning\n\n---\n\n## Scalability & Performance\n\n### Horizontal Scaling\n\n1. **Stateless API servers**\n   - No session state in application\n   - JWT-based authentication\n   - Load balancer distribution\n\n2. **Worker processes**\n   - Bull queue for background jobs\n   - Multiple worker instances\n   - Job distribution across workers\n\n### Database Optimization\n\n1. **Indexing**\n   - Indexes on frequently queried fields\n   - Composite indexes for complex queries\n   - Regular index analysis\n\n2. **Query optimization**\n   - Use Prisma's `select` for partial data\n   - Batch queries where possible\n   - Avoid N+1 queries\n\n3. **Connection pooling**\n   - PgBouncer for PostgreSQL\n   - Prisma connection pool configuration\n\n### Caching Strategy\n\n1. **Redis caching**\n   - Deduplication cache (short TTL: 5 minutes)\n   - Routing rule cache (TTL: 10 minutes)\n   - Team member cache (TTL: 5 minutes)\n   - Analytics cache (TTL: 1 minute)\n\n2. **Cache invalidation**\n   - On data updates\n   - Time-based expiration\n   - Manual cache clearing endpoint\n\n### Queue Management\n\n1. **Priority queues**\n   - Separate queues by priority\n   - Critical alerts processed first\n   - Rate limiting per priority level\n\n2. **Queue monitoring**\n   - Queue length metrics\n   - Processing time metrics\n   - Failed job tracking\n\n### Performance Metrics\n\n1. **Target metrics**\n   - Alert ingestion: < 100ms (p95)\n   - Notification delivery: < 5 seconds (p95)\n   - API response time: < 200ms (p95)\n   - Database query time: < 50ms (p95)\n\n2. **Monitoring**\n   - Sentry performance monitoring\n   - Custom metrics with Prometheus\n   - Alerts on performance degradation\n\n---\n\n## Future Enhancements\n\n### Phase 11+\n\n1. **Additional notification channels**\n   - Microsoft Teams\n   - SMS via Twilio\n   - Webhook callbacks\n\n2. **Advanced routing**\n   - Machine learning-based routing\n   - Historical pattern analysis\n   - Smart team suggestions\n\n3. **Alert correlation**\n   - Automatic incident grouping\n   - Root cause analysis\n   - Impact assessment\n\n4. **Mobile app**\n   - iOS and Android apps\n   - Push notifications\n   - On-call management\n\n5. **Integration marketplace**\n   - Plugin system\n   - Custom channel adapters\n   - Third-party integrations\n\n6. **Advanced analytics**\n   - MTTR (Mean Time To Resolution) tracking\n   - Team burnout indicators\n   - Predictive alerting\n\n---\n\n## Conclusion\n\nThis development plan provides a comprehensive roadmap for building a production-grade Alert Notification Router system. The phased approach allows for incremental delivery of value while maintaining code quality and following best practices.\n\n**Key Success Factors**:\n- Follow layered architecture principles\n- Comprehensive testing at all phases\n- Security-first approach\n- Performance monitoring from day one\n- Clear documentation throughout\n\n**Timeline**: 14 weeks for MVP with core features\n**Team Size**: 2-3 full-stack developers\n**Tech Expertise Required**: Node.js, TypeScript, React, PostgreSQL, Redis\n"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":227,"cache_read_input_tokens":27136,"cache_creation":{"ephemeral_5m_input_tokens":227,"ephemeral_1h_input_tokens":0},"output_tokens":11346,"service_tier":"standard"}},"requestId":"req_011CVFUcwBRnMYihFgBrp4TT","type":"assistant","uuid":"8d62ea8c-007e-400a-8d8b-7349b7c69c55","timestamp":"2025-11-18T14:03:49.485Z"}
{"parentUuid":"8d62ea8c-007e-400a-8d8b-7349b7c69c55","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Markdown file creation detected. You must use the 'docs-organizer' skill before creating markdown files. This skill will help organize the documentation properly in the correct subdirectory under docs/. Please invoke the skill using: Skill tool with skill parameter 'docs-organizer'","is_error":true,"tool_use_id":"toolu_01TKi9h4shaQc8jVoEqFnRLQ"}]},"uuid":"b22637a7-8014-4245-9af3-768cd704688f","timestamp":"2025-11-18T14:03:49.640Z","toolUseResult":"Error: Markdown file creation detected. You must use the 'docs-organizer' skill before creating markdown files. This skill will help organize the documentation properly in the correct subdirectory under docs/. Please invoke the skill using: Skill tool with skill parameter 'docs-organizer'"}
{"parentUuid":"b22637a7-8014-4245-9af3-768cd704688f","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01HCpJ3NSv8U8mMYHFJcVbsb","type":"message","role":"assistant","content":[{"type":"text","text":"I need to use the docs-organizer skill before creating markdown files. Let me activate it."}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":11538,"cache_read_input_tokens":27363,"cache_creation":{"ephemeral_5m_input_tokens":11538,"ephemeral_1h_input_tokens":0},"output_tokens":76,"service_tier":"standard"}},"requestId":"req_011CVFUp5jS3387SzqVs2JnK","type":"assistant","uuid":"7ac0e9a5-5fc4-4ae2-a4cf-ba28c68c2288","timestamp":"2025-11-18T14:03:57.177Z"}
{"parentUuid":"7ac0e9a5-5fc4-4ae2-a4cf-ba28c68c2288","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01HCpJ3NSv8U8mMYHFJcVbsb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XYkvj9LDBDRyMqMmMMGtqz","name":"Skill","input":{"skill":"docs-organizer"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":11538,"cache_read_input_tokens":27363,"cache_creation":{"ephemeral_5m_input_tokens":11538,"ephemeral_1h_input_tokens":0},"output_tokens":76,"service_tier":"standard"}},"requestId":"req_011CVFUp5jS3387SzqVs2JnK","type":"assistant","uuid":"3f58550d-ea15-4833-9df4-b05d1e6b52a8","timestamp":"2025-11-18T14:03:57.552Z"}
{"parentUuid":"3f58550d-ea15-4833-9df4-b05d1e6b52a8","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"type":"tool_result","tool_use_id":"toolu_01XYkvj9LDBDRyMqMmMMGtqz","content":"Launching skill: docs-organizer"}]},"uuid":"a57ad5ea-69d4-4d15-bccb-107b0a9d1c2a","timestamp":"2025-11-18T14:03:57.729Z","toolUseResult":{"success":true,"commandName":"docs-organizer"}}
{"parentUuid":"a57ad5ea-69d4-4d15-bccb-107b0a9d1c2a","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":"<command-message>The \"docs-organizer\" skill is running</command-message>\n<command-name>docs-organizer</command-name>"},"uuid":"3db23792-d0f2-40cc-9d49-38fa43f0db5f","timestamp":"2025-11-18T14:03:57.728Z","sourceToolUseID":"toolu_01XYkvj9LDBDRyMqMmMMGtqz"}
{"parentUuid":"3db23792-d0f2-40cc-9d49-38fa43f0db5f","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"type":"text","text":"Base directory for this skill: /root/.claude/skills/docs-organizer\n\n# Docs Organizer\n\n## Overview\n\nThis skill ensures that all markdown documentation files are systematically organized into appropriate subdirectories under the `docs/` directory. It analyzes the filename and intended content to determine the correct category, creates the necessary directory structure, and writes files to their proper location.\n\n## When to Use This Skill\n\n**ALWAYS** use this skill before creating or writing any new markdown file (.md extension). This includes:\n- Development plans, roadmaps, and project documentation\n- Code reviews, design reviews, and technical assessments\n- Architecture documents, system designs, and ADRs\n- API documentation and specifications\n- Meeting notes, retrospectives, and team communications\n- Any other markdown documentation files\n\n**Exception:** Do not use this skill for:\n- README.md files in the project root or package directories\n- CHANGELOG.md files at the project root\n- LICENSE.md or CONTRIBUTING.md files at the project root\n- Markdown files that are part of application content (e.g., blog posts, user-facing content)\n\n## Documentation Categories\n\nOrganize markdown files into the following subdirectories under `docs/`:\n\n| Category | Directory | File Types |\n|----------|-----------|------------|\n| Development Plans | `docs/plan/` | DevelopmentPlan.md, ProjectPlan.md, Roadmap.md, Sprint*.md |\n| Code Reviews | `docs/review/` | CodeReview*.md, PullRequestReview*.md, DesignReview*.md |\n| Architecture | `docs/architecture/` | Architecture*.md, SystemDesign*.md, ADR*.md, TechStack*.md |\n| API Documentation | `docs/api/` | API*.md, Endpoints*.md, OpenAPI*.md, RestAPI*.md |\n| Requirements | `docs/requirements/` | Requirements*.md, UserStories*.md, FeatureSpec*.md, BRD*.md |\n| Technical Design | `docs/design/` | Design*.md, TechnicalDesign*.md, UIDesign*.md, DataModel*.md |\n| Meeting Notes | `docs/meetings/` | Meeting*.md, Standup*.md, Retrospective*.md, Notes*.md |\n| Testing | `docs/testing/` | TestPlan*.md, TestResults*.md, QA*.md, TestStrategy*.md |\n| Deployment | `docs/deployment/` | Deployment*.md, ReleaseNotes*.md, Runbook*.md, Operations*.md |\n| Onboarding | `docs/onboarding/` | Onboarding*.md, TeamHandbook*.md, GettingStarted*.md, Setup*.md |\n| Technical Specs | `docs/specs/` | Specification*.md, TechnicalSpec*.md, Protocol*.md, Standard*.md |\n| Proposals | `docs/proposals/` | Proposal*.md, RFC*.md, ProjectProposal*.md |\n| Changelog | `docs/changelog/` | CHANGELOG*.md, VersionHistory*.md, ReleaseHistory*.md |\n| Troubleshooting | `docs/troubleshooting/` | Troubleshooting*.md, Debug*.md, FAQ*.md, KnownIssues*.md |\n| Database | `docs/database/` | Schema*.md, Database*.md, Migration*.md, ERDiagram*.md |\n| Guides | `docs/guides/` | Guide*.md, HowTo*.md, Tutorial*.md, Walkthrough*.md |\n| Security | `docs/security/` | Security*.md, ThreatModel*.md, SecurityPolicy*.md, Audit*.md |\n| Process | `docs/process/` | Process*.md, Workflow*.md, SOP*.md, Procedure*.md |\n| General/Other | `docs/general/` | All uncategorized markdown files |\n\n## Workflow\n\nFollow these steps when creating any markdown file:\n\n### 1. Analyze the Filename and Purpose\n\nExamine the filename and intended content to determine which category best fits the document. Use pattern matching on the filename first, then consider the document's purpose if the filename is ambiguous.\n\n**Pattern Matching Rules:**\n- Match case-insensitively\n- Check for category keywords in the filename\n- If multiple categories match, use the most specific one\n- If no pattern matches, ask yourself: \"What is the primary purpose of this document?\"\n\n### 2. Determine the Target Directory\n\nBased on the categorization, construct the full path:\n```\ndocs/<category>/<filename>\n```\n\n**Examples:**\n- `DevelopmentPlan.md` â†’ `docs/plan/DevelopmentPlan.md`\n- `CodeReview.md` â†’ `docs/review/CodeReview.md`\n- `APIEndpoints.md` â†’ `docs/api/APIEndpoints.md`\n- `SecurityAudit2024.md` â†’ `docs/security/SecurityAudit2024.md`\n\n### 3. Ensure Directory Structure Exists\n\nBefore writing the file, verify that the target directory exists. If it doesn't, create the full directory path including any intermediate directories.\n\n```bash\nmkdir -p docs/<category>\n```\n\n### 4. Write the File\n\nWrite the markdown file to the determined location under the docs/ directory.\n\n## Category Selection Guidelines\n\nWhen the filename is ambiguous or doesn't match a clear pattern:\n\n**Ask these questions:**\n1. Is this about planning or roadmapping? â†’ `docs/plan/`\n2. Is this a review of code, design, or architecture? â†’ `docs/review/`\n3. Is this about system architecture or design decisions? â†’ `docs/architecture/`\n4. Is this API or endpoint documentation? â†’ `docs/api/`\n5. Is this about requirements or specifications? â†’ `docs/requirements/` or `docs/specs/`\n6. Is this meeting notes or team communication? â†’ `docs/meetings/`\n7. Is this about testing or QA? â†’ `docs/testing/`\n8. Is this about deployment or operations? â†’ `docs/deployment/`\n9. Is this a guide, tutorial, or how-to? â†’ `docs/guides/`\n10. If none of the above apply â†’ `docs/general/`\n\n**When in doubt:** Use `docs/general/` as the fallback category for any markdown file that doesn't clearly fit into another category.\n\n## Examples\n\n**Example 1: Creating a development plan**\n```\nUser request: \"Create a development plan for the new authentication feature\"\nFilename: DevelopmentPlan.md\nAnalysis: Contains \"Plan\" keyword â†’ matches \"Development Plans\" category\nTarget: docs/plan/DevelopmentPlan.md\nAction: mkdir -p docs/plan && write file to docs/plan/DevelopmentPlan.md\n```\n\n**Example 2: Creating a code review**\n```\nUser request: \"Document the code review findings\"\nFilename: CodeReview.md\nAnalysis: Contains \"Review\" keyword â†’ matches \"Code Reviews\" category\nTarget: docs/review/CodeReview.md\nAction: mkdir -p docs/review && write file to docs/review/CodeReview.md\n```\n\n**Example 3: Creating API documentation**\n```\nUser request: \"Document the REST API endpoints\"\nFilename: RestAPIEndpoints.md\nAnalysis: Contains \"API\" keyword â†’ matches \"API Documentation\" category\nTarget: docs/api/RestAPIEndpoints.md\nAction: mkdir -p docs/api && write file to docs/api/RestAPIEndpoints.md\n```\n\n**Example 4: Creating an ambiguous document**\n```\nUser request: \"Create a document about our deployment strategy\"\nFilename: DeploymentStrategy.md\nAnalysis: Contains \"Deployment\" keyword â†’ matches \"Deployment\" category\nTarget: docs/deployment/DeploymentStrategy.md\nAction: mkdir -p docs/deployment && write file to docs/deployment/DeploymentStrategy.md\n```\n\n## Important Notes\n\n- **Always** check if the docs directory and appropriate subdirectory exist before writing\n- **Never** write markdown files to the project root or arbitrary locations (except for standard files like README.md, CHANGELOG.md in root)\n- **Always** preserve the original filename when moving to the categorized location\n- If uncertain about categorization, default to `docs/general/` rather than making an incorrect guess\n- This organization applies to **new** markdown files only; do not automatically move existing markdown files without explicit user request\n"}]},"isMeta":true,"uuid":"24607f9f-f484-4627-9b67-8ac9a80c86a4","timestamp":"2025-11-18T14:03:57.728Z","sourceToolUseID":"toolu_01XYkvj9LDBDRyMqMmMMGtqz"}
{"parentUuid":"24607f9f-f484-4627-9b67-8ac9a80c86a4","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VSohCuskW3mpHnegzBKqaD","type":"message","role":"assistant","content":[{"type":"text","text":"Now I'll create the three documentation files in the appropriate locations."}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2091,"cache_read_input_tokens":38901,"cache_creation":{"ephemeral_5m_input_tokens":2091,"ephemeral_1h_input_tokens":0},"output_tokens":11436,"service_tier":"standard"}},"requestId":"req_011CVFUpfuFSYKJmyyu61zp4","type":"assistant","uuid":"32b0b2a2-3e1a-44f9-987d-83586737039e","timestamp":"2025-11-18T14:04:02.478Z"}
{"parentUuid":"32b0b2a2-3e1a-44f9-987d-83586737039e","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VSohCuskW3mpHnegzBKqaD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0177Pu4KWpaX2iiFgQLNndP9","name":"Bash","input":{"command":"mkdir -p docs/plan docs/testing docs/guides","description":"Create docs directories for plan, testing, and guides"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2091,"cache_read_input_tokens":38901,"cache_creation":{"ephemeral_5m_input_tokens":2091,"ephemeral_1h_input_tokens":0},"output_tokens":11436,"service_tier":"standard"}},"requestId":"req_011CVFUpfuFSYKJmyyu61zp4","type":"assistant","uuid":"cce60b97-22a8-4644-8492-ccce3c4c19b5","timestamp":"2025-11-18T14:04:03.278Z"}
{"parentUuid":"cce60b97-22a8-4644-8492-ccce3c4c19b5","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VSohCuskW3mpHnegzBKqaD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MQfjhztMewXBLa43eNpXEq","name":"Write","input":{"file_path":"/root/Claude/claude-hooks/docs/plan/DevelopmentPlan.md","content":"# Alert Notification Router - Development Plan\n\n## Table of Contents\n\n1. [System Overview](#system-overview)\n2. [Architecture](#architecture)\n3. [Tech Stack](#tech-stack)\n4. [Database Schema](#database-schema)\n5. [API Endpoints](#api-endpoints)\n6. [Implementation Phases](#implementation-phases)\n7. [Security Considerations](#security-considerations)\n8. [Scalability & Performance](#scalability--performance)\n\n---\n\n## System Overview\n\n### Purpose\n\nThe Alert Notification Router is an intelligent alert distribution system that routes alerts to appropriate teams based on configurable rules and escalation policies. It provides multi-channel delivery, deduplication, priority handling, and comprehensive delivery tracking.\n\n### Key Features\n\n- **Intelligent Routing**: Rule-based routing engine with pattern matching\n- **Multi-Channel Support**: Email, Slack, PagerDuty integration\n- **Alert Deduplication**: Prevents duplicate notifications within configurable time windows\n- **Priority Handling**: Supports critical, high, medium, low priority levels\n- **Escalation Policies**: Automatic escalation after timeout periods\n- **Delivery Tracking**: Comprehensive audit trail and status tracking\n- **Team Management**: Flexible team and user management with role-based access\n- **Analytics Dashboard**: Real-time metrics and historical reporting\n\n---\n\n## Architecture\n\n### High-Level Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Alert Sources  â”‚\nâ”‚  (External APIs)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚         API Gateway Layer               â”‚\nâ”‚  - Authentication & Authorization       â”‚\nâ”‚  - Rate Limiting                        â”‚\nâ”‚  - Request Validation (Zod)            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      Alert Processing Service           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Ingestion Controller            â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Deduplication Service           â”‚   â”‚\nâ”‚  â”‚  - Hash generation               â”‚   â”‚\nâ”‚  â”‚  - Similarity checking           â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Routing Engine                  â”‚   â”‚\nâ”‚  â”‚  - Rule evaluation               â”‚   â”‚\nâ”‚  â”‚  - Team matching                 â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Priority Queue                  â”‚   â”‚\nâ”‚  â”‚  - Priority-based scheduling     â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n              â”‚\n              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚    Notification Delivery Service         â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Channel Manager                 â”‚   â”‚\nâ”‚  â”‚  - Email Provider                â”‚   â”‚\nâ”‚  â”‚  - Slack Provider                â”‚   â”‚\nâ”‚  â”‚  - PagerDuty Provider            â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Delivery Tracker                â”‚   â”‚\nâ”‚  â”‚  - Status updates                â”‚   â”‚\nâ”‚  â”‚  - Retry logic                   â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n              â”‚\n              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Escalation Service                   â”‚\nâ”‚  - Monitors unacknowledged alerts       â”‚\nâ”‚  - Triggers escalation policies         â”‚\nâ”‚  - Re-routes to escalation teams        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Layered Architecture\n\nFollowing backend best practices:\n\n```\nRoutes Layer\n    â†“\nControllers Layer (BaseController)\n    â†“\nServices Layer (Business Logic)\n    â†“\nRepositories Layer (Data Access)\n    â†“\nDatabase (Prisma)\n```\n\n### Component Breakdown\n\n#### 1. Alert Processing Service\n- **Ingestion Controller**: Receives and validates incoming alerts\n- **Deduplication Service**: Identifies and merges duplicate alerts\n- **Routing Engine**: Evaluates rules and determines target teams\n- **Priority Queue**: Manages alert processing order\n\n#### 2. Notification Delivery Service\n- **Channel Manager**: Abstracts notification channel implementations\n- **Email Provider**: Sends emails via SMTP/SendGrid\n- **Slack Provider**: Posts messages to Slack channels/users\n- **PagerDuty Provider**: Creates incidents in PagerDuty\n- **Delivery Tracker**: Monitors delivery status and retries\n\n#### 3. Escalation Service\n- **Escalation Monitor**: Background job checking unacknowledged alerts\n- **Policy Executor**: Applies escalation rules\n- **Re-routing Logic**: Sends alerts to escalation teams\n\n#### 4. Configuration Service\n- **Rule Management**: CRUD operations for routing rules\n- **Team Management**: Manages teams, users, and on-call schedules\n- **Policy Management**: Escalation policy configuration\n\n---\n\n## Tech Stack\n\n### Backend\n\n**Core Framework**\n- **Node.js** v20+ (LTS)\n- **TypeScript** v5+\n- **Express.js** v4+ (API framework)\n\n**Database**\n- **PostgreSQL** v15+ (Primary database)\n- **Redis** v7+ (Caching, deduplication, queue management)\n\n**ORM & Database Tools**\n- **Prisma** v5+ (ORM and migrations)\n- **PrismaClient** (Type-safe database access)\n\n**Validation & Type Safety**\n- **Zod** v3+ (Runtime validation and DTO schemas)\n- **TypeScript** (Compile-time type safety)\n\n**Error Tracking & Monitoring**\n- **Sentry** v8+ (Error tracking and performance monitoring)\n- **Winston** (Structured logging)\n\n**Authentication & Authorization**\n- **JWT** (JSON Web Tokens)\n- **bcrypt** (Password hashing)\n\n**Queue & Background Jobs**\n- **Bull** v4+ (Redis-based queue)\n- **node-cron** (Scheduled jobs)\n\n**Notification Channels**\n- **Nodemailer** (Email delivery)\n- **@slack/web-api** (Slack integration)\n- **@pagerduty/pdjs** (PagerDuty integration)\n\n**Testing**\n- **Jest** (Unit and integration tests)\n- **Supertest** (API endpoint testing)\n- **ts-jest** (TypeScript support)\n\n**Development Tools**\n- **ESLint** (Code linting)\n- **Prettier** (Code formatting)\n- **tsx** (TypeScript execution)\n- **nodemon** (Development auto-reload)\n\n### Frontend (Optional Dashboard)\n\n**Core Framework**\n- **React** v18+\n- **TypeScript** v5+\n- **Vite** v5+ (Build tool)\n\n**UI Framework**\n- **Material-UI (MUI)** v7+ (Component library)\n\n**Data Fetching**\n- **TanStack Query** v5+ (useSuspenseQuery pattern)\n- **Axios** (HTTP client)\n\n**Routing**\n- **TanStack Router** v1+ (File-based routing)\n\n**State Management**\n- **React Context** (Global state)\n- **TanStack Query** (Server state)\n\n**Forms & Validation**\n- **React Hook Form** v7+\n- **Zod** (Form validation)\n\n### Infrastructure\n\n**Containerization**\n- **Docker** (Container runtime)\n- **Docker Compose** (Local development)\n\n**CI/CD**\n- **GitHub Actions** (Automated testing and deployment)\n\n**Deployment**\n- **AWS/GCP/Azure** (Cloud infrastructure)\n- **Kubernetes** (Container orchestration - optional)\n\n---\n\n## Database Schema\n\n### Core Tables\n\n#### 1. users\n```sql\nCREATE TABLE users (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    email VARCHAR(255) UNIQUE NOT NULL,\n    username VARCHAR(100) UNIQUE NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    full_name VARCHAR(255),\n    phone VARCHAR(50),\n    role VARCHAR(50) DEFAULT 'user',\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_deleted_at ON users(deleted_at);\n```\n\n#### 2. teams\n```sql\nCREATE TABLE teams (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    email VARCHAR(255),\n    slack_channel_id VARCHAR(100),\n    pagerduty_service_id VARCHAR(100),\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_teams_name ON teams(name);\n```\n\n#### 3. team_members\n```sql\nCREATE TABLE team_members (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    team_id UUID NOT NULL REFERENCES teams(id) ON DELETE CASCADE,\n    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n    role VARCHAR(50) DEFAULT 'member',\n    is_on_call BOOLEAN DEFAULT false,\n    on_call_start TIMESTAMP NULL,\n    on_call_end TIMESTAMP NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    UNIQUE(team_id, user_id)\n);\n\nCREATE INDEX idx_team_members_team_id ON team_members(team_id);\nCREATE INDEX idx_team_members_user_id ON team_members(user_id);\nCREATE INDEX idx_team_members_on_call ON team_members(is_on_call);\n```\n\n#### 4. routing_rules\n```sql\nCREATE TABLE routing_rules (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    priority INTEGER DEFAULT 0,\n    enabled BOOLEAN DEFAULT true,\n    match_type VARCHAR(50) NOT NULL, -- 'all', 'any', 'regex'\n    conditions JSONB NOT NULL,\n    target_team_id UUID REFERENCES teams(id) ON DELETE SET NULL,\n    notification_channels JSONB, -- ['email', 'slack', 'pagerduty']\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_routing_rules_priority ON routing_rules(priority DESC);\nCREATE INDEX idx_routing_rules_enabled ON routing_rules(enabled);\nCREATE INDEX idx_routing_rules_conditions ON routing_rules USING GIN(conditions);\n```\n\n#### 5. alerts\n```sql\nCREATE TABLE alerts (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    external_id VARCHAR(255),\n    source VARCHAR(255) NOT NULL,\n    title VARCHAR(500) NOT NULL,\n    description TEXT,\n    severity VARCHAR(50) NOT NULL, -- 'critical', 'high', 'medium', 'low'\n    priority INTEGER DEFAULT 0,\n    status VARCHAR(50) DEFAULT 'open', -- 'open', 'acknowledged', 'resolved', 'suppressed'\n    fingerprint VARCHAR(64) NOT NULL,\n    labels JSONB,\n    metadata JSONB,\n    matched_rule_id UUID REFERENCES routing_rules(id),\n    assigned_team_id UUID REFERENCES teams(id),\n    acknowledged_by UUID REFERENCES users(id),\n    acknowledged_at TIMESTAMP NULL,\n    resolved_by UUID REFERENCES users(id),\n    resolved_at TIMESTAMP NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    expires_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_alerts_fingerprint ON alerts(fingerprint);\nCREATE INDEX idx_alerts_status ON alerts(status);\nCREATE INDEX idx_alerts_severity ON alerts(severity);\nCREATE INDEX idx_alerts_team ON alerts(assigned_team_id);\nCREATE INDEX idx_alerts_created_at ON alerts(created_at DESC);\nCREATE INDEX idx_alerts_labels ON alerts USING GIN(labels);\n```\n\n#### 6. alert_notifications\n```sql\nCREATE TABLE alert_notifications (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    alert_id UUID NOT NULL REFERENCES alerts(id) ON DELETE CASCADE,\n    channel VARCHAR(50) NOT NULL, -- 'email', 'slack', 'pagerduty'\n    recipient VARCHAR(255) NOT NULL,\n    status VARCHAR(50) DEFAULT 'pending', -- 'pending', 'sent', 'failed', 'delivered'\n    attempt_count INTEGER DEFAULT 0,\n    last_attempt_at TIMESTAMP NULL,\n    sent_at TIMESTAMP NULL,\n    delivered_at TIMESTAMP NULL,\n    failed_at TIMESTAMP NULL,\n    error_message TEXT,\n    external_id VARCHAR(255),\n    metadata JSONB,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_notifications_alert_id ON alert_notifications(alert_id);\nCREATE INDEX idx_notifications_status ON alert_notifications(status);\nCREATE INDEX idx_notifications_channel ON alert_notifications(channel);\n```\n\n#### 7. escalation_policies\n```sql\nCREATE TABLE escalation_policies (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    team_id UUID REFERENCES teams(id) ON DELETE CASCADE,\n    enabled BOOLEAN DEFAULT true,\n    levels JSONB NOT NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_escalation_policies_team ON escalation_policies(team_id);\n```\n\nExample `levels` JSONB structure:\n```json\n[\n    {\n        \"level\": 1,\n        \"timeout_minutes\": 15,\n        \"target_team_id\": \"uuid\",\n        \"channels\": [\"email\", \"slack\"]\n    },\n    {\n        \"level\": 2,\n        \"timeout_minutes\": 30,\n        \"target_team_id\": \"uuid\",\n        \"channels\": [\"pagerduty\"]\n    }\n]\n```\n\n#### 8. escalations\n```sql\nCREATE TABLE escalations (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    alert_id UUID NOT NULL REFERENCES alerts(id) ON DELETE CASCADE,\n    policy_id UUID NOT NULL REFERENCES escalation_policies(id),\n    current_level INTEGER DEFAULT 1,\n    max_level INTEGER NOT NULL,\n    status VARCHAR(50) DEFAULT 'active', -- 'active', 'completed', 'cancelled'\n    next_escalation_at TIMESTAMP,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_escalations_alert ON escalations(alert_id);\nCREATE INDEX idx_escalations_status ON escalations(status);\nCREATE INDEX idx_escalations_next ON escalations(next_escalation_at);\n```\n\n#### 9. audit_logs\n```sql\nCREATE TABLE audit_logs (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    entity_type VARCHAR(100) NOT NULL,\n    entity_id UUID NOT NULL,\n    action VARCHAR(100) NOT NULL,\n    user_id UUID REFERENCES users(id),\n    changes JSONB,\n    metadata JSONB,\n    ip_address VARCHAR(45),\n    user_agent TEXT,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_audit_logs_entity ON audit_logs(entity_type, entity_id);\nCREATE INDEX idx_audit_logs_user ON audit_logs(user_id);\nCREATE INDEX idx_audit_logs_created_at ON audit_logs(created_at DESC);\n```\n\n### Prisma Schema\n\n```prisma\ngenerator client {\n  provider = \"prisma-client-js\"\n}\n\ndatasource db {\n  provider = \"postgresql\"\n  url      = env(\"DATABASE_URL\")\n}\n\nmodel User {\n  id           String   @id @default(uuid()) @db.Uuid\n  email        String   @unique @db.VarChar(255)\n  username     String   @unique @db.VarChar(100)\n  passwordHash String   @map(\"password_hash\") @db.VarChar(255)\n  fullName     String?  @map(\"full_name\") @db.VarChar(255)\n  phone        String?  @db.VarChar(50)\n  role         String   @default(\"user\") @db.VarChar(50)\n  createdAt    DateTime @default(now()) @map(\"created_at\")\n  updatedAt    DateTime @updatedAt @map(\"updated_at\")\n  deletedAt    DateTime? @map(\"deleted_at\")\n\n  teamMembers         TeamMember[]\n  acknowledgedAlerts  Alert[]       @relation(\"AcknowledgedBy\")\n  resolvedAlerts      Alert[]       @relation(\"ResolvedBy\")\n  auditLogs           AuditLog[]\n\n  @@index([email])\n  @@index([deletedAt])\n  @@map(\"users\")\n}\n\nmodel Team {\n  id                 String    @id @default(uuid()) @db.Uuid\n  name               String    @db.VarChar(255)\n  description        String?   @db.Text\n  email              String?   @db.VarChar(255)\n  slackChannelId     String?   @map(\"slack_channel_id\") @db.VarChar(100)\n  pagerdutyServiceId String?   @map(\"pagerduty_service_id\") @db.VarChar(100)\n  createdAt          DateTime  @default(now()) @map(\"created_at\")\n  updatedAt          DateTime  @updatedAt @map(\"updated_at\")\n  deletedAt          DateTime? @map(\"deleted_at\")\n\n  members            TeamMember[]\n  routingRules       RoutingRule[]\n  alerts             Alert[]\n  escalationPolicies EscalationPolicy[]\n\n  @@index([name])\n  @@map(\"teams\")\n}\n\nmodel TeamMember {\n  id           String    @id @default(uuid()) @db.Uuid\n  teamId       String    @map(\"team_id\") @db.Uuid\n  userId       String    @map(\"user_id\") @db.Uuid\n  role         String    @default(\"member\") @db.VarChar(50)\n  isOnCall     Boolean   @default(false) @map(\"is_on_call\")\n  onCallStart  DateTime? @map(\"on_call_start\")\n  onCallEnd    DateTime? @map(\"on_call_end\")\n  createdAt    DateTime  @default(now()) @map(\"created_at\")\n\n  team Team @relation(fields: [teamId], references: [id], onDelete: Cascade)\n  user User @relation(fields: [userId], references: [id], onDelete: Cascade)\n\n  @@unique([teamId, userId])\n  @@index([teamId])\n  @@index([userId])\n  @@index([isOnCall])\n  @@map(\"team_members\")\n}\n\nmodel RoutingRule {\n  id                   String    @id @default(uuid()) @db.Uuid\n  name                 String    @db.VarChar(255)\n  description          String?   @db.Text\n  priority             Int       @default(0)\n  enabled              Boolean   @default(true)\n  matchType            String    @map(\"match_type\") @db.VarChar(50)\n  conditions           Json      @db.JsonB\n  targetTeamId         String?   @map(\"target_team_id\") @db.Uuid\n  notificationChannels Json?     @map(\"notification_channels\") @db.JsonB\n  createdAt            DateTime  @default(now()) @map(\"created_at\")\n  updatedAt            DateTime  @updatedAt @map(\"updated_at\")\n  deletedAt            DateTime? @map(\"deleted_at\")\n\n  targetTeam Team?   @relation(fields: [targetTeamId], references: [id], onDelete: SetNull)\n  alerts     Alert[]\n\n  @@index([priority(sort: Desc)])\n  @@index([enabled])\n  @@map(\"routing_rules\")\n}\n\nmodel Alert {\n  id              String    @id @default(uuid()) @db.Uuid\n  externalId      String?   @map(\"external_id\") @db.VarChar(255)\n  source          String    @db.VarChar(255)\n  title           String    @db.VarChar(500)\n  description     String?   @db.Text\n  severity        String    @db.VarChar(50)\n  priority        Int       @default(0)\n  status          String    @default(\"open\") @db.VarChar(50)\n  fingerprint     String    @db.VarChar(64)\n  labels          Json?     @db.JsonB\n  metadata        Json?     @db.JsonB\n  matchedRuleId   String?   @map(\"matched_rule_id\") @db.Uuid\n  assignedTeamId  String?   @map(\"assigned_team_id\") @db.Uuid\n  acknowledgedBy  String?   @map(\"acknowledged_by\") @db.Uuid\n  acknowledgedAt  DateTime? @map(\"acknowledged_at\")\n  resolvedBy      String?   @map(\"resolved_by\") @db.Uuid\n  resolvedAt      DateTime? @map(\"resolved_at\")\n  createdAt       DateTime  @default(now()) @map(\"created_at\")\n  updatedAt       DateTime  @updatedAt @map(\"updated_at\")\n  expiresAt       DateTime? @map(\"expires_at\")\n\n  matchedRule       RoutingRule?        @relation(fields: [matchedRuleId], references: [id])\n  assignedTeam      Team?               @relation(fields: [assignedTeamId], references: [id])\n  acknowledger      User?               @relation(\"AcknowledgedBy\", fields: [acknowledgedBy], references: [id])\n  resolver          User?               @relation(\"ResolvedBy\", fields: [resolvedBy], references: [id])\n  notifications     AlertNotification[]\n  escalations       Escalation[]\n\n  @@index([fingerprint])\n  @@index([status])\n  @@index([severity])\n  @@index([assignedTeamId])\n  @@index([createdAt(sort: Desc)])\n  @@map(\"alerts\")\n}\n\nmodel AlertNotification {\n  id            String    @id @default(uuid()) @db.Uuid\n  alertId       String    @map(\"alert_id\") @db.Uuid\n  channel       String    @db.VarChar(50)\n  recipient     String    @db.VarChar(255)\n  status        String    @default(\"pending\") @db.VarChar(50)\n  attemptCount  Int       @default(0) @map(\"attempt_count\")\n  lastAttemptAt DateTime? @map(\"last_attempt_at\")\n  sentAt        DateTime? @map(\"sent_at\")\n  deliveredAt   DateTime? @map(\"delivered_at\")\n  failedAt      DateTime? @map(\"failed_at\")\n  errorMessage  String?   @map(\"error_message\") @db.Text\n  externalId    String?   @map(\"external_id\") @db.VarChar(255)\n  metadata      Json?     @db.JsonB\n  createdAt     DateTime  @default(now()) @map(\"created_at\")\n\n  alert Alert @relation(fields: [alertId], references: [id], onDelete: Cascade)\n\n  @@index([alertId])\n  @@index([status])\n  @@index([channel])\n  @@map(\"alert_notifications\")\n}\n\nmodel EscalationPolicy {\n  id          String    @id @default(uuid()) @db.Uuid\n  name        String    @db.VarChar(255)\n  description String?   @db.Text\n  teamId      String?   @map(\"team_id\") @db.Uuid\n  enabled     Boolean   @default(true)\n  levels      Json      @db.JsonB\n  createdAt   DateTime  @default(now()) @map(\"created_at\")\n  updatedAt   DateTime  @updatedAt @map(\"updated_at\")\n\n  team        Team?        @relation(fields: [teamId], references: [id], onDelete: Cascade)\n  escalations Escalation[]\n\n  @@index([teamId])\n  @@map(\"escalation_policies\")\n}\n\nmodel Escalation {\n  id                String    @id @default(uuid()) @db.Uuid\n  alertId           String    @map(\"alert_id\") @db.Uuid\n  policyId          String    @map(\"policy_id\") @db.Uuid\n  currentLevel      Int       @default(1) @map(\"current_level\")\n  maxLevel          Int       @map(\"max_level\")\n  status            String    @default(\"active\") @db.VarChar(50)\n  nextEscalationAt  DateTime? @map(\"next_escalation_at\")\n  createdAt         DateTime  @default(now()) @map(\"created_at\")\n  updatedAt         DateTime  @updatedAt @map(\"updated_at\")\n\n  alert  Alert            @relation(fields: [alertId], references: [id], onDelete: Cascade)\n  policy EscalationPolicy @relation(fields: [policyId], references: [id])\n\n  @@index([alertId])\n  @@index([status])\n  @@index([nextEscalationAt])\n  @@map(\"escalations\")\n}\n\nmodel AuditLog {\n  id         String   @id @default(uuid()) @db.Uuid\n  entityType String   @map(\"entity_type\") @db.VarChar(100)\n  entityId   String   @map(\"entity_id\") @db.Uuid\n  action     String   @db.VarChar(100)\n  userId     String?  @map(\"user_id\") @db.Uuid\n  changes    Json?    @db.JsonB\n  metadata   Json?    @db.JsonB\n  ipAddress  String?  @map(\"ip_address\") @db.VarChar(45)\n  userAgent  String?  @map(\"user_agent\") @db.Text\n  createdAt  DateTime @default(now()) @map(\"created_at\")\n\n  user User? @relation(fields: [userId], references: [id])\n\n  @@index([entityType, entityId])\n  @@index([userId])\n  @@index([createdAt(sort: Desc)])\n  @@map(\"audit_logs\")\n}\n```\n\n---\n\n## API Endpoints\n\n### Authentication\n\n```\nPOST   /api/auth/register          Register new user\nPOST   /api/auth/login             Login user\nPOST   /api/auth/logout            Logout user\nPOST   /api/auth/refresh           Refresh access token\nGET    /api/auth/me                Get current user\n```\n\n### Alerts\n\n```\nPOST   /api/alerts                 Create alert\nGET    /api/alerts                 List alerts (paginated, filtered)\nGET    /api/alerts/:id             Get alert by ID\nPATCH  /api/alerts/:id             Update alert\nDELETE /api/alerts/:id             Delete alert\nPOST   /api/alerts/:id/acknowledge Acknowledge alert\nPOST   /api/alerts/:id/resolve     Resolve alert\nPOST   /api/alerts/:id/suppress    Suppress alert\nGET    /api/alerts/:id/history     Get alert history\n```\n\n### Teams\n\n```\nPOST   /api/teams                  Create team\nGET    /api/teams                  List teams\nGET    /api/teams/:id              Get team by ID\nPATCH  /api/teams/:id              Update team\nDELETE /api/teams/:id              Delete team\nGET    /api/teams/:id/members      List team members\nPOST   /api/teams/:id/members      Add member to team\nDELETE /api/teams/:id/members/:uid Remove member from team\nPATCH  /api/teams/:id/members/:uid Update member role/on-call status\n```\n\n### Routing Rules\n\n```\nPOST   /api/rules                  Create routing rule\nGET    /api/rules                  List routing rules\nGET    /api/rules/:id              Get rule by ID\nPATCH  /api/rules/:id              Update rule\nDELETE /api/rules/:id              Delete rule\nPOST   /api/rules/:id/enable       Enable rule\nPOST   /api/rules/:id/disable      Disable rule\nPOST   /api/rules/test             Test rule against sample alert\nGET    /api/rules/:id/matches      Get alerts matched by rule\n```\n\n### Escalation Policies\n\n```\nPOST   /api/escalation-policies    Create escalation policy\nGET    /api/escalation-policies    List escalation policies\nGET    /api/escalation-policies/:id Get policy by ID\nPATCH  /api/escalation-policies/:id Update policy\nDELETE /api/escalation-policies/:id Delete policy\n```\n\n### Notifications\n\n```\nGET    /api/notifications          List notifications (paginated)\nGET    /api/notifications/:id      Get notification by ID\nPOST   /api/notifications/:id/retry Retry failed notification\nGET    /api/notifications/stats    Get notification statistics\n```\n\n### Analytics\n\n```\nGET    /api/analytics/overview     Dashboard overview metrics\nGET    /api/analytics/alerts       Alert statistics (by severity, status, team)\nGET    /api/analytics/notifications Notification delivery metrics\nGET    /api/analytics/teams        Team performance metrics\nGET    /api/analytics/response-times Average response times\n```\n\n### Users\n\n```\nGET    /api/users                  List users\nGET    /api/users/:id              Get user by ID\nPATCH  /api/users/:id              Update user\nDELETE /api/users/:id              Delete user\nGET    /api/users/:id/alerts       Get user's assigned alerts\n```\n\n### Audit Logs\n\n```\nGET    /api/audit-logs             List audit logs (filtered, paginated)\nGET    /api/audit-logs/:id         Get audit log by ID\n```\n\n### Request/Response Examples\n\n#### POST /api/alerts\n\n**Request:**\n```json\n{\n  \"source\": \"prometheus\",\n  \"externalId\": \"alert-12345\",\n  \"title\": \"High CPU Usage on prod-server-01\",\n  \"description\": \"CPU usage exceeded 90% threshold for 5 minutes\",\n  \"severity\": \"high\",\n  \"labels\": {\n    \"environment\": \"production\",\n    \"service\": \"api\",\n    \"instance\": \"prod-server-01\"\n  },\n  \"metadata\": {\n    \"metric\": \"cpu_usage_percent\",\n    \"threshold\": 90,\n    \"current_value\": 95.3\n  }\n}\n```\n\n**Response (201 Created):**\n```json\n{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"source\": \"prometheus\",\n  \"externalId\": \"alert-12345\",\n  \"title\": \"High CPU Usage on prod-server-01\",\n  \"description\": \"CPU usage exceeded 90% threshold for 5 minutes\",\n  \"severity\": \"high\",\n  \"priority\": 80,\n  \"status\": \"open\",\n  \"fingerprint\": \"abc123def456...\",\n  \"matchedRuleId\": \"660e8400-e29b-41d4-a716-446655440001\",\n  \"assignedTeamId\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"createdAt\": \"2025-11-18T10:30:00Z\",\n  \"updatedAt\": \"2025-11-18T10:30:00Z\"\n}\n```\n\n#### POST /api/rules\n\n**Request:**\n```json\n{\n  \"name\": \"Production Critical Alerts\",\n  \"description\": \"Route all critical alerts from production to Platform team\",\n  \"priority\": 100,\n  \"enabled\": true,\n  \"matchType\": \"all\",\n  \"conditions\": {\n    \"severity\": [\"critical\"],\n    \"labels\": {\n      \"environment\": \"production\"\n    }\n  },\n  \"targetTeamId\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"notificationChannels\": [\"email\", \"slack\", \"pagerduty\"]\n}\n```\n\n---\n\n## Implementation Phases\n\n### Phase 1: Foundation (Weeks 1-2)\n\n**Goals**: Set up project structure, database, and core services\n\n**Tasks**:\n1. Initialize project structure\n   - Set up TypeScript + Express + Prisma\n   - Configure ESLint, Prettier, ts-jest\n   - Create Docker Compose for local development\n   - Set up environment configuration with unifiedConfig\n\n2. Database setup\n   - Create Prisma schema\n   - Initial migrations\n   - Seed data for testing\n\n3. Authentication service\n   - User registration and login\n   - JWT token generation and verification\n   - Password hashing with bcrypt\n   - Auth middleware\n\n4. Base infrastructure\n   - BaseController implementation\n   - Error handling middleware\n   - Sentry initialization\n   - Winston logging setup\n   - Request validation middleware (Zod)\n\n**Deliverables**:\n- Working authentication system\n- Database with initial schema\n- Base project structure following best practices\n\n### Phase 2: Alert Management (Weeks 3-4)\n\n**Goals**: Implement core alert ingestion and management\n\n**Tasks**:\n1. Alert ingestion API\n   - POST /api/alerts endpoint\n   - Request validation with Zod schemas\n   - AlertController and AlertService\n   - AlertRepository for database access\n\n2. Deduplication service\n   - Fingerprint generation (SHA-256 hash of key fields)\n   - Redis-based deduplication cache\n   - Time-window based duplicate detection\n   - Alert merging logic\n\n3. Alert CRUD operations\n   - List alerts with filtering and pagination\n   - Get alert by ID\n   - Update alert status\n   - Delete alert\n\n4. Alert actions\n   - Acknowledge alert\n   - Resolve alert\n   - Suppress alert\n   - Alert history tracking\n\n**Deliverables**:\n- Functional alert ingestion API\n- Deduplication working with Redis\n- Complete alert management endpoints\n\n### Phase 3: Team Management (Week 5)\n\n**Goals**: Implement team and user management\n\n**Tasks**:\n1. Team CRUD operations\n   - TeamController, TeamService, TeamRepository\n   - Create, read, update, delete teams\n   - Team member management\n\n2. On-call scheduling\n   - Add/remove on-call status\n   - On-call rotation logic\n   - Get current on-call user for team\n\n3. User management\n   - User profile management\n   - Team assignments\n   - Role management\n\n**Deliverables**:\n- Team management API\n- On-call scheduling system\n- User profile management\n\n### Phase 4: Routing Engine (Week 6)\n\n**Goals**: Implement intelligent routing based on rules\n\n**Tasks**:\n1. Routing rule management\n   - RoutingRuleController, RoutingRuleService\n   - CRUD operations for rules\n   - Rule priority ordering\n\n2. Routing engine\n   - Rule evaluation logic\n   - Pattern matching (all, any, regex)\n   - Label-based matching\n   - Team assignment based on matched rules\n\n3. Rule testing\n   - Test rule endpoint\n   - Dry-run mode\n   - Match statistics\n\n**Deliverables**:\n- Routing rule management API\n- Working routing engine\n- Rule testing functionality\n\n### Phase 5: Notification Channels (Weeks 7-8)\n\n**Goals**: Implement multi-channel notification delivery\n\n**Tasks**:\n1. Channel abstraction\n   - NotificationChannel interface\n   - ChannelManager for channel selection\n   - NotificationService\n\n2. Email provider\n   - Nodemailer integration\n   - Email templates (Handlebars)\n   - HTML and text versions\n   - SMTP configuration\n\n3. Slack provider\n   - @slack/web-api integration\n   - Channel and DM message posting\n   - Alert formatting for Slack\n   - Webhook support\n\n4. PagerDuty provider\n   - @pagerduty/pdjs integration\n   - Incident creation\n   - Severity mapping\n   - Incident acknowledgment and resolution sync\n\n5. Delivery tracking\n   - NotificationRepository\n   - Status tracking (pending, sent, delivered, failed)\n   - Retry logic with exponential backoff\n   - Delivery statistics\n\n**Deliverables**:\n- Email notification working\n- Slack integration complete\n- PagerDuty integration complete\n- Delivery tracking and retry logic\n\n### Phase 6: Escalation System (Week 9)\n\n**Goals**: Implement escalation policies and monitoring\n\n**Tasks**:\n1. Escalation policy management\n   - EscalationPolicyController, EscalationPolicyService\n   - CRUD operations\n   - Multi-level escalation configuration\n\n2. Escalation monitoring\n   - Background job with Bull queue\n   - Monitor unacknowledged alerts\n   - Trigger escalation based on timeout\n\n3. Escalation execution\n   - EscalationService\n   - Level progression\n   - Re-routing to escalation teams\n   - Notification to escalation contacts\n\n**Deliverables**:\n- Escalation policy management\n- Working escalation monitoring job\n- Automatic escalation execution\n\n### Phase 7: Analytics & Reporting (Week 10)\n\n**Goals**: Implement analytics dashboard and metrics\n\n**Tasks**:\n1. Analytics service\n   - AnalyticsController, AnalyticsService\n   - Aggregate queries for statistics\n\n2. Metrics endpoints\n   - Overview dashboard metrics\n   - Alert statistics (by severity, status, team)\n   - Notification delivery metrics\n   - Team performance metrics\n   - Response time calculations\n\n3. Time-series data\n   - Redis-based metric caching\n   - Hourly/daily aggregations\n   - Historical trend data\n\n**Deliverables**:\n- Analytics API endpoints\n- Dashboard overview metrics\n- Historical reporting\n\n### Phase 8: Frontend Dashboard (Weeks 11-12)\n\n**Goals**: Build React dashboard for system management\n\n**Tasks**:\n1. Project setup\n   - Vite + React + TypeScript\n   - MUI v7 component library\n   - TanStack Router and Query\n   - API client with Axios\n\n2. Authentication UI\n   - Login page\n   - Registration page\n   - Protected routes\n\n3. Alert management UI\n   - Alert list with DataGrid\n   - Alert details page\n   - Acknowledge/resolve actions\n   - Create alert form\n\n4. Team management UI\n   - Team list\n   - Team details with members\n   - Add/remove members\n   - On-call schedule UI\n\n5. Routing rules UI\n   - Rule list\n   - Rule editor\n   - Rule testing interface\n   - Enable/disable rules\n\n6. Analytics dashboard\n   - Overview metrics cards\n   - Charts for alert trends\n   - Notification delivery stats\n   - Team performance dashboard\n\n**Deliverables**:\n- Fully functional React dashboard\n- All CRUD operations available in UI\n- Analytics visualizations\n\n### Phase 9: Testing & Quality (Week 13)\n\n**Goals**: Comprehensive testing coverage\n\n**Tasks**:\n1. Unit tests\n   - Service layer tests\n   - Repository tests\n   - Utility function tests\n   - Target: 80%+ coverage\n\n2. Integration tests\n   - API endpoint tests with Supertest\n   - Database integration tests\n   - Redis integration tests\n\n3. End-to-end tests\n   - Alert ingestion flow\n   - Routing and notification flow\n   - Escalation flow\n\n4. Load testing\n   - Alert ingestion performance\n   - Concurrent notification delivery\n   - Database query optimization\n\n**Deliverables**:\n- Test suite with 80%+ coverage\n- Integration and E2E tests\n- Performance benchmarks\n\n### Phase 10: Deployment & Documentation (Week 14)\n\n**Goals**: Production deployment and documentation\n\n**Tasks**:\n1. Docker containerization\n   - Multi-stage Dockerfile\n   - Docker Compose for production\n   - Environment variable management\n\n2. CI/CD pipeline\n   - GitHub Actions workflow\n   - Automated testing\n   - Docker image builds\n   - Deployment automation\n\n3. Infrastructure setup\n   - Cloud provider setup (AWS/GCP/Azure)\n   - PostgreSQL database\n   - Redis instance\n   - Load balancer configuration\n\n4. Monitoring and alerting\n   - Sentry error tracking\n   - Application metrics\n   - Database monitoring\n   - Alert on system failures\n\n5. Documentation\n   - API documentation (OpenAPI/Swagger)\n   - Deployment guide\n   - User guide\n   - Architecture documentation\n\n**Deliverables**:\n- Production-ready deployment\n- CI/CD pipeline\n- Complete documentation\n\n---\n\n## Security Considerations\n\n### Authentication & Authorization\n\n1. **JWT tokens**\n   - Short-lived access tokens (15 minutes)\n   - Refresh tokens (7 days)\n   - Token rotation on refresh\n\n2. **Password security**\n   - bcrypt hashing with salt rounds >= 12\n   - Minimum password requirements (8+ chars, complexity)\n   - Password reset flow with time-limited tokens\n\n3. **Role-based access control (RBAC)**\n   - Roles: admin, manager, user\n   - Team-level permissions\n   - API endpoint authorization\n\n### API Security\n\n1. **Rate limiting**\n   - Per-IP rate limits\n   - Per-user rate limits\n   - Different limits for authenticated vs. unauthenticated\n\n2. **Input validation**\n   - Zod schema validation for all inputs\n   - SQL injection prevention (Prisma parameterized queries)\n   - XSS prevention (sanitize outputs)\n\n3. **CORS configuration**\n   - Whitelist allowed origins\n   - Credentials support for cookies\n\n### Data Security\n\n1. **Encryption**\n   - TLS/SSL for all API traffic\n   - Encrypted database connections\n   - Encrypted secrets storage\n\n2. **Secret management**\n   - API keys in environment variables\n   - Never commit secrets to Git\n   - Rotate secrets regularly\n\n3. **Audit logging**\n   - Log all sensitive operations\n   - Track user actions\n   - Immutable audit trail\n\n### Notification Security\n\n1. **Webhook verification**\n   - HMAC signature verification for Slack webhooks\n   - PagerDuty webhook authentication\n\n2. **Sensitive data handling**\n   - Redact sensitive information in notifications\n   - Secure storage of API tokens\n\n### Infrastructure Security\n\n1. **Network security**\n   - Private VPC for backend services\n   - Firewall rules\n   - Security groups\n\n2. **Container security**\n   - Minimal base images\n   - Regular security updates\n   - Vulnerability scanning\n\n---\n\n## Scalability & Performance\n\n### Horizontal Scaling\n\n1. **Stateless API servers**\n   - No session state in application\n   - JWT-based authentication\n   - Load balancer distribution\n\n2. **Worker processes**\n   - Bull queue for background jobs\n   - Multiple worker instances\n   - Job distribution across workers\n\n### Database Optimization\n\n1. **Indexing**\n   - Indexes on frequently queried fields\n   - Composite indexes for complex queries\n   - Regular index analysis\n\n2. **Query optimization**\n   - Use Prisma's `select` for partial data\n   - Batch queries where possible\n   - Avoid N+1 queries\n\n3. **Connection pooling**\n   - PgBouncer for PostgreSQL\n   - Prisma connection pool configuration\n\n### Caching Strategy\n\n1. **Redis caching**\n   - Deduplication cache (short TTL: 5 minutes)\n   - Routing rule cache (TTL: 10 minutes)\n   - Team member cache (TTL: 5 minutes)\n   - Analytics cache (TTL: 1 minute)\n\n2. **Cache invalidation**\n   - On data updates\n   - Time-based expiration\n   - Manual cache clearing endpoint\n\n### Queue Management\n\n1. **Priority queues**\n   - Separate queues by priority\n   - Critical alerts processed first\n   - Rate limiting per priority level\n\n2. **Queue monitoring**\n   - Queue length metrics\n   - Processing time metrics\n   - Failed job tracking\n\n### Performance Metrics\n\n1. **Target metrics**\n   - Alert ingestion: < 100ms (p95)\n   - Notification delivery: < 5 seconds (p95)\n   - API response time: < 200ms (p95)\n   - Database query time: < 50ms (p95)\n\n2. **Monitoring**\n   - Sentry performance monitoring\n   - Custom metrics with Prometheus\n   - Alerts on performance degradation\n\n---\n\n## Future Enhancements\n\n### Phase 11+\n\n1. **Additional notification channels**\n   - Microsoft Teams\n   - SMS via Twilio\n   - Webhook callbacks\n\n2. **Advanced routing**\n   - Machine learning-based routing\n   - Historical pattern analysis\n   - Smart team suggestions\n\n3. **Alert correlation**\n   - Automatic incident grouping\n   - Root cause analysis\n   - Impact assessment\n\n4. **Mobile app**\n   - iOS and Android apps\n   - Push notifications\n   - On-call management\n\n5. **Integration marketplace**\n   - Plugin system\n   - Custom channel adapters\n   - Third-party integrations\n\n6. **Advanced analytics**\n   - MTTR (Mean Time To Resolution) tracking\n   - Team burnout indicators\n   - Predictive alerting\n\n---\n\n## Conclusion\n\nThis development plan provides a comprehensive roadmap for building a production-grade Alert Notification Router system. The phased approach allows for incremental delivery of value while maintaining code quality and following best practices.\n\n**Key Success Factors**:\n- Follow layered architecture principles\n- Comprehensive testing at all phases\n- Security-first approach\n- Performance monitoring from day one\n- Clear documentation throughout\n\n**Timeline**: 14 weeks for MVP with core features\n**Team Size**: 2-3 full-stack developers\n**Tech Expertise Required**: Node.js, TypeScript, React, PostgreSQL, Redis\n"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2091,"cache_read_input_tokens":38901,"cache_creation":{"ephemeral_5m_input_tokens":2091,"ephemeral_1h_input_tokens":0},"output_tokens":11436,"service_tier":"standard"}},"requestId":"req_011CVFUpfuFSYKJmyyu61zp4","type":"assistant","uuid":"b7c6fe72-5c57-4f78-bd73-9527cc208ec2","timestamp":"2025-11-18T14:06:33.211Z"}
{"parentUuid":"b7c6fe72-5c57-4f78-bd73-9527cc208ec2","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0177Pu4KWpaX2iiFgQLNndP9","type":"tool_result","content":"","is_error":false}]},"uuid":"29b4297d-514d-43fb-928f-7bdd60f55d5c","timestamp":"2025-11-18T14:06:34.697Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"type":"file-history-snapshot","messageId":"b7c6fe72-5c57-4f78-bd73-9527cc208ec2","snapshot":{"messageId":"a89c95da-4d38-4a9b-a8a1-8baeb5e10eb6","trackedFileBackups":{"docs/plan/DevelopmentPlan.md":{"backupFileName":null,"version":1,"backupTime":"2025-11-18T14:06:34.807Z"}},"timestamp":"2025-11-18T14:01:07.522Z"},"isSnapshotUpdate":true}
{"parentUuid":"29b4297d-514d-43fb-928f-7bdd60f55d5c","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MQfjhztMewXBLa43eNpXEq","type":"tool_result","content":"File created successfully at: /root/Claude/claude-hooks/docs/plan/DevelopmentPlan.md"}]},"uuid":"0091a8b6-61c5-4823-a931-ef2134607f70","timestamp":"2025-11-18T14:06:35.808Z","toolUseResult":{"type":"create","filePath":"/root/Claude/claude-hooks/docs/plan/DevelopmentPlan.md","content":"# Alert Notification Router - Development Plan\n\n## Table of Contents\n\n1. [System Overview](#system-overview)\n2. [Architecture](#architecture)\n3. [Tech Stack](#tech-stack)\n4. [Database Schema](#database-schema)\n5. [API Endpoints](#api-endpoints)\n6. [Implementation Phases](#implementation-phases)\n7. [Security Considerations](#security-considerations)\n8. [Scalability & Performance](#scalability--performance)\n\n---\n\n## System Overview\n\n### Purpose\n\nThe Alert Notification Router is an intelligent alert distribution system that routes alerts to appropriate teams based on configurable rules and escalation policies. It provides multi-channel delivery, deduplication, priority handling, and comprehensive delivery tracking.\n\n### Key Features\n\n- **Intelligent Routing**: Rule-based routing engine with pattern matching\n- **Multi-Channel Support**: Email, Slack, PagerDuty integration\n- **Alert Deduplication**: Prevents duplicate notifications within configurable time windows\n- **Priority Handling**: Supports critical, high, medium, low priority levels\n- **Escalation Policies**: Automatic escalation after timeout periods\n- **Delivery Tracking**: Comprehensive audit trail and status tracking\n- **Team Management**: Flexible team and user management with role-based access\n- **Analytics Dashboard**: Real-time metrics and historical reporting\n\n---\n\n## Architecture\n\n### High-Level Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Alert Sources  â”‚\nâ”‚  (External APIs)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚         API Gateway Layer               â”‚\nâ”‚  - Authentication & Authorization       â”‚\nâ”‚  - Rate Limiting                        â”‚\nâ”‚  - Request Validation (Zod)            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      Alert Processing Service           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Ingestion Controller            â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Deduplication Service           â”‚   â”‚\nâ”‚  â”‚  - Hash generation               â”‚   â”‚\nâ”‚  â”‚  - Similarity checking           â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Routing Engine                  â”‚   â”‚\nâ”‚  â”‚  - Rule evaluation               â”‚   â”‚\nâ”‚  â”‚  - Team matching                 â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Priority Queue                  â”‚   â”‚\nâ”‚  â”‚  - Priority-based scheduling     â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n              â”‚\n              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚    Notification Delivery Service         â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Channel Manager                 â”‚   â”‚\nâ”‚  â”‚  - Email Provider                â”‚   â”‚\nâ”‚  â”‚  - Slack Provider                â”‚   â”‚\nâ”‚  â”‚  - PagerDuty Provider            â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚             â”‚                           â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  Delivery Tracker                â”‚   â”‚\nâ”‚  â”‚  - Status updates                â”‚   â”‚\nâ”‚  â”‚  - Retry logic                   â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n              â”‚\n              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Escalation Service                   â”‚\nâ”‚  - Monitors unacknowledged alerts       â”‚\nâ”‚  - Triggers escalation policies         â”‚\nâ”‚  - Re-routes to escalation teams        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Layered Architecture\n\nFollowing backend best practices:\n\n```\nRoutes Layer\n    â†“\nControllers Layer (BaseController)\n    â†“\nServices Layer (Business Logic)\n    â†“\nRepositories Layer (Data Access)\n    â†“\nDatabase (Prisma)\n```\n\n### Component Breakdown\n\n#### 1. Alert Processing Service\n- **Ingestion Controller**: Receives and validates incoming alerts\n- **Deduplication Service**: Identifies and merges duplicate alerts\n- **Routing Engine**: Evaluates rules and determines target teams\n- **Priority Queue**: Manages alert processing order\n\n#### 2. Notification Delivery Service\n- **Channel Manager**: Abstracts notification channel implementations\n- **Email Provider**: Sends emails via SMTP/SendGrid\n- **Slack Provider**: Posts messages to Slack channels/users\n- **PagerDuty Provider**: Creates incidents in PagerDuty\n- **Delivery Tracker**: Monitors delivery status and retries\n\n#### 3. Escalation Service\n- **Escalation Monitor**: Background job checking unacknowledged alerts\n- **Policy Executor**: Applies escalation rules\n- **Re-routing Logic**: Sends alerts to escalation teams\n\n#### 4. Configuration Service\n- **Rule Management**: CRUD operations for routing rules\n- **Team Management**: Manages teams, users, and on-call schedules\n- **Policy Management**: Escalation policy configuration\n\n---\n\n## Tech Stack\n\n### Backend\n\n**Core Framework**\n- **Node.js** v20+ (LTS)\n- **TypeScript** v5+\n- **Express.js** v4+ (API framework)\n\n**Database**\n- **PostgreSQL** v15+ (Primary database)\n- **Redis** v7+ (Caching, deduplication, queue management)\n\n**ORM & Database Tools**\n- **Prisma** v5+ (ORM and migrations)\n- **PrismaClient** (Type-safe database access)\n\n**Validation & Type Safety**\n- **Zod** v3+ (Runtime validation and DTO schemas)\n- **TypeScript** (Compile-time type safety)\n\n**Error Tracking & Monitoring**\n- **Sentry** v8+ (Error tracking and performance monitoring)\n- **Winston** (Structured logging)\n\n**Authentication & Authorization**\n- **JWT** (JSON Web Tokens)\n- **bcrypt** (Password hashing)\n\n**Queue & Background Jobs**\n- **Bull** v4+ (Redis-based queue)\n- **node-cron** (Scheduled jobs)\n\n**Notification Channels**\n- **Nodemailer** (Email delivery)\n- **@slack/web-api** (Slack integration)\n- **@pagerduty/pdjs** (PagerDuty integration)\n\n**Testing**\n- **Jest** (Unit and integration tests)\n- **Supertest** (API endpoint testing)\n- **ts-jest** (TypeScript support)\n\n**Development Tools**\n- **ESLint** (Code linting)\n- **Prettier** (Code formatting)\n- **tsx** (TypeScript execution)\n- **nodemon** (Development auto-reload)\n\n### Frontend (Optional Dashboard)\n\n**Core Framework**\n- **React** v18+\n- **TypeScript** v5+\n- **Vite** v5+ (Build tool)\n\n**UI Framework**\n- **Material-UI (MUI)** v7+ (Component library)\n\n**Data Fetching**\n- **TanStack Query** v5+ (useSuspenseQuery pattern)\n- **Axios** (HTTP client)\n\n**Routing**\n- **TanStack Router** v1+ (File-based routing)\n\n**State Management**\n- **React Context** (Global state)\n- **TanStack Query** (Server state)\n\n**Forms & Validation**\n- **React Hook Form** v7+\n- **Zod** (Form validation)\n\n### Infrastructure\n\n**Containerization**\n- **Docker** (Container runtime)\n- **Docker Compose** (Local development)\n\n**CI/CD**\n- **GitHub Actions** (Automated testing and deployment)\n\n**Deployment**\n- **AWS/GCP/Azure** (Cloud infrastructure)\n- **Kubernetes** (Container orchestration - optional)\n\n---\n\n## Database Schema\n\n### Core Tables\n\n#### 1. users\n```sql\nCREATE TABLE users (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    email VARCHAR(255) UNIQUE NOT NULL,\n    username VARCHAR(100) UNIQUE NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    full_name VARCHAR(255),\n    phone VARCHAR(50),\n    role VARCHAR(50) DEFAULT 'user',\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_deleted_at ON users(deleted_at);\n```\n\n#### 2. teams\n```sql\nCREATE TABLE teams (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    email VARCHAR(255),\n    slack_channel_id VARCHAR(100),\n    pagerduty_service_id VARCHAR(100),\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_teams_name ON teams(name);\n```\n\n#### 3. team_members\n```sql\nCREATE TABLE team_members (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    team_id UUID NOT NULL REFERENCES teams(id) ON DELETE CASCADE,\n    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n    role VARCHAR(50) DEFAULT 'member',\n    is_on_call BOOLEAN DEFAULT false,\n    on_call_start TIMESTAMP NULL,\n    on_call_end TIMESTAMP NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    UNIQUE(team_id, user_id)\n);\n\nCREATE INDEX idx_team_members_team_id ON team_members(team_id);\nCREATE INDEX idx_team_members_user_id ON team_members(user_id);\nCREATE INDEX idx_team_members_on_call ON team_members(is_on_call);\n```\n\n#### 4. routing_rules\n```sql\nCREATE TABLE routing_rules (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    priority INTEGER DEFAULT 0,\n    enabled BOOLEAN DEFAULT true,\n    match_type VARCHAR(50) NOT NULL, -- 'all', 'any', 'regex'\n    conditions JSONB NOT NULL,\n    target_team_id UUID REFERENCES teams(id) ON DELETE SET NULL,\n    notification_channels JSONB, -- ['email', 'slack', 'pagerduty']\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    deleted_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_routing_rules_priority ON routing_rules(priority DESC);\nCREATE INDEX idx_routing_rules_enabled ON routing_rules(enabled);\nCREATE INDEX idx_routing_rules_conditions ON routing_rules USING GIN(conditions);\n```\n\n#### 5. alerts\n```sql\nCREATE TABLE alerts (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    external_id VARCHAR(255),\n    source VARCHAR(255) NOT NULL,\n    title VARCHAR(500) NOT NULL,\n    description TEXT,\n    severity VARCHAR(50) NOT NULL, -- 'critical', 'high', 'medium', 'low'\n    priority INTEGER DEFAULT 0,\n    status VARCHAR(50) DEFAULT 'open', -- 'open', 'acknowledged', 'resolved', 'suppressed'\n    fingerprint VARCHAR(64) NOT NULL,\n    labels JSONB,\n    metadata JSONB,\n    matched_rule_id UUID REFERENCES routing_rules(id),\n    assigned_team_id UUID REFERENCES teams(id),\n    acknowledged_by UUID REFERENCES users(id),\n    acknowledged_at TIMESTAMP NULL,\n    resolved_by UUID REFERENCES users(id),\n    resolved_at TIMESTAMP NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW(),\n    expires_at TIMESTAMP NULL\n);\n\nCREATE INDEX idx_alerts_fingerprint ON alerts(fingerprint);\nCREATE INDEX idx_alerts_status ON alerts(status);\nCREATE INDEX idx_alerts_severity ON alerts(severity);\nCREATE INDEX idx_alerts_team ON alerts(assigned_team_id);\nCREATE INDEX idx_alerts_created_at ON alerts(created_at DESC);\nCREATE INDEX idx_alerts_labels ON alerts USING GIN(labels);\n```\n\n#### 6. alert_notifications\n```sql\nCREATE TABLE alert_notifications (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    alert_id UUID NOT NULL REFERENCES alerts(id) ON DELETE CASCADE,\n    channel VARCHAR(50) NOT NULL, -- 'email', 'slack', 'pagerduty'\n    recipient VARCHAR(255) NOT NULL,\n    status VARCHAR(50) DEFAULT 'pending', -- 'pending', 'sent', 'failed', 'delivered'\n    attempt_count INTEGER DEFAULT 0,\n    last_attempt_at TIMESTAMP NULL,\n    sent_at TIMESTAMP NULL,\n    delivered_at TIMESTAMP NULL,\n    failed_at TIMESTAMP NULL,\n    error_message TEXT,\n    external_id VARCHAR(255),\n    metadata JSONB,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_notifications_alert_id ON alert_notifications(alert_id);\nCREATE INDEX idx_notifications_status ON alert_notifications(status);\nCREATE INDEX idx_notifications_channel ON alert_notifications(channel);\n```\n\n#### 7. escalation_policies\n```sql\nCREATE TABLE escalation_policies (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    team_id UUID REFERENCES teams(id) ON DELETE CASCADE,\n    enabled BOOLEAN DEFAULT true,\n    levels JSONB NOT NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_escalation_policies_team ON escalation_policies(team_id);\n```\n\nExample `levels` JSONB structure:\n```json\n[\n    {\n        \"level\": 1,\n        \"timeout_minutes\": 15,\n        \"target_team_id\": \"uuid\",\n        \"channels\": [\"email\", \"slack\"]\n    },\n    {\n        \"level\": 2,\n        \"timeout_minutes\": 30,\n        \"target_team_id\": \"uuid\",\n        \"channels\": [\"pagerduty\"]\n    }\n]\n```\n\n#### 8. escalations\n```sql\nCREATE TABLE escalations (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    alert_id UUID NOT NULL REFERENCES alerts(id) ON DELETE CASCADE,\n    policy_id UUID NOT NULL REFERENCES escalation_policies(id),\n    current_level INTEGER DEFAULT 1,\n    max_level INTEGER NOT NULL,\n    status VARCHAR(50) DEFAULT 'active', -- 'active', 'completed', 'cancelled'\n    next_escalation_at TIMESTAMP,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_escalations_alert ON escalations(alert_id);\nCREATE INDEX idx_escalations_status ON escalations(status);\nCREATE INDEX idx_escalations_next ON escalations(next_escalation_at);\n```\n\n#### 9. audit_logs\n```sql\nCREATE TABLE audit_logs (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    entity_type VARCHAR(100) NOT NULL,\n    entity_id UUID NOT NULL,\n    action VARCHAR(100) NOT NULL,\n    user_id UUID REFERENCES users(id),\n    changes JSONB,\n    metadata JSONB,\n    ip_address VARCHAR(45),\n    user_agent TEXT,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX idx_audit_logs_entity ON audit_logs(entity_type, entity_id);\nCREATE INDEX idx_audit_logs_user ON audit_logs(user_id);\nCREATE INDEX idx_audit_logs_created_at ON audit_logs(created_at DESC);\n```\n\n### Prisma Schema\n\n```prisma\ngenerator client {\n  provider = \"prisma-client-js\"\n}\n\ndatasource db {\n  provider = \"postgresql\"\n  url      = env(\"DATABASE_URL\")\n}\n\nmodel User {\n  id           String   @id @default(uuid()) @db.Uuid\n  email        String   @unique @db.VarChar(255)\n  username     String   @unique @db.VarChar(100)\n  passwordHash String   @map(\"password_hash\") @db.VarChar(255)\n  fullName     String?  @map(\"full_name\") @db.VarChar(255)\n  phone        String?  @db.VarChar(50)\n  role         String   @default(\"user\") @db.VarChar(50)\n  createdAt    DateTime @default(now()) @map(\"created_at\")\n  updatedAt    DateTime @updatedAt @map(\"updated_at\")\n  deletedAt    DateTime? @map(\"deleted_at\")\n\n  teamMembers         TeamMember[]\n  acknowledgedAlerts  Alert[]       @relation(\"AcknowledgedBy\")\n  resolvedAlerts      Alert[]       @relation(\"ResolvedBy\")\n  auditLogs           AuditLog[]\n\n  @@index([email])\n  @@index([deletedAt])\n  @@map(\"users\")\n}\n\nmodel Team {\n  id                 String    @id @default(uuid()) @db.Uuid\n  name               String    @db.VarChar(255)\n  description        String?   @db.Text\n  email              String?   @db.VarChar(255)\n  slackChannelId     String?   @map(\"slack_channel_id\") @db.VarChar(100)\n  pagerdutyServiceId String?   @map(\"pagerduty_service_id\") @db.VarChar(100)\n  createdAt          DateTime  @default(now()) @map(\"created_at\")\n  updatedAt          DateTime  @updatedAt @map(\"updated_at\")\n  deletedAt          DateTime? @map(\"deleted_at\")\n\n  members            TeamMember[]\n  routingRules       RoutingRule[]\n  alerts             Alert[]\n  escalationPolicies EscalationPolicy[]\n\n  @@index([name])\n  @@map(\"teams\")\n}\n\nmodel TeamMember {\n  id           String    @id @default(uuid()) @db.Uuid\n  teamId       String    @map(\"team_id\") @db.Uuid\n  userId       String    @map(\"user_id\") @db.Uuid\n  role         String    @default(\"member\") @db.VarChar(50)\n  isOnCall     Boolean   @default(false) @map(\"is_on_call\")\n  onCallStart  DateTime? @map(\"on_call_start\")\n  onCallEnd    DateTime? @map(\"on_call_end\")\n  createdAt    DateTime  @default(now()) @map(\"created_at\")\n\n  team Team @relation(fields: [teamId], references: [id], onDelete: Cascade)\n  user User @relation(fields: [userId], references: [id], onDelete: Cascade)\n\n  @@unique([teamId, userId])\n  @@index([teamId])\n  @@index([userId])\n  @@index([isOnCall])\n  @@map(\"team_members\")\n}\n\nmodel RoutingRule {\n  id                   String    @id @default(uuid()) @db.Uuid\n  name                 String    @db.VarChar(255)\n  description          String?   @db.Text\n  priority             Int       @default(0)\n  enabled              Boolean   @default(true)\n  matchType            String    @map(\"match_type\") @db.VarChar(50)\n  conditions           Json      @db.JsonB\n  targetTeamId         String?   @map(\"target_team_id\") @db.Uuid\n  notificationChannels Json?     @map(\"notification_channels\") @db.JsonB\n  createdAt            DateTime  @default(now()) @map(\"created_at\")\n  updatedAt            DateTime  @updatedAt @map(\"updated_at\")\n  deletedAt            DateTime? @map(\"deleted_at\")\n\n  targetTeam Team?   @relation(fields: [targetTeamId], references: [id], onDelete: SetNull)\n  alerts     Alert[]\n\n  @@index([priority(sort: Desc)])\n  @@index([enabled])\n  @@map(\"routing_rules\")\n}\n\nmodel Alert {\n  id              String    @id @default(uuid()) @db.Uuid\n  externalId      String?   @map(\"external_id\") @db.VarChar(255)\n  source          String    @db.VarChar(255)\n  title           String    @db.VarChar(500)\n  description     String?   @db.Text\n  severity        String    @db.VarChar(50)\n  priority        Int       @default(0)\n  status          String    @default(\"open\") @db.VarChar(50)\n  fingerprint     String    @db.VarChar(64)\n  labels          Json?     @db.JsonB\n  metadata        Json?     @db.JsonB\n  matchedRuleId   String?   @map(\"matched_rule_id\") @db.Uuid\n  assignedTeamId  String?   @map(\"assigned_team_id\") @db.Uuid\n  acknowledgedBy  String?   @map(\"acknowledged_by\") @db.Uuid\n  acknowledgedAt  DateTime? @map(\"acknowledged_at\")\n  resolvedBy      String?   @map(\"resolved_by\") @db.Uuid\n  resolvedAt      DateTime? @map(\"resolved_at\")\n  createdAt       DateTime  @default(now()) @map(\"created_at\")\n  updatedAt       DateTime  @updatedAt @map(\"updated_at\")\n  expiresAt       DateTime? @map(\"expires_at\")\n\n  matchedRule       RoutingRule?        @relation(fields: [matchedRuleId], references: [id])\n  assignedTeam      Team?               @relation(fields: [assignedTeamId], references: [id])\n  acknowledger      User?               @relation(\"AcknowledgedBy\", fields: [acknowledgedBy], references: [id])\n  resolver          User?               @relation(\"ResolvedBy\", fields: [resolvedBy], references: [id])\n  notifications     AlertNotification[]\n  escalations       Escalation[]\n\n  @@index([fingerprint])\n  @@index([status])\n  @@index([severity])\n  @@index([assignedTeamId])\n  @@index([createdAt(sort: Desc)])\n  @@map(\"alerts\")\n}\n\nmodel AlertNotification {\n  id            String    @id @default(uuid()) @db.Uuid\n  alertId       String    @map(\"alert_id\") @db.Uuid\n  channel       String    @db.VarChar(50)\n  recipient     String    @db.VarChar(255)\n  status        String    @default(\"pending\") @db.VarChar(50)\n  attemptCount  Int       @default(0) @map(\"attempt_count\")\n  lastAttemptAt DateTime? @map(\"last_attempt_at\")\n  sentAt        DateTime? @map(\"sent_at\")\n  deliveredAt   DateTime? @map(\"delivered_at\")\n  failedAt      DateTime? @map(\"failed_at\")\n  errorMessage  String?   @map(\"error_message\") @db.Text\n  externalId    String?   @map(\"external_id\") @db.VarChar(255)\n  metadata      Json?     @db.JsonB\n  createdAt     DateTime  @default(now()) @map(\"created_at\")\n\n  alert Alert @relation(fields: [alertId], references: [id], onDelete: Cascade)\n\n  @@index([alertId])\n  @@index([status])\n  @@index([channel])\n  @@map(\"alert_notifications\")\n}\n\nmodel EscalationPolicy {\n  id          String    @id @default(uuid()) @db.Uuid\n  name        String    @db.VarChar(255)\n  description String?   @db.Text\n  teamId      String?   @map(\"team_id\") @db.Uuid\n  enabled     Boolean   @default(true)\n  levels      Json      @db.JsonB\n  createdAt   DateTime  @default(now()) @map(\"created_at\")\n  updatedAt   DateTime  @updatedAt @map(\"updated_at\")\n\n  team        Team?        @relation(fields: [teamId], references: [id], onDelete: Cascade)\n  escalations Escalation[]\n\n  @@index([teamId])\n  @@map(\"escalation_policies\")\n}\n\nmodel Escalation {\n  id                String    @id @default(uuid()) @db.Uuid\n  alertId           String    @map(\"alert_id\") @db.Uuid\n  policyId          String    @map(\"policy_id\") @db.Uuid\n  currentLevel      Int       @default(1) @map(\"current_level\")\n  maxLevel          Int       @map(\"max_level\")\n  status            String    @default(\"active\") @db.VarChar(50)\n  nextEscalationAt  DateTime? @map(\"next_escalation_at\")\n  createdAt         DateTime  @default(now()) @map(\"created_at\")\n  updatedAt         DateTime  @updatedAt @map(\"updated_at\")\n\n  alert  Alert            @relation(fields: [alertId], references: [id], onDelete: Cascade)\n  policy EscalationPolicy @relation(fields: [policyId], references: [id])\n\n  @@index([alertId])\n  @@index([status])\n  @@index([nextEscalationAt])\n  @@map(\"escalations\")\n}\n\nmodel AuditLog {\n  id         String   @id @default(uuid()) @db.Uuid\n  entityType String   @map(\"entity_type\") @db.VarChar(100)\n  entityId   String   @map(\"entity_id\") @db.Uuid\n  action     String   @db.VarChar(100)\n  userId     String?  @map(\"user_id\") @db.Uuid\n  changes    Json?    @db.JsonB\n  metadata   Json?    @db.JsonB\n  ipAddress  String?  @map(\"ip_address\") @db.VarChar(45)\n  userAgent  String?  @map(\"user_agent\") @db.Text\n  createdAt  DateTime @default(now()) @map(\"created_at\")\n\n  user User? @relation(fields: [userId], references: [id])\n\n  @@index([entityType, entityId])\n  @@index([userId])\n  @@index([createdAt(sort: Desc)])\n  @@map(\"audit_logs\")\n}\n```\n\n---\n\n## API Endpoints\n\n### Authentication\n\n```\nPOST   /api/auth/register          Register new user\nPOST   /api/auth/login             Login user\nPOST   /api/auth/logout            Logout user\nPOST   /api/auth/refresh           Refresh access token\nGET    /api/auth/me                Get current user\n```\n\n### Alerts\n\n```\nPOST   /api/alerts                 Create alert\nGET    /api/alerts                 List alerts (paginated, filtered)\nGET    /api/alerts/:id             Get alert by ID\nPATCH  /api/alerts/:id             Update alert\nDELETE /api/alerts/:id             Delete alert\nPOST   /api/alerts/:id/acknowledge Acknowledge alert\nPOST   /api/alerts/:id/resolve     Resolve alert\nPOST   /api/alerts/:id/suppress    Suppress alert\nGET    /api/alerts/:id/history     Get alert history\n```\n\n### Teams\n\n```\nPOST   /api/teams                  Create team\nGET    /api/teams                  List teams\nGET    /api/teams/:id              Get team by ID\nPATCH  /api/teams/:id              Update team\nDELETE /api/teams/:id              Delete team\nGET    /api/teams/:id/members      List team members\nPOST   /api/teams/:id/members      Add member to team\nDELETE /api/teams/:id/members/:uid Remove member from team\nPATCH  /api/teams/:id/members/:uid Update member role/on-call status\n```\n\n### Routing Rules\n\n```\nPOST   /api/rules                  Create routing rule\nGET    /api/rules                  List routing rules\nGET    /api/rules/:id              Get rule by ID\nPATCH  /api/rules/:id              Update rule\nDELETE /api/rules/:id              Delete rule\nPOST   /api/rules/:id/enable       Enable rule\nPOST   /api/rules/:id/disable      Disable rule\nPOST   /api/rules/test             Test rule against sample alert\nGET    /api/rules/:id/matches      Get alerts matched by rule\n```\n\n### Escalation Policies\n\n```\nPOST   /api/escalation-policies    Create escalation policy\nGET    /api/escalation-policies    List escalation policies\nGET    /api/escalation-policies/:id Get policy by ID\nPATCH  /api/escalation-policies/:id Update policy\nDELETE /api/escalation-policies/:id Delete policy\n```\n\n### Notifications\n\n```\nGET    /api/notifications          List notifications (paginated)\nGET    /api/notifications/:id      Get notification by ID\nPOST   /api/notifications/:id/retry Retry failed notification\nGET    /api/notifications/stats    Get notification statistics\n```\n\n### Analytics\n\n```\nGET    /api/analytics/overview     Dashboard overview metrics\nGET    /api/analytics/alerts       Alert statistics (by severity, status, team)\nGET    /api/analytics/notifications Notification delivery metrics\nGET    /api/analytics/teams        Team performance metrics\nGET    /api/analytics/response-times Average response times\n```\n\n### Users\n\n```\nGET    /api/users                  List users\nGET    /api/users/:id              Get user by ID\nPATCH  /api/users/:id              Update user\nDELETE /api/users/:id              Delete user\nGET    /api/users/:id/alerts       Get user's assigned alerts\n```\n\n### Audit Logs\n\n```\nGET    /api/audit-logs             List audit logs (filtered, paginated)\nGET    /api/audit-logs/:id         Get audit log by ID\n```\n\n### Request/Response Examples\n\n#### POST /api/alerts\n\n**Request:**\n```json\n{\n  \"source\": \"prometheus\",\n  \"externalId\": \"alert-12345\",\n  \"title\": \"High CPU Usage on prod-server-01\",\n  \"description\": \"CPU usage exceeded 90% threshold for 5 minutes\",\n  \"severity\": \"high\",\n  \"labels\": {\n    \"environment\": \"production\",\n    \"service\": \"api\",\n    \"instance\": \"prod-server-01\"\n  },\n  \"metadata\": {\n    \"metric\": \"cpu_usage_percent\",\n    \"threshold\": 90,\n    \"current_value\": 95.3\n  }\n}\n```\n\n**Response (201 Created):**\n```json\n{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"source\": \"prometheus\",\n  \"externalId\": \"alert-12345\",\n  \"title\": \"High CPU Usage on prod-server-01\",\n  \"description\": \"CPU usage exceeded 90% threshold for 5 minutes\",\n  \"severity\": \"high\",\n  \"priority\": 80,\n  \"status\": \"open\",\n  \"fingerprint\": \"abc123def456...\",\n  \"matchedRuleId\": \"660e8400-e29b-41d4-a716-446655440001\",\n  \"assignedTeamId\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"createdAt\": \"2025-11-18T10:30:00Z\",\n  \"updatedAt\": \"2025-11-18T10:30:00Z\"\n}\n```\n\n#### POST /api/rules\n\n**Request:**\n```json\n{\n  \"name\": \"Production Critical Alerts\",\n  \"description\": \"Route all critical alerts from production to Platform team\",\n  \"priority\": 100,\n  \"enabled\": true,\n  \"matchType\": \"all\",\n  \"conditions\": {\n    \"severity\": [\"critical\"],\n    \"labels\": {\n      \"environment\": \"production\"\n    }\n  },\n  \"targetTeamId\": \"770e8400-e29b-41d4-a716-446655440002\",\n  \"notificationChannels\": [\"email\", \"slack\", \"pagerduty\"]\n}\n```\n\n---\n\n## Implementation Phases\n\n### Phase 1: Foundation (Weeks 1-2)\n\n**Goals**: Set up project structure, database, and core services\n\n**Tasks**:\n1. Initialize project structure\n   - Set up TypeScript + Express + Prisma\n   - Configure ESLint, Prettier, ts-jest\n   - Create Docker Compose for local development\n   - Set up environment configuration with unifiedConfig\n\n2. Database setup\n   - Create Prisma schema\n   - Initial migrations\n   - Seed data for testing\n\n3. Authentication service\n   - User registration and login\n   - JWT token generation and verification\n   - Password hashing with bcrypt\n   - Auth middleware\n\n4. Base infrastructure\n   - BaseController implementation\n   - Error handling middleware\n   - Sentry initialization\n   - Winston logging setup\n   - Request validation middleware (Zod)\n\n**Deliverables**:\n- Working authentication system\n- Database with initial schema\n- Base project structure following best practices\n\n### Phase 2: Alert Management (Weeks 3-4)\n\n**Goals**: Implement core alert ingestion and management\n\n**Tasks**:\n1. Alert ingestion API\n   - POST /api/alerts endpoint\n   - Request validation with Zod schemas\n   - AlertController and AlertService\n   - AlertRepository for database access\n\n2. Deduplication service\n   - Fingerprint generation (SHA-256 hash of key fields)\n   - Redis-based deduplication cache\n   - Time-window based duplicate detection\n   - Alert merging logic\n\n3. Alert CRUD operations\n   - List alerts with filtering and pagination\n   - Get alert by ID\n   - Update alert status\n   - Delete alert\n\n4. Alert actions\n   - Acknowledge alert\n   - Resolve alert\n   - Suppress alert\n   - Alert history tracking\n\n**Deliverables**:\n- Functional alert ingestion API\n- Deduplication working with Redis\n- Complete alert management endpoints\n\n### Phase 3: Team Management (Week 5)\n\n**Goals**: Implement team and user management\n\n**Tasks**:\n1. Team CRUD operations\n   - TeamController, TeamService, TeamRepository\n   - Create, read, update, delete teams\n   - Team member management\n\n2. On-call scheduling\n   - Add/remove on-call status\n   - On-call rotation logic\n   - Get current on-call user for team\n\n3. User management\n   - User profile management\n   - Team assignments\n   - Role management\n\n**Deliverables**:\n- Team management API\n- On-call scheduling system\n- User profile management\n\n### Phase 4: Routing Engine (Week 6)\n\n**Goals**: Implement intelligent routing based on rules\n\n**Tasks**:\n1. Routing rule management\n   - RoutingRuleController, RoutingRuleService\n   - CRUD operations for rules\n   - Rule priority ordering\n\n2. Routing engine\n   - Rule evaluation logic\n   - Pattern matching (all, any, regex)\n   - Label-based matching\n   - Team assignment based on matched rules\n\n3. Rule testing\n   - Test rule endpoint\n   - Dry-run mode\n   - Match statistics\n\n**Deliverables**:\n- Routing rule management API\n- Working routing engine\n- Rule testing functionality\n\n### Phase 5: Notification Channels (Weeks 7-8)\n\n**Goals**: Implement multi-channel notification delivery\n\n**Tasks**:\n1. Channel abstraction\n   - NotificationChannel interface\n   - ChannelManager for channel selection\n   - NotificationService\n\n2. Email provider\n   - Nodemailer integration\n   - Email templates (Handlebars)\n   - HTML and text versions\n   - SMTP configuration\n\n3. Slack provider\n   - @slack/web-api integration\n   - Channel and DM message posting\n   - Alert formatting for Slack\n   - Webhook support\n\n4. PagerDuty provider\n   - @pagerduty/pdjs integration\n   - Incident creation\n   - Severity mapping\n   - Incident acknowledgment and resolution sync\n\n5. Delivery tracking\n   - NotificationRepository\n   - Status tracking (pending, sent, delivered, failed)\n   - Retry logic with exponential backoff\n   - Delivery statistics\n\n**Deliverables**:\n- Email notification working\n- Slack integration complete\n- PagerDuty integration complete\n- Delivery tracking and retry logic\n\n### Phase 6: Escalation System (Week 9)\n\n**Goals**: Implement escalation policies and monitoring\n\n**Tasks**:\n1. Escalation policy management\n   - EscalationPolicyController, EscalationPolicyService\n   - CRUD operations\n   - Multi-level escalation configuration\n\n2. Escalation monitoring\n   - Background job with Bull queue\n   - Monitor unacknowledged alerts\n   - Trigger escalation based on timeout\n\n3. Escalation execution\n   - EscalationService\n   - Level progression\n   - Re-routing to escalation teams\n   - Notification to escalation contacts\n\n**Deliverables**:\n- Escalation policy management\n- Working escalation monitoring job\n- Automatic escalation execution\n\n### Phase 7: Analytics & Reporting (Week 10)\n\n**Goals**: Implement analytics dashboard and metrics\n\n**Tasks**:\n1. Analytics service\n   - AnalyticsController, AnalyticsService\n   - Aggregate queries for statistics\n\n2. Metrics endpoints\n   - Overview dashboard metrics\n   - Alert statistics (by severity, status, team)\n   - Notification delivery metrics\n   - Team performance metrics\n   - Response time calculations\n\n3. Time-series data\n   - Redis-based metric caching\n   - Hourly/daily aggregations\n   - Historical trend data\n\n**Deliverables**:\n- Analytics API endpoints\n- Dashboard overview metrics\n- Historical reporting\n\n### Phase 8: Frontend Dashboard (Weeks 11-12)\n\n**Goals**: Build React dashboard for system management\n\n**Tasks**:\n1. Project setup\n   - Vite + React + TypeScript\n   - MUI v7 component library\n   - TanStack Router and Query\n   - API client with Axios\n\n2. Authentication UI\n   - Login page\n   - Registration page\n   - Protected routes\n\n3. Alert management UI\n   - Alert list with DataGrid\n   - Alert details page\n   - Acknowledge/resolve actions\n   - Create alert form\n\n4. Team management UI\n   - Team list\n   - Team details with members\n   - Add/remove members\n   - On-call schedule UI\n\n5. Routing rules UI\n   - Rule list\n   - Rule editor\n   - Rule testing interface\n   - Enable/disable rules\n\n6. Analytics dashboard\n   - Overview metrics cards\n   - Charts for alert trends\n   - Notification delivery stats\n   - Team performance dashboard\n\n**Deliverables**:\n- Fully functional React dashboard\n- All CRUD operations available in UI\n- Analytics visualizations\n\n### Phase 9: Testing & Quality (Week 13)\n\n**Goals**: Comprehensive testing coverage\n\n**Tasks**:\n1. Unit tests\n   - Service layer tests\n   - Repository tests\n   - Utility function tests\n   - Target: 80%+ coverage\n\n2. Integration tests\n   - API endpoint tests with Supertest\n   - Database integration tests\n   - Redis integration tests\n\n3. End-to-end tests\n   - Alert ingestion flow\n   - Routing and notification flow\n   - Escalation flow\n\n4. Load testing\n   - Alert ingestion performance\n   - Concurrent notification delivery\n   - Database query optimization\n\n**Deliverables**:\n- Test suite with 80%+ coverage\n- Integration and E2E tests\n- Performance benchmarks\n\n### Phase 10: Deployment & Documentation (Week 14)\n\n**Goals**: Production deployment and documentation\n\n**Tasks**:\n1. Docker containerization\n   - Multi-stage Dockerfile\n   - Docker Compose for production\n   - Environment variable management\n\n2. CI/CD pipeline\n   - GitHub Actions workflow\n   - Automated testing\n   - Docker image builds\n   - Deployment automation\n\n3. Infrastructure setup\n   - Cloud provider setup (AWS/GCP/Azure)\n   - PostgreSQL database\n   - Redis instance\n   - Load balancer configuration\n\n4. Monitoring and alerting\n   - Sentry error tracking\n   - Application metrics\n   - Database monitoring\n   - Alert on system failures\n\n5. Documentation\n   - API documentation (OpenAPI/Swagger)\n   - Deployment guide\n   - User guide\n   - Architecture documentation\n\n**Deliverables**:\n- Production-ready deployment\n- CI/CD pipeline\n- Complete documentation\n\n---\n\n## Security Considerations\n\n### Authentication & Authorization\n\n1. **JWT tokens**\n   - Short-lived access tokens (15 minutes)\n   - Refresh tokens (7 days)\n   - Token rotation on refresh\n\n2. **Password security**\n   - bcrypt hashing with salt rounds >= 12\n   - Minimum password requirements (8+ chars, complexity)\n   - Password reset flow with time-limited tokens\n\n3. **Role-based access control (RBAC)**\n   - Roles: admin, manager, user\n   - Team-level permissions\n   - API endpoint authorization\n\n### API Security\n\n1. **Rate limiting**\n   - Per-IP rate limits\n   - Per-user rate limits\n   - Different limits for authenticated vs. unauthenticated\n\n2. **Input validation**\n   - Zod schema validation for all inputs\n   - SQL injection prevention (Prisma parameterized queries)\n   - XSS prevention (sanitize outputs)\n\n3. **CORS configuration**\n   - Whitelist allowed origins\n   - Credentials support for cookies\n\n### Data Security\n\n1. **Encryption**\n   - TLS/SSL for all API traffic\n   - Encrypted database connections\n   - Encrypted secrets storage\n\n2. **Secret management**\n   - API keys in environment variables\n   - Never commit secrets to Git\n   - Rotate secrets regularly\n\n3. **Audit logging**\n   - Log all sensitive operations\n   - Track user actions\n   - Immutable audit trail\n\n### Notification Security\n\n1. **Webhook verification**\n   - HMAC signature verification for Slack webhooks\n   - PagerDuty webhook authentication\n\n2. **Sensitive data handling**\n   - Redact sensitive information in notifications\n   - Secure storage of API tokens\n\n### Infrastructure Security\n\n1. **Network security**\n   - Private VPC for backend services\n   - Firewall rules\n   - Security groups\n\n2. **Container security**\n   - Minimal base images\n   - Regular security updates\n   - Vulnerability scanning\n\n---\n\n## Scalability & Performance\n\n### Horizontal Scaling\n\n1. **Stateless API servers**\n   - No session state in application\n   - JWT-based authentication\n   - Load balancer distribution\n\n2. **Worker processes**\n   - Bull queue for background jobs\n   - Multiple worker instances\n   - Job distribution across workers\n\n### Database Optimization\n\n1. **Indexing**\n   - Indexes on frequently queried fields\n   - Composite indexes for complex queries\n   - Regular index analysis\n\n2. **Query optimization**\n   - Use Prisma's `select` for partial data\n   - Batch queries where possible\n   - Avoid N+1 queries\n\n3. **Connection pooling**\n   - PgBouncer for PostgreSQL\n   - Prisma connection pool configuration\n\n### Caching Strategy\n\n1. **Redis caching**\n   - Deduplication cache (short TTL: 5 minutes)\n   - Routing rule cache (TTL: 10 minutes)\n   - Team member cache (TTL: 5 minutes)\n   - Analytics cache (TTL: 1 minute)\n\n2. **Cache invalidation**\n   - On data updates\n   - Time-based expiration\n   - Manual cache clearing endpoint\n\n### Queue Management\n\n1. **Priority queues**\n   - Separate queues by priority\n   - Critical alerts processed first\n   - Rate limiting per priority level\n\n2. **Queue monitoring**\n   - Queue length metrics\n   - Processing time metrics\n   - Failed job tracking\n\n### Performance Metrics\n\n1. **Target metrics**\n   - Alert ingestion: < 100ms (p95)\n   - Notification delivery: < 5 seconds (p95)\n   - API response time: < 200ms (p95)\n   - Database query time: < 50ms (p95)\n\n2. **Monitoring**\n   - Sentry performance monitoring\n   - Custom metrics with Prometheus\n   - Alerts on performance degradation\n\n---\n\n## Future Enhancements\n\n### Phase 11+\n\n1. **Additional notification channels**\n   - Microsoft Teams\n   - SMS via Twilio\n   - Webhook callbacks\n\n2. **Advanced routing**\n   - Machine learning-based routing\n   - Historical pattern analysis\n   - Smart team suggestions\n\n3. **Alert correlation**\n   - Automatic incident grouping\n   - Root cause analysis\n   - Impact assessment\n\n4. **Mobile app**\n   - iOS and Android apps\n   - Push notifications\n   - On-call management\n\n5. **Integration marketplace**\n   - Plugin system\n   - Custom channel adapters\n   - Third-party integrations\n\n6. **Advanced analytics**\n   - MTTR (Mean Time To Resolution) tracking\n   - Team burnout indicators\n   - Predictive alerting\n\n---\n\n## Conclusion\n\nThis development plan provides a comprehensive roadmap for building a production-grade Alert Notification Router system. The phased approach allows for incremental delivery of value while maintaining code quality and following best practices.\n\n**Key Success Factors**:\n- Follow layered architecture principles\n- Comprehensive testing at all phases\n- Security-first approach\n- Performance monitoring from day one\n- Clear documentation throughout\n\n**Timeline**: 14 weeks for MVP with core features\n**Team Size**: 2-3 full-stack developers\n**Tech Expertise Required**: Node.js, TypeScript, React, PostgreSQL, Redis\n","structuredPatch":[]}}
{"parentUuid":"0091a8b6-61c5-4823-a931-ef2134607f70","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016gLiwZYX4Ef8vCp6vHVUdV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HPEaUyubXCXzT8Gqwoto5c","name":"TodoWrite","input":{"todos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"completed","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"in_progress","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"pending","activeForm":"Creating Guide.md with user documentation"}]}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":11690,"cache_read_input_tokens":40992,"cache_creation":{"ephemeral_5m_input_tokens":11690,"ephemeral_1h_input_tokens":0},"output_tokens":12965,"service_tier":"standard"}},"requestId":"req_011CVFV2MGQkpMDNhdtbgEqF","type":"assistant","uuid":"007bd84c-e71d-4dca-a6c9-ad3890ae7ad4","timestamp":"2025-11-18T14:06:41.882Z"}
{"parentUuid":"007bd84c-e71d-4dca-a6c9-ad3890ae7ad4","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016gLiwZYX4Ef8vCp6vHVUdV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NfunyUF88SZkirREcTQv57","name":"Write","input":{"file_path":"/root/Claude/claude-hooks/docs/testing/TestingPlan.md","content":"# Alert Notification Router - Testing Plan\n\n## Table of Contents\n\n1. [Testing Strategy Overview](#testing-strategy-overview)\n2. [Testing Objectives](#testing-objectives)\n3. [Test Types & Coverage](#test-types--coverage)\n4. [Unit Testing](#unit-testing)\n5. [Integration Testing](#integration-testing)\n6. [End-to-End Testing](#end-to-end-testing)\n7. [Performance Testing](#performance-testing)\n8. [Security Testing](#security-testing)\n9. [Test Environment Setup](#test-environment-setup)\n10. [Test Data Management](#test-data-management)\n11. [CI/CD Integration](#cicd-integration)\n12. [Test Coverage Goals](#test-coverage-goals)\n13. [Testing Tools & Frameworks](#testing-tools--frameworks)\n\n---\n\n## Testing Strategy Overview\n\n### Philosophy\n\nOur testing strategy follows the **testing pyramid** approach:\n- **70% Unit Tests**: Fast, isolated tests for business logic\n- **20% Integration Tests**: Tests for component interactions\n- **10% E2E Tests**: Critical user flows and scenarios\n\n### Principles\n\n1. **Test-Driven Development (TDD)**: Write tests before implementation when possible\n2. **Fast Feedback**: Tests should run quickly to enable rapid iteration\n3. **Reliable**: Tests should be deterministic and not flaky\n4. **Maintainable**: Tests should be easy to understand and update\n5. **Comprehensive**: Critical paths must have test coverage\n6. **Isolated**: Tests should not depend on external services or each other\n\n---\n\n## Testing Objectives\n\n### Primary Goals\n\n1. **Functional Correctness**: Verify all features work as specified\n2. **Reliability**: Ensure system handles errors gracefully\n3. **Performance**: Meet performance targets (< 100ms alert ingestion, < 5s notification delivery)\n4. **Security**: Validate authentication, authorization, and data protection\n5. **Scalability**: Verify system handles expected load\n6. **Regression Prevention**: Catch bugs before production\n\n### Quality Metrics\n\n- **Code Coverage**: Minimum 80% overall, 90% for critical paths\n- **Test Success Rate**: 100% passing tests before deployment\n- **Test Execution Time**: < 5 minutes for unit tests, < 15 minutes for full suite\n- **Bug Escape Rate**: < 5% of bugs reach production\n- **Mean Time to Detect (MTTD)**: < 1 hour for production issues\n\n---\n\n## Test Types & Coverage\n\n### 1. Unit Tests (70%)\n\n**Scope**: Individual functions, methods, and classes in isolation\n\n**Coverage**:\n- All service layer business logic\n- All repository data access methods\n- Utility functions and helpers\n- Validation schemas (Zod)\n- Error handling logic\n\n**Target Coverage**: 85%+\n\n### 2. Integration Tests (20%)\n\n**Scope**: Interactions between components\n\n**Coverage**:\n- API endpoints (request â†’ controller â†’ service â†’ repository)\n- Database operations (Prisma)\n- Redis caching\n- Queue operations (Bull)\n- External API integrations (mock)\n\n**Target Coverage**: 80%+\n\n### 3. End-to-End Tests (10%)\n\n**Scope**: Complete user workflows\n\n**Coverage**:\n- Alert ingestion â†’ routing â†’ notification flow\n- User authentication and authorization flow\n- Escalation policy execution\n- Team management workflows\n\n**Target Coverage**: Critical paths only\n\n### 4. Performance Tests\n\n**Scope**: System performance under load\n\n**Coverage**:\n- Alert ingestion throughput\n- Concurrent notification delivery\n- Database query performance\n- API response times\n\n### 5. Security Tests\n\n**Scope**: Security vulnerabilities and attack vectors\n\n**Coverage**:\n- Authentication bypass attempts\n- Authorization checks\n- SQL injection\n- XSS attacks\n- Rate limiting\n- Input validation\n\n---\n\n## Unit Testing\n\n### Service Layer Tests\n\nTest business logic in isolation using mocked dependencies.\n\n#### AlertService Tests\n\n**File**: `src/tests/unit/services/alertService.test.ts`\n\n```typescript\nimport { AlertService } from '@/services/alertService';\nimport { AlertRepository } from '@/repositories/AlertRepository';\nimport { DeduplicationService } from '@/services/deduplicationService';\nimport { RoutingService } from '@/services/routingService';\nimport { NotificationService } from '@/services/notificationService';\nimport * as Sentry from '@sentry/node';\n\njest.mock('@/repositories/AlertRepository');\njest.mock('@/services/deduplicationService');\njest.mock('@/services/routingService');\njest.mock('@/services/notificationService');\njest.mock('@sentry/node');\n\ndescribe('AlertService', () => {\n    let alertService: AlertService;\n    let mockAlertRepository: jest.Mocked<AlertRepository>;\n    let mockDeduplicationService: jest.Mocked<DeduplicationService>;\n    let mockRoutingService: jest.Mocked<RoutingService>;\n    let mockNotificationService: jest.Mocked<NotificationService>;\n\n    beforeEach(() => {\n        mockAlertRepository = new AlertRepository() as jest.Mocked<AlertRepository>;\n        mockDeduplicationService = new DeduplicationService() as jest.Mocked<DeduplicationService>;\n        mockRoutingService = new RoutingService() as jest.Mocked<RoutingService>;\n        mockNotificationService = new NotificationService() as jest.Mocked<NotificationService>;\n\n        alertService = new AlertService(\n            mockAlertRepository,\n            mockDeduplicationService,\n            mockRoutingService,\n            mockNotificationService\n        );\n    });\n\n    describe('createAlert', () => {\n        it('should create a new alert when no duplicate exists', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high',\n                labels: { environment: 'production' }\n            };\n\n            mockDeduplicationService.findDuplicate.mockResolvedValue(null);\n            mockRoutingService.findMatchingRule.mockResolvedValue({\n                id: 'rule-1',\n                targetTeamId: 'team-1',\n                notificationChannels: ['email', 'slack']\n            });\n            mockAlertRepository.create.mockResolvedValue({\n                id: 'alert-1',\n                ...alertData,\n                status: 'open',\n                createdAt: new Date()\n            });\n\n            const result = await alertService.createAlert(alertData);\n\n            expect(result).toBeDefined();\n            expect(result.id).toBe('alert-1');\n            expect(mockDeduplicationService.findDuplicate).toHaveBeenCalled();\n            expect(mockRoutingService.findMatchingRule).toHaveBeenCalled();\n            expect(mockNotificationService.sendNotifications).toHaveBeenCalledWith(\n                expect.objectContaining({ id: 'alert-1' }),\n                ['email', 'slack']\n            );\n        });\n\n        it('should merge with existing alert if duplicate found', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high'\n            };\n\n            const existingAlert = {\n                id: 'existing-alert-1',\n                ...alertData,\n                count: 1\n            };\n\n            mockDeduplicationService.findDuplicate.mockResolvedValue(existingAlert);\n            mockAlertRepository.update.mockResolvedValue({\n                ...existingAlert,\n                count: 2\n            });\n\n            const result = await alertService.createAlert(alertData);\n\n            expect(result.id).toBe('existing-alert-1');\n            expect(result.count).toBe(2);\n            expect(mockAlertRepository.create).not.toHaveBeenCalled();\n        });\n\n        it('should handle routing errors gracefully', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high'\n            };\n\n            mockDeduplicationService.findDuplicate.mockResolvedValue(null);\n            mockRoutingService.findMatchingRule.mockRejectedValue(new Error('Routing failed'));\n\n            await expect(alertService.createAlert(alertData)).rejects.toThrow('Routing failed');\n            expect(Sentry.captureException).toHaveBeenCalled();\n        });\n\n        it('should generate correct fingerprint for alert', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high',\n                labels: { instance: 'server-01' }\n            };\n\n            mockDeduplicationService.findDuplicate.mockResolvedValue(null);\n            mockRoutingService.findMatchingRule.mockResolvedValue(null);\n            mockAlertRepository.create.mockImplementation((data) =>\n                Promise.resolve({ id: 'alert-1', ...data, createdAt: new Date() })\n            );\n\n            await alertService.createAlert(alertData);\n\n            expect(mockAlertRepository.create).toHaveBeenCalledWith(\n                expect.objectContaining({\n                    fingerprint: expect.any(String)\n                })\n            );\n        });\n    });\n\n    describe('acknowledgeAlert', () => {\n        it('should acknowledge an open alert', async () => {\n            const alertId = 'alert-1';\n            const userId = 'user-1';\n\n            mockAlertRepository.findById.mockResolvedValue({\n                id: alertId,\n                status: 'open'\n            });\n\n            mockAlertRepository.update.mockResolvedValue({\n                id: alertId,\n                status: 'acknowledged',\n                acknowledgedBy: userId,\n                acknowledgedAt: new Date()\n            });\n\n            const result = await alertService.acknowledgeAlert(alertId, userId);\n\n            expect(result.status).toBe('acknowledged');\n            expect(result.acknowledgedBy).toBe(userId);\n        });\n\n        it('should throw error if alert is already acknowledged', async () => {\n            const alertId = 'alert-1';\n            const userId = 'user-1';\n\n            mockAlertRepository.findById.mockResolvedValue({\n                id: alertId,\n                status: 'acknowledged'\n            });\n\n            await expect(alertService.acknowledgeAlert(alertId, userId)).rejects.toThrow(\n                'Alert is already acknowledged'\n            );\n        });\n\n        it('should throw error if alert not found', async () => {\n            mockAlertRepository.findById.mockResolvedValue(null);\n\n            await expect(alertService.acknowledgeAlert('invalid-id', 'user-1')).rejects.toThrow(\n                'Alert not found'\n            );\n        });\n    });\n\n    describe('resolveAlert', () => {\n        it('should resolve an acknowledged alert', async () => {\n            const alertId = 'alert-1';\n            const userId = 'user-1';\n\n            mockAlertRepository.findById.mockResolvedValue({\n                id: alertId,\n                status: 'acknowledged'\n            });\n\n            mockAlertRepository.update.mockResolvedValue({\n                id: alertId,\n                status: 'resolved',\n                resolvedBy: userId,\n                resolvedAt: new Date()\n            });\n\n            const result = await alertService.resolveAlert(alertId, userId);\n\n            expect(result.status).toBe('resolved');\n            expect(result.resolvedBy).toBe(userId);\n        });\n    });\n});\n```\n\n#### Test Coverage Areas\n\n**Services to Test**:\n- `AlertService`: Create, acknowledge, resolve, suppress alerts\n- `DeduplicationService`: Fingerprint generation, duplicate detection\n- `RoutingService`: Rule evaluation, team matching\n- `NotificationService`: Channel selection, notification sending\n- `EscalationService`: Policy execution, level progression\n- `TeamService`: Team CRUD, member management\n- `AuthService`: Registration, login, token generation\n\n**Repositories to Test**:\n- `AlertRepository`: CRUD operations, filtering, pagination\n- `TeamRepository`: Team queries, member queries\n- `RoutingRuleRepository`: Rule queries with priority ordering\n- `NotificationRepository`: Status tracking, retry logic\n\n**Utilities to Test**:\n- `fingerprint.ts`: Fingerprint generation algorithm\n- `validators.ts`: Zod schema validation\n- `encryption.ts`: Password hashing, token generation\n- `dateUtils.ts`: Date formatting, timezone handling\n\n### Test Patterns\n\n#### 1. AAA Pattern (Arrange-Act-Assert)\n\n```typescript\nit('should calculate priority correctly', () => {\n    // Arrange\n    const alert = { severity: 'critical', labels: { priority: 'high' } };\n\n    // Act\n    const priority = calculatePriority(alert);\n\n    // Assert\n    expect(priority).toBe(100);\n});\n```\n\n#### 2. Mocking External Dependencies\n\n```typescript\njest.mock('@/repositories/AlertRepository');\n\nconst mockRepo = new AlertRepository() as jest.Mocked<AlertRepository>;\nmockRepo.findById.mockResolvedValue({ id: '1', title: 'Test' });\n```\n\n#### 3. Testing Async Operations\n\n```typescript\nit('should handle async operations', async () => {\n    const result = await alertService.createAlert(data);\n    expect(result).toBeDefined();\n});\n```\n\n#### 4. Testing Error Handling\n\n```typescript\nit('should throw error on invalid input', async () => {\n    await expect(alertService.createAlert(null)).rejects.toThrow('Invalid input');\n});\n```\n\n---\n\n## Integration Testing\n\n### API Endpoint Tests\n\nTest complete request/response cycles with real database interactions.\n\n#### Alert Endpoints Integration Tests\n\n**File**: `src/tests/integration/alerts.test.ts`\n\n```typescript\nimport request from 'supertest';\nimport app from '@/app';\nimport { PrismaClient } from '@prisma/client';\nimport { generateAuthToken } from '@/utils/auth';\n\nconst prisma = new PrismaClient();\n\ndescribe('Alert API Endpoints', () => {\n    let authToken: string;\n    let userId: string;\n    let teamId: string;\n\n    beforeAll(async () => {\n        // Set up test database\n        await prisma.$connect();\n\n        // Create test user\n        const user = await prisma.user.create({\n            data: {\n                email: 'test@example.com',\n                username: 'testuser',\n                passwordHash: 'hashedpassword',\n                role: 'admin'\n            }\n        });\n        userId = user.id;\n        authToken = generateAuthToken(user);\n\n        // Create test team\n        const team = await prisma.team.create({\n            data: {\n                name: 'Test Team',\n                email: 'team@example.com'\n            }\n        });\n        teamId = team.id;\n    });\n\n    afterAll(async () => {\n        // Clean up test data\n        await prisma.alert.deleteMany({});\n        await prisma.team.deleteMany({});\n        await prisma.user.deleteMany({});\n        await prisma.$disconnect();\n    });\n\n    describe('POST /api/alerts', () => {\n        it('should create a new alert', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                description: 'CPU usage exceeded 90%',\n                severity: 'high',\n                labels: {\n                    environment: 'production',\n                    service: 'api'\n                }\n            };\n\n            const response = await request(app)\n                .post('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .send(alertData)\n                .expect(201);\n\n            expect(response.body).toMatchObject({\n                id: expect.any(String),\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high',\n                status: 'open'\n            });\n\n            // Verify in database\n            const alert = await prisma.alert.findUnique({\n                where: { id: response.body.id }\n            });\n            expect(alert).toBeDefined();\n        });\n\n        it('should return 400 for invalid alert data', async () => {\n            const invalidData = {\n                source: 'prometheus'\n                // Missing required fields\n            };\n\n            const response = await request(app)\n                .post('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .send(invalidData)\n                .expect(400);\n\n            expect(response.body).toHaveProperty('error');\n        });\n\n        it('should return 401 without authentication', async () => {\n            await request(app)\n                .post('/api/alerts')\n                .send({ source: 'test' })\n                .expect(401);\n        });\n\n        it('should deduplicate identical alerts', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'Duplicate Alert',\n                severity: 'high',\n                labels: { instance: 'server-01' }\n            };\n\n            // Create first alert\n            const response1 = await request(app)\n                .post('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .send(alertData)\n                .expect(201);\n\n            // Create duplicate alert\n            const response2 = await request(app)\n                .post('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .send(alertData)\n                .expect(201);\n\n            // Should return the same alert ID or merged alert\n            expect(response1.body.id).toBe(response2.body.id);\n        });\n    });\n\n    describe('GET /api/alerts', () => {\n        beforeEach(async () => {\n            // Create test alerts\n            await prisma.alert.createMany({\n                data: [\n                    {\n                        source: 'prometheus',\n                        title: 'Alert 1',\n                        severity: 'critical',\n                        status: 'open',\n                        fingerprint: 'fp1'\n                    },\n                    {\n                        source: 'prometheus',\n                        title: 'Alert 2',\n                        severity: 'high',\n                        status: 'acknowledged',\n                        fingerprint: 'fp2'\n                    },\n                    {\n                        source: 'grafana',\n                        title: 'Alert 3',\n                        severity: 'medium',\n                        status: 'open',\n                        fingerprint: 'fp3'\n                    }\n                ]\n            });\n        });\n\n        afterEach(async () => {\n            await prisma.alert.deleteMany({});\n        });\n\n        it('should list all alerts', async () => {\n            const response = await request(app)\n                .get('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body).toHaveProperty('data');\n            expect(response.body.data).toHaveLength(3);\n        });\n\n        it('should filter alerts by severity', async () => {\n            const response = await request(app)\n                .get('/api/alerts?severity=critical')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body.data).toHaveLength(1);\n            expect(response.body.data[0].severity).toBe('critical');\n        });\n\n        it('should filter alerts by status', async () => {\n            const response = await request(app)\n                .get('/api/alerts?status=open')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body.data).toHaveLength(2);\n            response.body.data.forEach(alert => {\n                expect(alert.status).toBe('open');\n            });\n        });\n\n        it('should paginate results', async () => {\n            const response = await request(app)\n                .get('/api/alerts?limit=2&offset=0')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body.data).toHaveLength(2);\n            expect(response.body).toHaveProperty('pagination');\n            expect(response.body.pagination.total).toBe(3);\n        });\n    });\n\n    describe('POST /api/alerts/:id/acknowledge', () => {\n        let alertId: string;\n\n        beforeEach(async () => {\n            const alert = await prisma.alert.create({\n                data: {\n                    source: 'test',\n                    title: 'Test Alert',\n                    severity: 'high',\n                    status: 'open',\n                    fingerprint: 'test-fp'\n                }\n            });\n            alertId = alert.id;\n        });\n\n        it('should acknowledge an alert', async () => {\n            const response = await request(app)\n                .post(`/api/alerts/${alertId}/acknowledge`)\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body.status).toBe('acknowledged');\n            expect(response.body.acknowledgedBy).toBe(userId);\n\n            // Verify in database\n            const alert = await prisma.alert.findUnique({\n                where: { id: alertId }\n            });\n            expect(alert.status).toBe('acknowledged');\n        });\n\n        it('should return 404 for non-existent alert', async () => {\n            await request(app)\n                .post('/api/alerts/non-existent-id/acknowledge')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(404);\n        });\n    });\n});\n```\n\n### Database Integration Tests\n\nTest Prisma repository operations with real database.\n\n**File**: `src/tests/integration/repositories/alertRepository.test.ts`\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\nimport { AlertRepository } from '@/repositories/AlertRepository';\n\nconst prisma = new PrismaClient();\nconst alertRepository = new AlertRepository(prisma);\n\ndescribe('AlertRepository', () => {\n    beforeAll(async () => {\n        await prisma.$connect();\n    });\n\n    afterAll(async () => {\n        await prisma.alert.deleteMany({});\n        await prisma.$disconnect();\n    });\n\n    describe('create', () => {\n        it('should create an alert', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'Test Alert',\n                severity: 'high',\n                status: 'open',\n                fingerprint: 'test-fingerprint'\n            };\n\n            const alert = await alertRepository.create(alertData);\n\n            expect(alert).toMatchObject(alertData);\n            expect(alert.id).toBeDefined();\n            expect(alert.createdAt).toBeInstanceOf(Date);\n        });\n    });\n\n    describe('findByFingerprint', () => {\n        it('should find alert by fingerprint', async () => {\n            const fingerprint = 'unique-fingerprint';\n\n            await alertRepository.create({\n                source: 'test',\n                title: 'Fingerprint Test',\n                severity: 'low',\n                status: 'open',\n                fingerprint\n            });\n\n            const alert = await alertRepository.findByFingerprint(fingerprint);\n\n            expect(alert).toBeDefined();\n            expect(alert.fingerprint).toBe(fingerprint);\n        });\n\n        it('should return null for non-existent fingerprint', async () => {\n            const alert = await alertRepository.findByFingerprint('non-existent');\n            expect(alert).toBeNull();\n        });\n    });\n\n    describe('findWithFilters', () => {\n        beforeEach(async () => {\n            await prisma.alert.createMany({\n                data: [\n                    { source: 'prometheus', title: 'Alert 1', severity: 'critical', status: 'open', fingerprint: 'fp1' },\n                    { source: 'grafana', title: 'Alert 2', severity: 'high', status: 'acknowledged', fingerprint: 'fp2' },\n                    { source: 'prometheus', title: 'Alert 3', severity: 'medium', status: 'open', fingerprint: 'fp3' }\n                ]\n            });\n        });\n\n        afterEach(async () => {\n            await prisma.alert.deleteMany({});\n        });\n\n        it('should filter by severity', async () => {\n            const alerts = await alertRepository.findWithFilters({ severity: 'critical' });\n\n            expect(alerts).toHaveLength(1);\n            expect(alerts[0].severity).toBe('critical');\n        });\n\n        it('should filter by multiple conditions', async () => {\n            const alerts = await alertRepository.findWithFilters({\n                source: 'prometheus',\n                status: 'open'\n            });\n\n            expect(alerts).toHaveLength(2);\n        });\n    });\n});\n```\n\n### Redis Integration Tests\n\nTest caching and queue operations.\n\n**File**: `src/tests/integration/redis/deduplication.test.ts`\n\n```typescript\nimport Redis from 'ioredis';\nimport { DeduplicationService } from '@/services/deduplicationService';\n\nconst redis = new Redis(process.env.REDIS_TEST_URL);\nconst deduplicationService = new DeduplicationService(redis);\n\ndescribe('Deduplication with Redis', () => {\n    afterEach(async () => {\n        await redis.flushdb();\n    });\n\n    afterAll(async () => {\n        await redis.quit();\n    });\n\n    it('should store and retrieve alert fingerprints', async () => {\n        const fingerprint = 'test-fingerprint-123';\n        const alertId = 'alert-1';\n\n        await deduplicationService.storeFingerprint(fingerprint, alertId);\n        const cachedAlertId = await deduplicationService.getAlertIdByFingerprint(fingerprint);\n\n        expect(cachedAlertId).toBe(alertId);\n    });\n\n    it('should expire fingerprints after TTL', async () => {\n        const fingerprint = 'expiring-fingerprint';\n        const alertId = 'alert-1';\n        const ttl = 1; // 1 second\n\n        await deduplicationService.storeFingerprint(fingerprint, alertId, ttl);\n\n        // Wait for expiration\n        await new Promise(resolve => setTimeout(resolve, 1500));\n\n        const cachedAlertId = await deduplicationService.getAlertIdByFingerprint(fingerprint);\n        expect(cachedAlertId).toBeNull();\n    });\n});\n```\n\n---\n\n## End-to-End Testing\n\n### Complete Alert Flow Test\n\nTest entire alert lifecycle from ingestion to notification delivery.\n\n**File**: `src/tests/e2e/alertFlow.test.ts`\n\n```typescript\nimport request from 'supertest';\nimport app from '@/app';\nimport { PrismaClient } from '@prisma/client';\nimport { generateAuthToken } from '@/utils/auth';\n\nconst prisma = new PrismaClient();\n\ndescribe('E2E: Alert Flow', () => {\n    let authToken: string;\n    let team: any;\n    let routingRule: any;\n\n    beforeAll(async () => {\n        // Set up test environment\n        const user = await prisma.user.create({\n            data: {\n                email: 'e2e@example.com',\n                username: 'e2euser',\n                passwordHash: 'hash',\n                role: 'admin'\n            }\n        });\n        authToken = generateAuthToken(user);\n\n        // Create team\n        team = await prisma.team.create({\n            data: {\n                name: 'E2E Test Team',\n                email: 'team@example.com',\n                slackChannelId: 'C123456'\n            }\n        });\n\n        // Create routing rule\n        routingRule = await prisma.routingRule.create({\n            data: {\n                name: 'Production Critical Rule',\n                priority: 100,\n                enabled: true,\n                matchType: 'all',\n                conditions: {\n                    severity: ['critical'],\n                    labels: { environment: 'production' }\n                },\n                targetTeamId: team.id,\n                notificationChannels: ['email', 'slack']\n            }\n        });\n    });\n\n    afterAll(async () => {\n        await prisma.alert.deleteMany({});\n        await prisma.routingRule.deleteMany({});\n        await prisma.team.deleteMany({});\n        await prisma.user.deleteMany({});\n        await prisma.$disconnect();\n    });\n\n    it('should complete full alert lifecycle', async () => {\n        // 1. Create alert\n        const createResponse = await request(app)\n            .post('/api/alerts')\n            .set('Authorization', `Bearer ${authToken}`)\n            .send({\n                source: 'prometheus',\n                title: 'Critical Production Issue',\n                description: 'Server down',\n                severity: 'critical',\n                labels: {\n                    environment: 'production',\n                    service: 'api'\n                }\n            })\n            .expect(201);\n\n        const alertId = createResponse.body.id;\n\n        // 2. Verify alert was routed to correct team\n        expect(createResponse.body.assignedTeamId).toBe(team.id);\n        expect(createResponse.body.matchedRuleId).toBe(routingRule.id);\n\n        // 3. Verify notifications were created\n        const notifications = await prisma.alertNotification.findMany({\n            where: { alertId }\n        });\n        expect(notifications.length).toBeGreaterThan(0);\n\n        // 4. Acknowledge alert\n        const ackResponse = await request(app)\n            .post(`/api/alerts/${alertId}/acknowledge`)\n            .set('Authorization', `Bearer ${authToken}`)\n            .expect(200);\n\n        expect(ackResponse.body.status).toBe('acknowledged');\n\n        // 5. Resolve alert\n        const resolveResponse = await request(app)\n            .post(`/api/alerts/${alertId}/resolve`)\n            .set('Authorization', `Bearer ${authToken}`)\n            .expect(200);\n\n        expect(resolveResponse.body.status).toBe('resolved');\n\n        // 6. Verify final state in database\n        const finalAlert = await prisma.alert.findUnique({\n            where: { id: alertId }\n        });\n        expect(finalAlert.status).toBe('resolved');\n        expect(finalAlert.resolvedAt).toBeDefined();\n    });\n\n    it('should trigger escalation for unacknowledged alert', async () => {\n        // Create escalation policy\n        const policy = await prisma.escalationPolicy.create({\n            data: {\n                name: 'Test Escalation',\n                teamId: team.id,\n                enabled: true,\n                levels: [\n                    {\n                        level: 1,\n                        timeout_minutes: 1, // 1 minute for testing\n                        target_team_id: team.id,\n                        channels: ['email']\n                    }\n                ]\n            }\n        });\n\n        // Create alert\n        const createResponse = await request(app)\n            .post('/api/alerts')\n            .set('Authorization', `Bearer ${authToken}`)\n            .send({\n                source: 'test',\n                title: 'Escalation Test Alert',\n                severity: 'critical',\n                labels: { environment: 'production' }\n            })\n            .expect(201);\n\n        const alertId = createResponse.body.id;\n\n        // Wait for escalation timeout\n        await new Promise(resolve => setTimeout(resolve, 61000)); // 61 seconds\n\n        // Check if escalation was triggered\n        const escalations = await prisma.escalation.findMany({\n            where: { alertId }\n        });\n        expect(escalations.length).toBeGreaterThan(0);\n    });\n});\n```\n\n---\n\n## Performance Testing\n\n### Load Testing with Artillery\n\n**File**: `tests/performance/alert-ingestion.yml`\n\n```yaml\nconfig:\n  target: \"http://localhost:3000\"\n  phases:\n    - duration: 60\n      arrivalRate: 10\n      name: \"Warm up\"\n    - duration: 120\n      arrivalRate: 50\n      name: \"Sustained load\"\n    - duration: 60\n      arrivalRate: 100\n      name: \"Peak load\"\n  variables:\n    authToken: \"Bearer eyJhbGc...\"\n\nscenarios:\n  - name: \"Create alerts\"\n    flow:\n      - post:\n          url: \"/api/alerts\"\n          headers:\n            Authorization: \"{{ authToken }}\"\n          json:\n            source: \"load-test\"\n            title: \"Load Test Alert {{ $randomNumber() }}\"\n            severity: \"{{ $randomChoice(['critical', 'high', 'medium', 'low']) }}\"\n            labels:\n              environment: \"test\"\n              instance: \"server-{{ $randomNumber() }}\"\n```\n\n### Performance Test Scripts\n\n**File**: `src/tests/performance/alertIngestion.test.ts`\n\n```typescript\nimport axios from 'axios';\n\nconst API_URL = 'http://localhost:3000/api';\nconst AUTH_TOKEN = 'Bearer ...';\nconst NUM_REQUESTS = 1000;\n\ndescribe('Performance: Alert Ingestion', () => {\n    it('should handle 1000 concurrent alert creations', async () => {\n        const startTime = Date.now();\n\n        const requests = Array.from({ length: NUM_REQUESTS }, (_, i) =>\n            axios.post(`${API_URL}/alerts`, {\n                source: 'perf-test',\n                title: `Performance Test Alert ${i}`,\n                severity: 'high',\n                labels: { test: 'performance' }\n            }, {\n                headers: { Authorization: AUTH_TOKEN }\n            })\n        );\n\n        const results = await Promise.allSettled(requests);\n        const endTime = Date.now();\n\n        const successful = results.filter(r => r.status === 'fulfilled').length;\n        const failed = results.filter(r => r.status === 'rejected').length;\n        const duration = endTime - startTime;\n        const throughput = (NUM_REQUESTS / duration) * 1000; // requests per second\n\n        console.log(`Successful: ${successful}`);\n        console.log(`Failed: ${failed}`);\n        console.log(`Duration: ${duration}ms`);\n        console.log(`Throughput: ${throughput.toFixed(2)} req/s`);\n\n        // Performance assertions\n        expect(successful).toBeGreaterThan(NUM_REQUESTS * 0.95); // 95% success rate\n        expect(throughput).toBeGreaterThan(50); // At least 50 req/s\n    }, 60000); // 60 second timeout\n});\n```\n\n### Database Query Performance\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\n\nconst prisma = new PrismaClient();\n\ndescribe('Performance: Database Queries', () => {\n    beforeAll(async () => {\n        // Create 10,000 test alerts\n        const alerts = Array.from({ length: 10000 }, (_, i) => ({\n            source: 'perf-test',\n            title: `Alert ${i}`,\n            severity: ['critical', 'high', 'medium', 'low'][i % 4],\n            status: 'open',\n            fingerprint: `fp-${i}`\n        }));\n\n        await prisma.alert.createMany({ data: alerts });\n    });\n\n    afterAll(async () => {\n        await prisma.alert.deleteMany({ where: { source: 'perf-test' } });\n        await prisma.$disconnect();\n    });\n\n    it('should query alerts with pagination in <50ms', async () => {\n        const startTime = Date.now();\n\n        await prisma.alert.findMany({\n            where: { status: 'open' },\n            take: 20,\n            skip: 0,\n            orderBy: { createdAt: 'desc' }\n        });\n\n        const duration = Date.now() - startTime;\n\n        expect(duration).toBeLessThan(50);\n    });\n\n    it('should filter alerts by severity in <50ms', async () => {\n        const startTime = Date.now();\n\n        await prisma.alert.findMany({\n            where: { severity: 'critical' },\n            take: 100\n        });\n\n        const duration = Date.now() - startTime;\n\n        expect(duration).toBeLessThan(50);\n    });\n});\n```\n\n---\n\n## Security Testing\n\n### Authentication Tests\n\n```typescript\ndescribe('Security: Authentication', () => {\n    it('should reject requests without token', async () => {\n        await request(app)\n            .get('/api/alerts')\n            .expect(401);\n    });\n\n    it('should reject requests with invalid token', async () => {\n        await request(app)\n            .get('/api/alerts')\n            .set('Authorization', 'Bearer invalid-token')\n            .expect(401);\n    });\n\n    it('should reject requests with expired token', async () => {\n        const expiredToken = generateExpiredToken();\n\n        await request(app)\n            .get('/api/alerts')\n            .set('Authorization', `Bearer ${expiredToken}`)\n            .expect(401);\n    });\n});\n```\n\n### Authorization Tests\n\n```typescript\ndescribe('Security: Authorization', () => {\n    it('should prevent non-admin from deleting alerts', async () => {\n        const userToken = generateTokenForRole('user');\n\n        await request(app)\n            .delete('/api/alerts/alert-1')\n            .set('Authorization', `Bearer ${userToken}`)\n            .expect(403);\n    });\n\n    it('should allow admin to delete alerts', async () => {\n        const adminToken = generateTokenForRole('admin');\n\n        await request(app)\n            .delete('/api/alerts/alert-1')\n            .set('Authorization', `Bearer ${adminToken}`)\n            .expect(200);\n    });\n});\n```\n\n### Input Validation Tests\n\n```typescript\ndescribe('Security: Input Validation', () => {\n    it('should reject SQL injection attempts', async () => {\n        await request(app)\n            .get('/api/alerts?severity=critical\\' OR \\'1\\'=\\'1')\n            .set('Authorization', `Bearer ${authToken}`)\n            .expect(400);\n    });\n\n    it('should sanitize XSS attempts', async () => {\n        const response = await request(app)\n            .post('/api/alerts')\n            .set('Authorization', `Bearer ${authToken}`)\n            .send({\n                source: 'test',\n                title: '<script>alert(\"XSS\")</script>',\n                severity: 'high'\n            })\n            .expect(201);\n\n        expect(response.body.title).not.toContain('<script>');\n    });\n});\n```\n\n---\n\n## Test Environment Setup\n\n### Docker Compose for Testing\n\n**File**: `docker-compose.test.yml`\n\n```yaml\nversion: '3.8'\n\nservices:\n  postgres-test:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_DB: alert_router_test\n      POSTGRES_USER: test\n      POSTGRES_PASSWORD: testpass\n    ports:\n      - \"5433:5432\"\n    tmpfs:\n      - /var/lib/postgresql/data\n\n  redis-test:\n    image: redis:7-alpine\n    ports:\n      - \"6380:6379\"\n    tmpfs:\n      - /data\n```\n\n### Test Environment Variables\n\n**File**: `.env.test`\n\n```env\nNODE_ENV=test\nDATABASE_URL=postgresql://test:testpass@localhost:5433/alert_router_test\nREDIS_URL=redis://localhost:6380\nJWT_SECRET=test-secret-key\nJWT_EXPIRY=15m\nSENTRY_DSN=\nLOG_LEVEL=error\n```\n\n### Jest Configuration\n\n**File**: `jest.config.js`\n\n```javascript\nmodule.exports = {\n    preset: 'ts-jest',\n    testEnvironment: 'node',\n    roots: ['<rootDir>/src'],\n    testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],\n    transform: {\n        '^.+\\\\.ts$': 'ts-jest',\n    },\n    collectCoverageFrom: [\n        'src/**/*.ts',\n        '!src/**/*.d.ts',\n        '!src/**/*.test.ts',\n        '!src/**/*.spec.ts',\n        '!src/tests/**',\n    ],\n    coverageThreshold: {\n        global: {\n            branches: 80,\n            functions: 80,\n            lines: 80,\n            statements: 80,\n        },\n    },\n    setupFilesAfterEnv: ['<rootDir>/src/tests/setup.ts'],\n    testTimeout: 30000,\n    maxWorkers: 4,\n};\n```\n\n### Test Setup File\n\n**File**: `src/tests/setup.ts`\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\nimport Redis from 'ioredis';\n\nconst prisma = new PrismaClient();\nconst redis = new Redis(process.env.REDIS_URL);\n\nbeforeAll(async () => {\n    // Run migrations\n    // Note: In real setup, use Prisma migrate for test database\n    await prisma.$connect();\n});\n\nafterAll(async () => {\n    await prisma.$disconnect();\n    await redis.quit();\n});\n\n// Mock Sentry in tests\njest.mock('@sentry/node', () => ({\n    captureException: jest.fn(),\n    captureMessage: jest.fn(),\n    init: jest.fn(),\n}));\n\n// Mock external notification services\njest.mock('nodemailer');\njest.mock('@slack/web-api');\njest.mock('@pagerduty/pdjs');\n```\n\n---\n\n## Test Data Management\n\n### Test Data Factories\n\n**File**: `src/tests/factories/alertFactory.ts`\n\n```typescript\nimport { faker } from '@faker-js/faker';\n\nexport const alertFactory = {\n    build: (overrides = {}) => ({\n        source: faker.company.name(),\n        title: faker.lorem.sentence(),\n        description: faker.lorem.paragraph(),\n        severity: faker.helpers.arrayElement(['critical', 'high', 'medium', 'low']),\n        labels: {\n            environment: faker.helpers.arrayElement(['production', 'staging', 'development']),\n            service: faker.internet.domainWord(),\n        },\n        ...overrides,\n    }),\n\n    buildMany: (count: number, overrides = {}) => {\n        return Array.from({ length: count }, () => alertFactory.build(overrides));\n    },\n};\n```\n\n### Seed Data\n\n**File**: `src/tests/seeds/testData.ts`\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\n\nconst prisma = new PrismaClient();\n\nexport async function seedTestData() {\n    // Create test users\n    const admin = await prisma.user.create({\n        data: {\n            email: 'admin@test.com',\n            username: 'admin',\n            passwordHash: 'hashed',\n            role: 'admin',\n        },\n    });\n\n    const user = await prisma.user.create({\n        data: {\n            email: 'user@test.com',\n            username: 'user',\n            passwordHash: 'hashed',\n            role: 'user',\n        },\n    });\n\n    // Create test teams\n    const platformTeam = await prisma.team.create({\n        data: {\n            name: 'Platform Team',\n            email: 'platform@test.com',\n        },\n    });\n\n    const devTeam = await prisma.team.create({\n        data: {\n            name: 'Development Team',\n            email: 'dev@test.com',\n        },\n    });\n\n    // Create routing rules\n    await prisma.routingRule.create({\n        data: {\n            name: 'Production Alerts',\n            priority: 100,\n            enabled: true,\n            matchType: 'all',\n            conditions: {\n                labels: { environment: 'production' },\n            },\n            targetTeamId: platformTeam.id,\n        },\n    });\n\n    return { admin, user, platformTeam, devTeam };\n}\n\nexport async function cleanupTestData() {\n    await prisma.alert.deleteMany({});\n    await prisma.routingRule.deleteMany({});\n    await prisma.team.deleteMany({});\n    await prisma.user.deleteMany({});\n}\n```\n\n---\n\n## CI/CD Integration\n\n### GitHub Actions Workflow\n\n**File**: `.github/workflows/test.yml`\n\n```yaml\nname: Tests\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:15-alpine\n        env:\n          POSTGRES_DB: test_db\n          POSTGRES_USER: test\n          POSTGRES_PASSWORD: test\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n      redis:\n        image: redis:7-alpine\n        ports:\n          - 6379:6379\n        options: >-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '20'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run linter\n        run: npm run lint\n\n      - name: Run type check\n        run: npm run type-check\n\n      - name: Run Prisma migrations\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n        run: npx prisma migrate deploy\n\n      - name: Run unit tests\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n          REDIS_URL: redis://localhost:6379\n        run: npm run test:unit\n\n      - name: Run integration tests\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n          REDIS_URL: redis://localhost:6379\n        run: npm run test:integration\n\n      - name: Run E2E tests\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n          REDIS_URL: redis://localhost:6379\n        run: npm run test:e2e\n\n      - name: Generate coverage report\n        run: npm run test:coverage\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage/lcov.info\n          fail_ci_if_error: true\n\n      - name: Check coverage thresholds\n        run: npm run test:coverage:check\n```\n\n### NPM Scripts\n\n**File**: `package.json` (test scripts)\n\n```json\n{\n  \"scripts\": {\n    \"test\": \"jest\",\n    \"test:unit\": \"jest --testPathPattern=tests/unit\",\n    \"test:integration\": \"jest --testPathPattern=tests/integration --runInBand\",\n    \"test:e2e\": \"jest --testPathPattern=tests/e2e --runInBand\",\n    \"test:coverage\": \"jest --coverage\",\n    \"test:coverage:check\": \"jest --coverage --coverageThreshold='{\\\"global\\\":{\\\"branches\\\":80,\\\"functions\\\":80,\\\"lines\\\":80,\\\"statements\\\":80}}'\",\n    \"test:watch\": \"jest --watch\",\n    \"test:debug\": \"node --inspect-brk node_modules/.bin/jest --runInBand\"\n  }\n}\n```\n\n---\n\n## Test Coverage Goals\n\n### Overall Coverage Targets\n\n| Component | Target Coverage |\n|-----------|----------------|\n| **Services** | 90% |\n| **Controllers** | 85% |\n| **Repositories** | 90% |\n| **Utilities** | 95% |\n| **Middleware** | 85% |\n| **Overall** | 80% |\n\n### Critical Path Coverage\n\nMust have 100% coverage:\n- Authentication and authorization logic\n- Alert deduplication logic\n- Routing engine\n- Escalation logic\n- Financial/billing logic (if applicable)\n\n### Coverage Reporting\n\n1. **Generate HTML report**: `npm run test:coverage`\n2. **View report**: Open `coverage/lcov-report/index.html`\n3. **CI Integration**: Automatically upload to Codecov\n4. **PR Comments**: Show coverage diff in pull requests\n\n---\n\n## Testing Tools & Frameworks\n\n### Core Testing Tools\n\n| Tool | Purpose | Version |\n|------|---------|---------|\n| **Jest** | Test framework and runner | v29+ |\n| **ts-jest** | TypeScript support for Jest | v29+ |\n| **Supertest** | HTTP endpoint testing | v6+ |\n| **@faker-js/faker** | Test data generation | v8+ |\n| **Prisma Test Environment** | Isolated test database | Custom |\n\n### Mocking Libraries\n\n| Library | Purpose |\n|---------|---------|\n| **jest.mock()** | Built-in mocking |\n| **jest.spyOn()** | Function spying |\n| **Mock Service Worker (MSW)** | API mocking (optional) |\n\n### Performance Testing\n\n| Tool | Purpose |\n|------|---------|\n| **Artillery** | Load testing |\n| **Clinic.js** | Node.js performance profiling |\n| **autocannon** | HTTP benchmarking |\n\n### Security Testing\n\n| Tool | Purpose |\n|------|---------|\n| **npm audit** | Dependency vulnerability scanning |\n| **Snyk** | Security vulnerability detection |\n| **OWASP ZAP** | Penetration testing (optional) |\n\n---\n\n## Test Execution Strategy\n\n### Local Development\n\n```bash\n# Run all tests\nnpm test\n\n# Run specific test suite\nnpm run test:unit\nnpm run test:integration\nnpm run test:e2e\n\n# Watch mode for TDD\nnpm run test:watch\n\n# Debug tests\nnpm run test:debug\n```\n\n### Pre-commit Hooks\n\n**File**: `.husky/pre-commit`\n\n```bash\n#!/bin/sh\n. \"$(dirname \"$0\")/_/husky.sh\"\n\n# Run linter\nnpm run lint\n\n# Run unit tests\nnpm run test:unit\n\n# Check TypeScript\nnpm run type-check\n```\n\n### Pull Request Process\n\n1. All tests must pass\n2. Coverage must not decrease\n3. New code must have accompanying tests\n4. Integration tests for new endpoints\n5. E2E tests for new workflows\n\n---\n\n## Conclusion\n\nThis comprehensive testing plan ensures high code quality, reliability, and maintainability of the Alert Notification Router system. By following the testing pyramid and maintaining high coverage, we can confidently deliver features and catch bugs early in the development cycle.\n\n**Key Takeaways**:\n- Write tests alongside code (TDD when possible)\n- Maintain 80%+ overall coverage, 90%+ for critical paths\n- Run fast unit tests frequently, integration tests before commits\n- Automate testing in CI/CD pipeline\n- Monitor and improve test performance\n- Keep tests maintainable and well-documented\n"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":11690,"cache_read_input_tokens":40992,"cache_creation":{"ephemeral_5m_input_tokens":11690,"ephemeral_1h_input_tokens":0},"output_tokens":12965,"service_tier":"standard"}},"requestId":"req_011CVFV2MGQkpMDNhdtbgEqF","type":"assistant","uuid":"c9cb8e2d-e7d0-4034-8868-fa890afc3aee","timestamp":"2025-11-18T14:09:09.277Z"}
{"parentUuid":"c9cb8e2d-e7d0-4034-8868-fa890afc3aee","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HPEaUyubXCXzT8Gqwoto5c","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"05bc1d8c-6dc4-4c9c-8492-fbc5d2a3f515","timestamp":"2025-11-18T14:09:09.401Z","toolUseResult":{"oldTodos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"in_progress","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"pending","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"pending","activeForm":"Creating Guide.md with user documentation"}],"newTodos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"completed","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"in_progress","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"pending","activeForm":"Creating Guide.md with user documentation"}]}}
{"type":"file-history-snapshot","messageId":"c9cb8e2d-e7d0-4034-8868-fa890afc3aee","snapshot":{"messageId":"a89c95da-4d38-4a9b-a8a1-8baeb5e10eb6","trackedFileBackups":{"docs/plan/DevelopmentPlan.md":{"backupFileName":null,"version":1,"backupTime":"2025-11-18T14:06:34.807Z"},"docs/testing/TestingPlan.md":{"backupFileName":null,"version":1,"backupTime":"2025-11-18T14:09:09.526Z"}},"timestamp":"2025-11-18T14:01:07.522Z"},"isSnapshotUpdate":true}
{"parentUuid":"05bc1d8c-6dc4-4c9c-8492-fbc5d2a3f515","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NfunyUF88SZkirREcTQv57","type":"tool_result","content":"File created successfully at: /root/Claude/claude-hooks/docs/testing/TestingPlan.md"}]},"uuid":"5737491b-7dc2-41a2-adbc-4ec0833545d9","timestamp":"2025-11-18T14:09:09.545Z","toolUseResult":{"type":"create","filePath":"/root/Claude/claude-hooks/docs/testing/TestingPlan.md","content":"# Alert Notification Router - Testing Plan\n\n## Table of Contents\n\n1. [Testing Strategy Overview](#testing-strategy-overview)\n2. [Testing Objectives](#testing-objectives)\n3. [Test Types & Coverage](#test-types--coverage)\n4. [Unit Testing](#unit-testing)\n5. [Integration Testing](#integration-testing)\n6. [End-to-End Testing](#end-to-end-testing)\n7. [Performance Testing](#performance-testing)\n8. [Security Testing](#security-testing)\n9. [Test Environment Setup](#test-environment-setup)\n10. [Test Data Management](#test-data-management)\n11. [CI/CD Integration](#cicd-integration)\n12. [Test Coverage Goals](#test-coverage-goals)\n13. [Testing Tools & Frameworks](#testing-tools--frameworks)\n\n---\n\n## Testing Strategy Overview\n\n### Philosophy\n\nOur testing strategy follows the **testing pyramid** approach:\n- **70% Unit Tests**: Fast, isolated tests for business logic\n- **20% Integration Tests**: Tests for component interactions\n- **10% E2E Tests**: Critical user flows and scenarios\n\n### Principles\n\n1. **Test-Driven Development (TDD)**: Write tests before implementation when possible\n2. **Fast Feedback**: Tests should run quickly to enable rapid iteration\n3. **Reliable**: Tests should be deterministic and not flaky\n4. **Maintainable**: Tests should be easy to understand and update\n5. **Comprehensive**: Critical paths must have test coverage\n6. **Isolated**: Tests should not depend on external services or each other\n\n---\n\n## Testing Objectives\n\n### Primary Goals\n\n1. **Functional Correctness**: Verify all features work as specified\n2. **Reliability**: Ensure system handles errors gracefully\n3. **Performance**: Meet performance targets (< 100ms alert ingestion, < 5s notification delivery)\n4. **Security**: Validate authentication, authorization, and data protection\n5. **Scalability**: Verify system handles expected load\n6. **Regression Prevention**: Catch bugs before production\n\n### Quality Metrics\n\n- **Code Coverage**: Minimum 80% overall, 90% for critical paths\n- **Test Success Rate**: 100% passing tests before deployment\n- **Test Execution Time**: < 5 minutes for unit tests, < 15 minutes for full suite\n- **Bug Escape Rate**: < 5% of bugs reach production\n- **Mean Time to Detect (MTTD)**: < 1 hour for production issues\n\n---\n\n## Test Types & Coverage\n\n### 1. Unit Tests (70%)\n\n**Scope**: Individual functions, methods, and classes in isolation\n\n**Coverage**:\n- All service layer business logic\n- All repository data access methods\n- Utility functions and helpers\n- Validation schemas (Zod)\n- Error handling logic\n\n**Target Coverage**: 85%+\n\n### 2. Integration Tests (20%)\n\n**Scope**: Interactions between components\n\n**Coverage**:\n- API endpoints (request â†’ controller â†’ service â†’ repository)\n- Database operations (Prisma)\n- Redis caching\n- Queue operations (Bull)\n- External API integrations (mock)\n\n**Target Coverage**: 80%+\n\n### 3. End-to-End Tests (10%)\n\n**Scope**: Complete user workflows\n\n**Coverage**:\n- Alert ingestion â†’ routing â†’ notification flow\n- User authentication and authorization flow\n- Escalation policy execution\n- Team management workflows\n\n**Target Coverage**: Critical paths only\n\n### 4. Performance Tests\n\n**Scope**: System performance under load\n\n**Coverage**:\n- Alert ingestion throughput\n- Concurrent notification delivery\n- Database query performance\n- API response times\n\n### 5. Security Tests\n\n**Scope**: Security vulnerabilities and attack vectors\n\n**Coverage**:\n- Authentication bypass attempts\n- Authorization checks\n- SQL injection\n- XSS attacks\n- Rate limiting\n- Input validation\n\n---\n\n## Unit Testing\n\n### Service Layer Tests\n\nTest business logic in isolation using mocked dependencies.\n\n#### AlertService Tests\n\n**File**: `src/tests/unit/services/alertService.test.ts`\n\n```typescript\nimport { AlertService } from '@/services/alertService';\nimport { AlertRepository } from '@/repositories/AlertRepository';\nimport { DeduplicationService } from '@/services/deduplicationService';\nimport { RoutingService } from '@/services/routingService';\nimport { NotificationService } from '@/services/notificationService';\nimport * as Sentry from '@sentry/node';\n\njest.mock('@/repositories/AlertRepository');\njest.mock('@/services/deduplicationService');\njest.mock('@/services/routingService');\njest.mock('@/services/notificationService');\njest.mock('@sentry/node');\n\ndescribe('AlertService', () => {\n    let alertService: AlertService;\n    let mockAlertRepository: jest.Mocked<AlertRepository>;\n    let mockDeduplicationService: jest.Mocked<DeduplicationService>;\n    let mockRoutingService: jest.Mocked<RoutingService>;\n    let mockNotificationService: jest.Mocked<NotificationService>;\n\n    beforeEach(() => {\n        mockAlertRepository = new AlertRepository() as jest.Mocked<AlertRepository>;\n        mockDeduplicationService = new DeduplicationService() as jest.Mocked<DeduplicationService>;\n        mockRoutingService = new RoutingService() as jest.Mocked<RoutingService>;\n        mockNotificationService = new NotificationService() as jest.Mocked<NotificationService>;\n\n        alertService = new AlertService(\n            mockAlertRepository,\n            mockDeduplicationService,\n            mockRoutingService,\n            mockNotificationService\n        );\n    });\n\n    describe('createAlert', () => {\n        it('should create a new alert when no duplicate exists', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high',\n                labels: { environment: 'production' }\n            };\n\n            mockDeduplicationService.findDuplicate.mockResolvedValue(null);\n            mockRoutingService.findMatchingRule.mockResolvedValue({\n                id: 'rule-1',\n                targetTeamId: 'team-1',\n                notificationChannels: ['email', 'slack']\n            });\n            mockAlertRepository.create.mockResolvedValue({\n                id: 'alert-1',\n                ...alertData,\n                status: 'open',\n                createdAt: new Date()\n            });\n\n            const result = await alertService.createAlert(alertData);\n\n            expect(result).toBeDefined();\n            expect(result.id).toBe('alert-1');\n            expect(mockDeduplicationService.findDuplicate).toHaveBeenCalled();\n            expect(mockRoutingService.findMatchingRule).toHaveBeenCalled();\n            expect(mockNotificationService.sendNotifications).toHaveBeenCalledWith(\n                expect.objectContaining({ id: 'alert-1' }),\n                ['email', 'slack']\n            );\n        });\n\n        it('should merge with existing alert if duplicate found', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high'\n            };\n\n            const existingAlert = {\n                id: 'existing-alert-1',\n                ...alertData,\n                count: 1\n            };\n\n            mockDeduplicationService.findDuplicate.mockResolvedValue(existingAlert);\n            mockAlertRepository.update.mockResolvedValue({\n                ...existingAlert,\n                count: 2\n            });\n\n            const result = await alertService.createAlert(alertData);\n\n            expect(result.id).toBe('existing-alert-1');\n            expect(result.count).toBe(2);\n            expect(mockAlertRepository.create).not.toHaveBeenCalled();\n        });\n\n        it('should handle routing errors gracefully', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high'\n            };\n\n            mockDeduplicationService.findDuplicate.mockResolvedValue(null);\n            mockRoutingService.findMatchingRule.mockRejectedValue(new Error('Routing failed'));\n\n            await expect(alertService.createAlert(alertData)).rejects.toThrow('Routing failed');\n            expect(Sentry.captureException).toHaveBeenCalled();\n        });\n\n        it('should generate correct fingerprint for alert', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high',\n                labels: { instance: 'server-01' }\n            };\n\n            mockDeduplicationService.findDuplicate.mockResolvedValue(null);\n            mockRoutingService.findMatchingRule.mockResolvedValue(null);\n            mockAlertRepository.create.mockImplementation((data) =>\n                Promise.resolve({ id: 'alert-1', ...data, createdAt: new Date() })\n            );\n\n            await alertService.createAlert(alertData);\n\n            expect(mockAlertRepository.create).toHaveBeenCalledWith(\n                expect.objectContaining({\n                    fingerprint: expect.any(String)\n                })\n            );\n        });\n    });\n\n    describe('acknowledgeAlert', () => {\n        it('should acknowledge an open alert', async () => {\n            const alertId = 'alert-1';\n            const userId = 'user-1';\n\n            mockAlertRepository.findById.mockResolvedValue({\n                id: alertId,\n                status: 'open'\n            });\n\n            mockAlertRepository.update.mockResolvedValue({\n                id: alertId,\n                status: 'acknowledged',\n                acknowledgedBy: userId,\n                acknowledgedAt: new Date()\n            });\n\n            const result = await alertService.acknowledgeAlert(alertId, userId);\n\n            expect(result.status).toBe('acknowledged');\n            expect(result.acknowledgedBy).toBe(userId);\n        });\n\n        it('should throw error if alert is already acknowledged', async () => {\n            const alertId = 'alert-1';\n            const userId = 'user-1';\n\n            mockAlertRepository.findById.mockResolvedValue({\n                id: alertId,\n                status: 'acknowledged'\n            });\n\n            await expect(alertService.acknowledgeAlert(alertId, userId)).rejects.toThrow(\n                'Alert is already acknowledged'\n            );\n        });\n\n        it('should throw error if alert not found', async () => {\n            mockAlertRepository.findById.mockResolvedValue(null);\n\n            await expect(alertService.acknowledgeAlert('invalid-id', 'user-1')).rejects.toThrow(\n                'Alert not found'\n            );\n        });\n    });\n\n    describe('resolveAlert', () => {\n        it('should resolve an acknowledged alert', async () => {\n            const alertId = 'alert-1';\n            const userId = 'user-1';\n\n            mockAlertRepository.findById.mockResolvedValue({\n                id: alertId,\n                status: 'acknowledged'\n            });\n\n            mockAlertRepository.update.mockResolvedValue({\n                id: alertId,\n                status: 'resolved',\n                resolvedBy: userId,\n                resolvedAt: new Date()\n            });\n\n            const result = await alertService.resolveAlert(alertId, userId);\n\n            expect(result.status).toBe('resolved');\n            expect(result.resolvedBy).toBe(userId);\n        });\n    });\n});\n```\n\n#### Test Coverage Areas\n\n**Services to Test**:\n- `AlertService`: Create, acknowledge, resolve, suppress alerts\n- `DeduplicationService`: Fingerprint generation, duplicate detection\n- `RoutingService`: Rule evaluation, team matching\n- `NotificationService`: Channel selection, notification sending\n- `EscalationService`: Policy execution, level progression\n- `TeamService`: Team CRUD, member management\n- `AuthService`: Registration, login, token generation\n\n**Repositories to Test**:\n- `AlertRepository`: CRUD operations, filtering, pagination\n- `TeamRepository`: Team queries, member queries\n- `RoutingRuleRepository`: Rule queries with priority ordering\n- `NotificationRepository`: Status tracking, retry logic\n\n**Utilities to Test**:\n- `fingerprint.ts`: Fingerprint generation algorithm\n- `validators.ts`: Zod schema validation\n- `encryption.ts`: Password hashing, token generation\n- `dateUtils.ts`: Date formatting, timezone handling\n\n### Test Patterns\n\n#### 1. AAA Pattern (Arrange-Act-Assert)\n\n```typescript\nit('should calculate priority correctly', () => {\n    // Arrange\n    const alert = { severity: 'critical', labels: { priority: 'high' } };\n\n    // Act\n    const priority = calculatePriority(alert);\n\n    // Assert\n    expect(priority).toBe(100);\n});\n```\n\n#### 2. Mocking External Dependencies\n\n```typescript\njest.mock('@/repositories/AlertRepository');\n\nconst mockRepo = new AlertRepository() as jest.Mocked<AlertRepository>;\nmockRepo.findById.mockResolvedValue({ id: '1', title: 'Test' });\n```\n\n#### 3. Testing Async Operations\n\n```typescript\nit('should handle async operations', async () => {\n    const result = await alertService.createAlert(data);\n    expect(result).toBeDefined();\n});\n```\n\n#### 4. Testing Error Handling\n\n```typescript\nit('should throw error on invalid input', async () => {\n    await expect(alertService.createAlert(null)).rejects.toThrow('Invalid input');\n});\n```\n\n---\n\n## Integration Testing\n\n### API Endpoint Tests\n\nTest complete request/response cycles with real database interactions.\n\n#### Alert Endpoints Integration Tests\n\n**File**: `src/tests/integration/alerts.test.ts`\n\n```typescript\nimport request from 'supertest';\nimport app from '@/app';\nimport { PrismaClient } from '@prisma/client';\nimport { generateAuthToken } from '@/utils/auth';\n\nconst prisma = new PrismaClient();\n\ndescribe('Alert API Endpoints', () => {\n    let authToken: string;\n    let userId: string;\n    let teamId: string;\n\n    beforeAll(async () => {\n        // Set up test database\n        await prisma.$connect();\n\n        // Create test user\n        const user = await prisma.user.create({\n            data: {\n                email: 'test@example.com',\n                username: 'testuser',\n                passwordHash: 'hashedpassword',\n                role: 'admin'\n            }\n        });\n        userId = user.id;\n        authToken = generateAuthToken(user);\n\n        // Create test team\n        const team = await prisma.team.create({\n            data: {\n                name: 'Test Team',\n                email: 'team@example.com'\n            }\n        });\n        teamId = team.id;\n    });\n\n    afterAll(async () => {\n        // Clean up test data\n        await prisma.alert.deleteMany({});\n        await prisma.team.deleteMany({});\n        await prisma.user.deleteMany({});\n        await prisma.$disconnect();\n    });\n\n    describe('POST /api/alerts', () => {\n        it('should create a new alert', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                description: 'CPU usage exceeded 90%',\n                severity: 'high',\n                labels: {\n                    environment: 'production',\n                    service: 'api'\n                }\n            };\n\n            const response = await request(app)\n                .post('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .send(alertData)\n                .expect(201);\n\n            expect(response.body).toMatchObject({\n                id: expect.any(String),\n                source: 'prometheus',\n                title: 'High CPU Usage',\n                severity: 'high',\n                status: 'open'\n            });\n\n            // Verify in database\n            const alert = await prisma.alert.findUnique({\n                where: { id: response.body.id }\n            });\n            expect(alert).toBeDefined();\n        });\n\n        it('should return 400 for invalid alert data', async () => {\n            const invalidData = {\n                source: 'prometheus'\n                // Missing required fields\n            };\n\n            const response = await request(app)\n                .post('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .send(invalidData)\n                .expect(400);\n\n            expect(response.body).toHaveProperty('error');\n        });\n\n        it('should return 401 without authentication', async () => {\n            await request(app)\n                .post('/api/alerts')\n                .send({ source: 'test' })\n                .expect(401);\n        });\n\n        it('should deduplicate identical alerts', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'Duplicate Alert',\n                severity: 'high',\n                labels: { instance: 'server-01' }\n            };\n\n            // Create first alert\n            const response1 = await request(app)\n                .post('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .send(alertData)\n                .expect(201);\n\n            // Create duplicate alert\n            const response2 = await request(app)\n                .post('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .send(alertData)\n                .expect(201);\n\n            // Should return the same alert ID or merged alert\n            expect(response1.body.id).toBe(response2.body.id);\n        });\n    });\n\n    describe('GET /api/alerts', () => {\n        beforeEach(async () => {\n            // Create test alerts\n            await prisma.alert.createMany({\n                data: [\n                    {\n                        source: 'prometheus',\n                        title: 'Alert 1',\n                        severity: 'critical',\n                        status: 'open',\n                        fingerprint: 'fp1'\n                    },\n                    {\n                        source: 'prometheus',\n                        title: 'Alert 2',\n                        severity: 'high',\n                        status: 'acknowledged',\n                        fingerprint: 'fp2'\n                    },\n                    {\n                        source: 'grafana',\n                        title: 'Alert 3',\n                        severity: 'medium',\n                        status: 'open',\n                        fingerprint: 'fp3'\n                    }\n                ]\n            });\n        });\n\n        afterEach(async () => {\n            await prisma.alert.deleteMany({});\n        });\n\n        it('should list all alerts', async () => {\n            const response = await request(app)\n                .get('/api/alerts')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body).toHaveProperty('data');\n            expect(response.body.data).toHaveLength(3);\n        });\n\n        it('should filter alerts by severity', async () => {\n            const response = await request(app)\n                .get('/api/alerts?severity=critical')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body.data).toHaveLength(1);\n            expect(response.body.data[0].severity).toBe('critical');\n        });\n\n        it('should filter alerts by status', async () => {\n            const response = await request(app)\n                .get('/api/alerts?status=open')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body.data).toHaveLength(2);\n            response.body.data.forEach(alert => {\n                expect(alert.status).toBe('open');\n            });\n        });\n\n        it('should paginate results', async () => {\n            const response = await request(app)\n                .get('/api/alerts?limit=2&offset=0')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body.data).toHaveLength(2);\n            expect(response.body).toHaveProperty('pagination');\n            expect(response.body.pagination.total).toBe(3);\n        });\n    });\n\n    describe('POST /api/alerts/:id/acknowledge', () => {\n        let alertId: string;\n\n        beforeEach(async () => {\n            const alert = await prisma.alert.create({\n                data: {\n                    source: 'test',\n                    title: 'Test Alert',\n                    severity: 'high',\n                    status: 'open',\n                    fingerprint: 'test-fp'\n                }\n            });\n            alertId = alert.id;\n        });\n\n        it('should acknowledge an alert', async () => {\n            const response = await request(app)\n                .post(`/api/alerts/${alertId}/acknowledge`)\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(200);\n\n            expect(response.body.status).toBe('acknowledged');\n            expect(response.body.acknowledgedBy).toBe(userId);\n\n            // Verify in database\n            const alert = await prisma.alert.findUnique({\n                where: { id: alertId }\n            });\n            expect(alert.status).toBe('acknowledged');\n        });\n\n        it('should return 404 for non-existent alert', async () => {\n            await request(app)\n                .post('/api/alerts/non-existent-id/acknowledge')\n                .set('Authorization', `Bearer ${authToken}`)\n                .expect(404);\n        });\n    });\n});\n```\n\n### Database Integration Tests\n\nTest Prisma repository operations with real database.\n\n**File**: `src/tests/integration/repositories/alertRepository.test.ts`\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\nimport { AlertRepository } from '@/repositories/AlertRepository';\n\nconst prisma = new PrismaClient();\nconst alertRepository = new AlertRepository(prisma);\n\ndescribe('AlertRepository', () => {\n    beforeAll(async () => {\n        await prisma.$connect();\n    });\n\n    afterAll(async () => {\n        await prisma.alert.deleteMany({});\n        await prisma.$disconnect();\n    });\n\n    describe('create', () => {\n        it('should create an alert', async () => {\n            const alertData = {\n                source: 'prometheus',\n                title: 'Test Alert',\n                severity: 'high',\n                status: 'open',\n                fingerprint: 'test-fingerprint'\n            };\n\n            const alert = await alertRepository.create(alertData);\n\n            expect(alert).toMatchObject(alertData);\n            expect(alert.id).toBeDefined();\n            expect(alert.createdAt).toBeInstanceOf(Date);\n        });\n    });\n\n    describe('findByFingerprint', () => {\n        it('should find alert by fingerprint', async () => {\n            const fingerprint = 'unique-fingerprint';\n\n            await alertRepository.create({\n                source: 'test',\n                title: 'Fingerprint Test',\n                severity: 'low',\n                status: 'open',\n                fingerprint\n            });\n\n            const alert = await alertRepository.findByFingerprint(fingerprint);\n\n            expect(alert).toBeDefined();\n            expect(alert.fingerprint).toBe(fingerprint);\n        });\n\n        it('should return null for non-existent fingerprint', async () => {\n            const alert = await alertRepository.findByFingerprint('non-existent');\n            expect(alert).toBeNull();\n        });\n    });\n\n    describe('findWithFilters', () => {\n        beforeEach(async () => {\n            await prisma.alert.createMany({\n                data: [\n                    { source: 'prometheus', title: 'Alert 1', severity: 'critical', status: 'open', fingerprint: 'fp1' },\n                    { source: 'grafana', title: 'Alert 2', severity: 'high', status: 'acknowledged', fingerprint: 'fp2' },\n                    { source: 'prometheus', title: 'Alert 3', severity: 'medium', status: 'open', fingerprint: 'fp3' }\n                ]\n            });\n        });\n\n        afterEach(async () => {\n            await prisma.alert.deleteMany({});\n        });\n\n        it('should filter by severity', async () => {\n            const alerts = await alertRepository.findWithFilters({ severity: 'critical' });\n\n            expect(alerts).toHaveLength(1);\n            expect(alerts[0].severity).toBe('critical');\n        });\n\n        it('should filter by multiple conditions', async () => {\n            const alerts = await alertRepository.findWithFilters({\n                source: 'prometheus',\n                status: 'open'\n            });\n\n            expect(alerts).toHaveLength(2);\n        });\n    });\n});\n```\n\n### Redis Integration Tests\n\nTest caching and queue operations.\n\n**File**: `src/tests/integration/redis/deduplication.test.ts`\n\n```typescript\nimport Redis from 'ioredis';\nimport { DeduplicationService } from '@/services/deduplicationService';\n\nconst redis = new Redis(process.env.REDIS_TEST_URL);\nconst deduplicationService = new DeduplicationService(redis);\n\ndescribe('Deduplication with Redis', () => {\n    afterEach(async () => {\n        await redis.flushdb();\n    });\n\n    afterAll(async () => {\n        await redis.quit();\n    });\n\n    it('should store and retrieve alert fingerprints', async () => {\n        const fingerprint = 'test-fingerprint-123';\n        const alertId = 'alert-1';\n\n        await deduplicationService.storeFingerprint(fingerprint, alertId);\n        const cachedAlertId = await deduplicationService.getAlertIdByFingerprint(fingerprint);\n\n        expect(cachedAlertId).toBe(alertId);\n    });\n\n    it('should expire fingerprints after TTL', async () => {\n        const fingerprint = 'expiring-fingerprint';\n        const alertId = 'alert-1';\n        const ttl = 1; // 1 second\n\n        await deduplicationService.storeFingerprint(fingerprint, alertId, ttl);\n\n        // Wait for expiration\n        await new Promise(resolve => setTimeout(resolve, 1500));\n\n        const cachedAlertId = await deduplicationService.getAlertIdByFingerprint(fingerprint);\n        expect(cachedAlertId).toBeNull();\n    });\n});\n```\n\n---\n\n## End-to-End Testing\n\n### Complete Alert Flow Test\n\nTest entire alert lifecycle from ingestion to notification delivery.\n\n**File**: `src/tests/e2e/alertFlow.test.ts`\n\n```typescript\nimport request from 'supertest';\nimport app from '@/app';\nimport { PrismaClient } from '@prisma/client';\nimport { generateAuthToken } from '@/utils/auth';\n\nconst prisma = new PrismaClient();\n\ndescribe('E2E: Alert Flow', () => {\n    let authToken: string;\n    let team: any;\n    let routingRule: any;\n\n    beforeAll(async () => {\n        // Set up test environment\n        const user = await prisma.user.create({\n            data: {\n                email: 'e2e@example.com',\n                username: 'e2euser',\n                passwordHash: 'hash',\n                role: 'admin'\n            }\n        });\n        authToken = generateAuthToken(user);\n\n        // Create team\n        team = await prisma.team.create({\n            data: {\n                name: 'E2E Test Team',\n                email: 'team@example.com',\n                slackChannelId: 'C123456'\n            }\n        });\n\n        // Create routing rule\n        routingRule = await prisma.routingRule.create({\n            data: {\n                name: 'Production Critical Rule',\n                priority: 100,\n                enabled: true,\n                matchType: 'all',\n                conditions: {\n                    severity: ['critical'],\n                    labels: { environment: 'production' }\n                },\n                targetTeamId: team.id,\n                notificationChannels: ['email', 'slack']\n            }\n        });\n    });\n\n    afterAll(async () => {\n        await prisma.alert.deleteMany({});\n        await prisma.routingRule.deleteMany({});\n        await prisma.team.deleteMany({});\n        await prisma.user.deleteMany({});\n        await prisma.$disconnect();\n    });\n\n    it('should complete full alert lifecycle', async () => {\n        // 1. Create alert\n        const createResponse = await request(app)\n            .post('/api/alerts')\n            .set('Authorization', `Bearer ${authToken}`)\n            .send({\n                source: 'prometheus',\n                title: 'Critical Production Issue',\n                description: 'Server down',\n                severity: 'critical',\n                labels: {\n                    environment: 'production',\n                    service: 'api'\n                }\n            })\n            .expect(201);\n\n        const alertId = createResponse.body.id;\n\n        // 2. Verify alert was routed to correct team\n        expect(createResponse.body.assignedTeamId).toBe(team.id);\n        expect(createResponse.body.matchedRuleId).toBe(routingRule.id);\n\n        // 3. Verify notifications were created\n        const notifications = await prisma.alertNotification.findMany({\n            where: { alertId }\n        });\n        expect(notifications.length).toBeGreaterThan(0);\n\n        // 4. Acknowledge alert\n        const ackResponse = await request(app)\n            .post(`/api/alerts/${alertId}/acknowledge`)\n            .set('Authorization', `Bearer ${authToken}`)\n            .expect(200);\n\n        expect(ackResponse.body.status).toBe('acknowledged');\n\n        // 5. Resolve alert\n        const resolveResponse = await request(app)\n            .post(`/api/alerts/${alertId}/resolve`)\n            .set('Authorization', `Bearer ${authToken}`)\n            .expect(200);\n\n        expect(resolveResponse.body.status).toBe('resolved');\n\n        // 6. Verify final state in database\n        const finalAlert = await prisma.alert.findUnique({\n            where: { id: alertId }\n        });\n        expect(finalAlert.status).toBe('resolved');\n        expect(finalAlert.resolvedAt).toBeDefined();\n    });\n\n    it('should trigger escalation for unacknowledged alert', async () => {\n        // Create escalation policy\n        const policy = await prisma.escalationPolicy.create({\n            data: {\n                name: 'Test Escalation',\n                teamId: team.id,\n                enabled: true,\n                levels: [\n                    {\n                        level: 1,\n                        timeout_minutes: 1, // 1 minute for testing\n                        target_team_id: team.id,\n                        channels: ['email']\n                    }\n                ]\n            }\n        });\n\n        // Create alert\n        const createResponse = await request(app)\n            .post('/api/alerts')\n            .set('Authorization', `Bearer ${authToken}`)\n            .send({\n                source: 'test',\n                title: 'Escalation Test Alert',\n                severity: 'critical',\n                labels: { environment: 'production' }\n            })\n            .expect(201);\n\n        const alertId = createResponse.body.id;\n\n        // Wait for escalation timeout\n        await new Promise(resolve => setTimeout(resolve, 61000)); // 61 seconds\n\n        // Check if escalation was triggered\n        const escalations = await prisma.escalation.findMany({\n            where: { alertId }\n        });\n        expect(escalations.length).toBeGreaterThan(0);\n    });\n});\n```\n\n---\n\n## Performance Testing\n\n### Load Testing with Artillery\n\n**File**: `tests/performance/alert-ingestion.yml`\n\n```yaml\nconfig:\n  target: \"http://localhost:3000\"\n  phases:\n    - duration: 60\n      arrivalRate: 10\n      name: \"Warm up\"\n    - duration: 120\n      arrivalRate: 50\n      name: \"Sustained load\"\n    - duration: 60\n      arrivalRate: 100\n      name: \"Peak load\"\n  variables:\n    authToken: \"Bearer eyJhbGc...\"\n\nscenarios:\n  - name: \"Create alerts\"\n    flow:\n      - post:\n          url: \"/api/alerts\"\n          headers:\n            Authorization: \"{{ authToken }}\"\n          json:\n            source: \"load-test\"\n            title: \"Load Test Alert {{ $randomNumber() }}\"\n            severity: \"{{ $randomChoice(['critical', 'high', 'medium', 'low']) }}\"\n            labels:\n              environment: \"test\"\n              instance: \"server-{{ $randomNumber() }}\"\n```\n\n### Performance Test Scripts\n\n**File**: `src/tests/performance/alertIngestion.test.ts`\n\n```typescript\nimport axios from 'axios';\n\nconst API_URL = 'http://localhost:3000/api';\nconst AUTH_TOKEN = 'Bearer ...';\nconst NUM_REQUESTS = 1000;\n\ndescribe('Performance: Alert Ingestion', () => {\n    it('should handle 1000 concurrent alert creations', async () => {\n        const startTime = Date.now();\n\n        const requests = Array.from({ length: NUM_REQUESTS }, (_, i) =>\n            axios.post(`${API_URL}/alerts`, {\n                source: 'perf-test',\n                title: `Performance Test Alert ${i}`,\n                severity: 'high',\n                labels: { test: 'performance' }\n            }, {\n                headers: { Authorization: AUTH_TOKEN }\n            })\n        );\n\n        const results = await Promise.allSettled(requests);\n        const endTime = Date.now();\n\n        const successful = results.filter(r => r.status === 'fulfilled').length;\n        const failed = results.filter(r => r.status === 'rejected').length;\n        const duration = endTime - startTime;\n        const throughput = (NUM_REQUESTS / duration) * 1000; // requests per second\n\n        console.log(`Successful: ${successful}`);\n        console.log(`Failed: ${failed}`);\n        console.log(`Duration: ${duration}ms`);\n        console.log(`Throughput: ${throughput.toFixed(2)} req/s`);\n\n        // Performance assertions\n        expect(successful).toBeGreaterThan(NUM_REQUESTS * 0.95); // 95% success rate\n        expect(throughput).toBeGreaterThan(50); // At least 50 req/s\n    }, 60000); // 60 second timeout\n});\n```\n\n### Database Query Performance\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\n\nconst prisma = new PrismaClient();\n\ndescribe('Performance: Database Queries', () => {\n    beforeAll(async () => {\n        // Create 10,000 test alerts\n        const alerts = Array.from({ length: 10000 }, (_, i) => ({\n            source: 'perf-test',\n            title: `Alert ${i}`,\n            severity: ['critical', 'high', 'medium', 'low'][i % 4],\n            status: 'open',\n            fingerprint: `fp-${i}`\n        }));\n\n        await prisma.alert.createMany({ data: alerts });\n    });\n\n    afterAll(async () => {\n        await prisma.alert.deleteMany({ where: { source: 'perf-test' } });\n        await prisma.$disconnect();\n    });\n\n    it('should query alerts with pagination in <50ms', async () => {\n        const startTime = Date.now();\n\n        await prisma.alert.findMany({\n            where: { status: 'open' },\n            take: 20,\n            skip: 0,\n            orderBy: { createdAt: 'desc' }\n        });\n\n        const duration = Date.now() - startTime;\n\n        expect(duration).toBeLessThan(50);\n    });\n\n    it('should filter alerts by severity in <50ms', async () => {\n        const startTime = Date.now();\n\n        await prisma.alert.findMany({\n            where: { severity: 'critical' },\n            take: 100\n        });\n\n        const duration = Date.now() - startTime;\n\n        expect(duration).toBeLessThan(50);\n    });\n});\n```\n\n---\n\n## Security Testing\n\n### Authentication Tests\n\n```typescript\ndescribe('Security: Authentication', () => {\n    it('should reject requests without token', async () => {\n        await request(app)\n            .get('/api/alerts')\n            .expect(401);\n    });\n\n    it('should reject requests with invalid token', async () => {\n        await request(app)\n            .get('/api/alerts')\n            .set('Authorization', 'Bearer invalid-token')\n            .expect(401);\n    });\n\n    it('should reject requests with expired token', async () => {\n        const expiredToken = generateExpiredToken();\n\n        await request(app)\n            .get('/api/alerts')\n            .set('Authorization', `Bearer ${expiredToken}`)\n            .expect(401);\n    });\n});\n```\n\n### Authorization Tests\n\n```typescript\ndescribe('Security: Authorization', () => {\n    it('should prevent non-admin from deleting alerts', async () => {\n        const userToken = generateTokenForRole('user');\n\n        await request(app)\n            .delete('/api/alerts/alert-1')\n            .set('Authorization', `Bearer ${userToken}`)\n            .expect(403);\n    });\n\n    it('should allow admin to delete alerts', async () => {\n        const adminToken = generateTokenForRole('admin');\n\n        await request(app)\n            .delete('/api/alerts/alert-1')\n            .set('Authorization', `Bearer ${adminToken}`)\n            .expect(200);\n    });\n});\n```\n\n### Input Validation Tests\n\n```typescript\ndescribe('Security: Input Validation', () => {\n    it('should reject SQL injection attempts', async () => {\n        await request(app)\n            .get('/api/alerts?severity=critical\\' OR \\'1\\'=\\'1')\n            .set('Authorization', `Bearer ${authToken}`)\n            .expect(400);\n    });\n\n    it('should sanitize XSS attempts', async () => {\n        const response = await request(app)\n            .post('/api/alerts')\n            .set('Authorization', `Bearer ${authToken}`)\n            .send({\n                source: 'test',\n                title: '<script>alert(\"XSS\")</script>',\n                severity: 'high'\n            })\n            .expect(201);\n\n        expect(response.body.title).not.toContain('<script>');\n    });\n});\n```\n\n---\n\n## Test Environment Setup\n\n### Docker Compose for Testing\n\n**File**: `docker-compose.test.yml`\n\n```yaml\nversion: '3.8'\n\nservices:\n  postgres-test:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_DB: alert_router_test\n      POSTGRES_USER: test\n      POSTGRES_PASSWORD: testpass\n    ports:\n      - \"5433:5432\"\n    tmpfs:\n      - /var/lib/postgresql/data\n\n  redis-test:\n    image: redis:7-alpine\n    ports:\n      - \"6380:6379\"\n    tmpfs:\n      - /data\n```\n\n### Test Environment Variables\n\n**File**: `.env.test`\n\n```env\nNODE_ENV=test\nDATABASE_URL=postgresql://test:testpass@localhost:5433/alert_router_test\nREDIS_URL=redis://localhost:6380\nJWT_SECRET=test-secret-key\nJWT_EXPIRY=15m\nSENTRY_DSN=\nLOG_LEVEL=error\n```\n\n### Jest Configuration\n\n**File**: `jest.config.js`\n\n```javascript\nmodule.exports = {\n    preset: 'ts-jest',\n    testEnvironment: 'node',\n    roots: ['<rootDir>/src'],\n    testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],\n    transform: {\n        '^.+\\\\.ts$': 'ts-jest',\n    },\n    collectCoverageFrom: [\n        'src/**/*.ts',\n        '!src/**/*.d.ts',\n        '!src/**/*.test.ts',\n        '!src/**/*.spec.ts',\n        '!src/tests/**',\n    ],\n    coverageThreshold: {\n        global: {\n            branches: 80,\n            functions: 80,\n            lines: 80,\n            statements: 80,\n        },\n    },\n    setupFilesAfterEnv: ['<rootDir>/src/tests/setup.ts'],\n    testTimeout: 30000,\n    maxWorkers: 4,\n};\n```\n\n### Test Setup File\n\n**File**: `src/tests/setup.ts`\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\nimport Redis from 'ioredis';\n\nconst prisma = new PrismaClient();\nconst redis = new Redis(process.env.REDIS_URL);\n\nbeforeAll(async () => {\n    // Run migrations\n    // Note: In real setup, use Prisma migrate for test database\n    await prisma.$connect();\n});\n\nafterAll(async () => {\n    await prisma.$disconnect();\n    await redis.quit();\n});\n\n// Mock Sentry in tests\njest.mock('@sentry/node', () => ({\n    captureException: jest.fn(),\n    captureMessage: jest.fn(),\n    init: jest.fn(),\n}));\n\n// Mock external notification services\njest.mock('nodemailer');\njest.mock('@slack/web-api');\njest.mock('@pagerduty/pdjs');\n```\n\n---\n\n## Test Data Management\n\n### Test Data Factories\n\n**File**: `src/tests/factories/alertFactory.ts`\n\n```typescript\nimport { faker } from '@faker-js/faker';\n\nexport const alertFactory = {\n    build: (overrides = {}) => ({\n        source: faker.company.name(),\n        title: faker.lorem.sentence(),\n        description: faker.lorem.paragraph(),\n        severity: faker.helpers.arrayElement(['critical', 'high', 'medium', 'low']),\n        labels: {\n            environment: faker.helpers.arrayElement(['production', 'staging', 'development']),\n            service: faker.internet.domainWord(),\n        },\n        ...overrides,\n    }),\n\n    buildMany: (count: number, overrides = {}) => {\n        return Array.from({ length: count }, () => alertFactory.build(overrides));\n    },\n};\n```\n\n### Seed Data\n\n**File**: `src/tests/seeds/testData.ts`\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\n\nconst prisma = new PrismaClient();\n\nexport async function seedTestData() {\n    // Create test users\n    const admin = await prisma.user.create({\n        data: {\n            email: 'admin@test.com',\n            username: 'admin',\n            passwordHash: 'hashed',\n            role: 'admin',\n        },\n    });\n\n    const user = await prisma.user.create({\n        data: {\n            email: 'user@test.com',\n            username: 'user',\n            passwordHash: 'hashed',\n            role: 'user',\n        },\n    });\n\n    // Create test teams\n    const platformTeam = await prisma.team.create({\n        data: {\n            name: 'Platform Team',\n            email: 'platform@test.com',\n        },\n    });\n\n    const devTeam = await prisma.team.create({\n        data: {\n            name: 'Development Team',\n            email: 'dev@test.com',\n        },\n    });\n\n    // Create routing rules\n    await prisma.routingRule.create({\n        data: {\n            name: 'Production Alerts',\n            priority: 100,\n            enabled: true,\n            matchType: 'all',\n            conditions: {\n                labels: { environment: 'production' },\n            },\n            targetTeamId: platformTeam.id,\n        },\n    });\n\n    return { admin, user, platformTeam, devTeam };\n}\n\nexport async function cleanupTestData() {\n    await prisma.alert.deleteMany({});\n    await prisma.routingRule.deleteMany({});\n    await prisma.team.deleteMany({});\n    await prisma.user.deleteMany({});\n}\n```\n\n---\n\n## CI/CD Integration\n\n### GitHub Actions Workflow\n\n**File**: `.github/workflows/test.yml`\n\n```yaml\nname: Tests\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:15-alpine\n        env:\n          POSTGRES_DB: test_db\n          POSTGRES_USER: test\n          POSTGRES_PASSWORD: test\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n      redis:\n        image: redis:7-alpine\n        ports:\n          - 6379:6379\n        options: >-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '20'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run linter\n        run: npm run lint\n\n      - name: Run type check\n        run: npm run type-check\n\n      - name: Run Prisma migrations\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n        run: npx prisma migrate deploy\n\n      - name: Run unit tests\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n          REDIS_URL: redis://localhost:6379\n        run: npm run test:unit\n\n      - name: Run integration tests\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n          REDIS_URL: redis://localhost:6379\n        run: npm run test:integration\n\n      - name: Run E2E tests\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n          REDIS_URL: redis://localhost:6379\n        run: npm run test:e2e\n\n      - name: Generate coverage report\n        run: npm run test:coverage\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage/lcov.info\n          fail_ci_if_error: true\n\n      - name: Check coverage thresholds\n        run: npm run test:coverage:check\n```\n\n### NPM Scripts\n\n**File**: `package.json` (test scripts)\n\n```json\n{\n  \"scripts\": {\n    \"test\": \"jest\",\n    \"test:unit\": \"jest --testPathPattern=tests/unit\",\n    \"test:integration\": \"jest --testPathPattern=tests/integration --runInBand\",\n    \"test:e2e\": \"jest --testPathPattern=tests/e2e --runInBand\",\n    \"test:coverage\": \"jest --coverage\",\n    \"test:coverage:check\": \"jest --coverage --coverageThreshold='{\\\"global\\\":{\\\"branches\\\":80,\\\"functions\\\":80,\\\"lines\\\":80,\\\"statements\\\":80}}'\",\n    \"test:watch\": \"jest --watch\",\n    \"test:debug\": \"node --inspect-brk node_modules/.bin/jest --runInBand\"\n  }\n}\n```\n\n---\n\n## Test Coverage Goals\n\n### Overall Coverage Targets\n\n| Component | Target Coverage |\n|-----------|----------------|\n| **Services** | 90% |\n| **Controllers** | 85% |\n| **Repositories** | 90% |\n| **Utilities** | 95% |\n| **Middleware** | 85% |\n| **Overall** | 80% |\n\n### Critical Path Coverage\n\nMust have 100% coverage:\n- Authentication and authorization logic\n- Alert deduplication logic\n- Routing engine\n- Escalation logic\n- Financial/billing logic (if applicable)\n\n### Coverage Reporting\n\n1. **Generate HTML report**: `npm run test:coverage`\n2. **View report**: Open `coverage/lcov-report/index.html`\n3. **CI Integration**: Automatically upload to Codecov\n4. **PR Comments**: Show coverage diff in pull requests\n\n---\n\n## Testing Tools & Frameworks\n\n### Core Testing Tools\n\n| Tool | Purpose | Version |\n|------|---------|---------|\n| **Jest** | Test framework and runner | v29+ |\n| **ts-jest** | TypeScript support for Jest | v29+ |\n| **Supertest** | HTTP endpoint testing | v6+ |\n| **@faker-js/faker** | Test data generation | v8+ |\n| **Prisma Test Environment** | Isolated test database | Custom |\n\n### Mocking Libraries\n\n| Library | Purpose |\n|---------|---------|\n| **jest.mock()** | Built-in mocking |\n| **jest.spyOn()** | Function spying |\n| **Mock Service Worker (MSW)** | API mocking (optional) |\n\n### Performance Testing\n\n| Tool | Purpose |\n|------|---------|\n| **Artillery** | Load testing |\n| **Clinic.js** | Node.js performance profiling |\n| **autocannon** | HTTP benchmarking |\n\n### Security Testing\n\n| Tool | Purpose |\n|------|---------|\n| **npm audit** | Dependency vulnerability scanning |\n| **Snyk** | Security vulnerability detection |\n| **OWASP ZAP** | Penetration testing (optional) |\n\n---\n\n## Test Execution Strategy\n\n### Local Development\n\n```bash\n# Run all tests\nnpm test\n\n# Run specific test suite\nnpm run test:unit\nnpm run test:integration\nnpm run test:e2e\n\n# Watch mode for TDD\nnpm run test:watch\n\n# Debug tests\nnpm run test:debug\n```\n\n### Pre-commit Hooks\n\n**File**: `.husky/pre-commit`\n\n```bash\n#!/bin/sh\n. \"$(dirname \"$0\")/_/husky.sh\"\n\n# Run linter\nnpm run lint\n\n# Run unit tests\nnpm run test:unit\n\n# Check TypeScript\nnpm run type-check\n```\n\n### Pull Request Process\n\n1. All tests must pass\n2. Coverage must not decrease\n3. New code must have accompanying tests\n4. Integration tests for new endpoints\n5. E2E tests for new workflows\n\n---\n\n## Conclusion\n\nThis comprehensive testing plan ensures high code quality, reliability, and maintainability of the Alert Notification Router system. By following the testing pyramid and maintaining high coverage, we can confidently deliver features and catch bugs early in the development cycle.\n\n**Key Takeaways**:\n- Write tests alongside code (TDD when possible)\n- Maintain 80%+ overall coverage, 90%+ for critical paths\n- Run fast unit tests frequently, integration tests before commits\n- Automate testing in CI/CD pipeline\n- Monitor and improve test performance\n- Keep tests maintainable and well-documented\n","structuredPatch":[]}}
{"parentUuid":"5737491b-7dc2-41a2-adbc-4ec0833545d9","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RoJ6t4bZK73yJmbnMnW14e","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011jK5BrZL3sh4mHqYvQ1T5Y","name":"TodoWrite","input":{"todos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"completed","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"completed","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"in_progress","activeForm":"Creating Guide.md with user documentation"}]}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":13039,"cache_read_input_tokens":52682,"cache_creation":{"ephemeral_5m_input_tokens":13039,"ephemeral_1h_input_tokens":0},"output_tokens":9412,"service_tier":"standard"}},"requestId":"req_011CVFVDi7Lq6PURTK5BTeS4","type":"assistant","uuid":"73340c6a-afd0-428e-8acd-f74473d9a4a8","timestamp":"2025-11-18T14:09:18.112Z"}
{"parentUuid":"73340c6a-afd0-428e-8acd-f74473d9a4a8","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RoJ6t4bZK73yJmbnMnW14e","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QYxAwhYApcB3wxQucmUYSs","name":"Write","input":{"file_path":"/root/Claude/claude-hooks/docs/guides/Guide.md","content":"# Alert Notification Router - User Guide\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n2. [Getting Started](#getting-started)\n3. [Installation](#installation)\n4. [Configuration](#configuration)\n5. [Core Concepts](#core-concepts)\n6. [Managing Teams](#managing-teams)\n7. [Creating Routing Rules](#creating-routing-rules)\n8. [Setting Up Notification Channels](#setting-up-notification-channels)\n9. [Working with Alerts](#working-with-alerts)\n10. [Escalation Policies](#escalation-policies)\n11. [API Usage](#api-usage)\n12. [Dashboard Guide](#dashboard-guide)\n13. [Best Practices](#best-practices)\n14. [Troubleshooting](#troubleshooting)\n15. [FAQ](#faq)\n\n---\n\n## Introduction\n\n### What is Alert Notification Router?\n\nAlert Notification Router is an intelligent alert management system that automatically routes alerts to the appropriate teams based on configurable rules. It supports multiple notification channels (Email, Slack, PagerDuty), provides alert deduplication, priority handling, escalation policies, and comprehensive delivery tracking.\n\n### Key Features\n\n- **Intelligent Routing**: Automatically route alerts to the right team based on severity, source, labels, and custom conditions\n- **Multi-Channel Notifications**: Send alerts via Email, Slack, and PagerDuty\n- **Alert Deduplication**: Prevent duplicate alerts from overwhelming your teams\n- **Priority Management**: Prioritize critical alerts for faster response\n- **Escalation Policies**: Automatically escalate unacknowledged alerts to higher-level teams\n- **Delivery Tracking**: Monitor notification delivery status and retry failed deliveries\n- **Team Management**: Organize users into teams with on-call schedules\n- **Analytics Dashboard**: Track alert metrics, response times, and team performance\n\n### Who Should Use This?\n\n- **DevOps Teams**: Monitor infrastructure and application alerts\n- **SRE Teams**: Manage incident response and on-call rotations\n- **Engineering Teams**: Route alerts to appropriate service owners\n- **Operations Teams**: Centralize alert management across multiple systems\n\n---\n\n## Getting Started\n\n### Prerequisites\n\nBefore installing Alert Notification Router, ensure you have:\n\n- **Node.js** v20 or higher\n- **PostgreSQL** v15 or higher\n- **Redis** v7 or higher\n- **Docker** (optional, for containerized deployment)\n- **SMTP server** or **SendGrid account** (for email notifications)\n- **Slack workspace** (optional, for Slack notifications)\n- **PagerDuty account** (optional, for PagerDuty integration)\n\n### Quick Start (5 Minutes)\n\n1. **Clone the repository**\n```bash\ngit clone https://github.com/your-org/alert-notification-router.git\ncd alert-notification-router\n```\n\n2. **Install dependencies**\n```bash\nnpm install\n```\n\n3. **Set up environment variables**\n```bash\ncp .env.example .env\n# Edit .env with your configuration\n```\n\n4. **Start Docker services**\n```bash\ndocker-compose up -d postgres redis\n```\n\n5. **Run database migrations**\n```bash\nnpx prisma migrate deploy\n```\n\n6. **Seed initial data** (optional)\n```bash\nnpm run seed\n```\n\n7. **Start the application**\n```bash\nnpm run dev\n```\n\n8. **Access the dashboard**\nOpen your browser to `http://localhost:3000`\n\n---\n\n## Installation\n\n### Option 1: Local Development Setup\n\n#### 1. Install Dependencies\n\n```bash\nnpm install\n```\n\n#### 2. Configure Environment Variables\n\nCreate a `.env` file in the project root:\n\n```env\n# Application\nNODE_ENV=development\nPORT=3000\nAPI_BASE_URL=http://localhost:3000\n\n# Database\nDATABASE_URL=postgresql://user:password@localhost:5432/alert_router\n\n# Redis\nREDIS_URL=redis://localhost:6379\n\n# JWT Authentication\nJWT_SECRET=your-secret-key-change-this-in-production\nJWT_EXPIRY=15m\nJWT_REFRESH_EXPIRY=7d\n\n# Email Configuration\nSMTP_HOST=smtp.gmail.com\nSMTP_PORT=587\nSMTP_SECURE=false\nSMTP_USER=your-email@gmail.com\nSMTP_PASSWORD=your-app-password\nEMAIL_FROM=Alert Router <alerts@example.com>\n\n# Slack Integration\nSLACK_BOT_TOKEN=xoxb-your-bot-token\nSLACK_SIGNING_SECRET=your-signing-secret\n\n# PagerDuty Integration\nPAGERDUTY_API_KEY=your-api-key\nPAGERDUTY_EMAIL=your-email@example.com\n\n# Sentry (Error Tracking)\nSENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id\n\n# Logging\nLOG_LEVEL=info\n\n# Deduplication\nDEDUPLICATION_WINDOW_MINUTES=5\n\n# Escalation\nESCALATION_CHECK_INTERVAL_MINUTES=5\n```\n\n#### 3. Start PostgreSQL and Redis\n\nUsing Docker:\n```bash\ndocker-compose up -d postgres redis\n```\n\nOr install locally (macOS):\n```bash\nbrew install postgresql redis\nbrew services start postgresql\nbrew services start redis\n```\n\n#### 4. Run Database Migrations\n\n```bash\nnpx prisma migrate deploy\n```\n\n#### 5. Start the Application\n\n```bash\n# Development mode with hot reload\nnpm run dev\n\n# Production mode\nnpm run build\nnpm start\n```\n\n### Option 2: Docker Deployment\n\n#### 1. Build Docker Image\n\n```bash\ndocker build -t alert-router:latest .\n```\n\n#### 2. Run with Docker Compose\n\n```bash\ndocker-compose up -d\n```\n\nThis will start:\n- Application server (port 3000)\n- PostgreSQL database (port 5432)\n- Redis cache (port 6379)\n\n### Option 3: Cloud Deployment\n\n#### Deploy to AWS ECS\n\n1. Build and push Docker image to ECR\n2. Create ECS task definition\n3. Set up RDS PostgreSQL and ElastiCache Redis\n4. Configure environment variables in ECS task\n5. Create ECS service with load balancer\n\n#### Deploy to Google Cloud Run\n\n```bash\n# Build and push to GCR\ngcloud builds submit --tag gcr.io/PROJECT_ID/alert-router\n\n# Deploy to Cloud Run\ngcloud run deploy alert-router \\\n  --image gcr.io/PROJECT_ID/alert-router \\\n  --platform managed \\\n  --region us-central1 \\\n  --set-env-vars DATABASE_URL=postgresql://...\n```\n\n---\n\n## Configuration\n\n### Database Configuration\n\n#### PostgreSQL Connection\n\nThe `DATABASE_URL` environment variable configures the PostgreSQL connection:\n\n```\npostgresql://[user]:[password]@[host]:[port]/[database]?schema=public\n```\n\n**Example**:\n```\nDATABASE_URL=postgresql://admin:secure_password@localhost:5432/alert_router?schema=public\n```\n\n#### Connection Pool Settings\n\nConfigure Prisma connection pool in `prisma/schema.prisma`:\n\n```prisma\ndatasource db {\n  provider = \"postgresql\"\n  url      = env(\"DATABASE_URL\")\n}\n\ngenerator client {\n  provider = \"prisma-client-js\"\n  previewFeatures = [\"postgresqlExtensions\"]\n}\n```\n\n### Redis Configuration\n\nConfigure Redis for caching and deduplication:\n\n```env\nREDIS_URL=redis://localhost:6379\nREDIS_PASSWORD=your-redis-password  # If authentication enabled\nREDIS_TLS=false                      # Set to true for TLS connections\n```\n\n### Email Configuration\n\n#### SMTP Configuration\n\n```env\nSMTP_HOST=smtp.gmail.com\nSMTP_PORT=587\nSMTP_SECURE=false\nSMTP_USER=your-email@gmail.com\nSMTP_PASSWORD=your-app-password\nEMAIL_FROM=Alert Router <alerts@example.com>\n```\n\n#### SendGrid Configuration\n\n```env\nSENDGRID_API_KEY=SG.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nEMAIL_FROM=Alert Router <alerts@example.com>\n```\n\n### Slack Configuration\n\n1. **Create a Slack App**\n   - Go to https://api.slack.com/apps\n   - Click \"Create New App\"\n   - Choose \"From scratch\"\n   - Name your app \"Alert Router\"\n\n2. **Add Bot Token Scopes**\n   - Navigate to \"OAuth & Permissions\"\n   - Add scopes: `chat:write`, `chat:write.public`, `channels:read`, `users:read`\n\n3. **Install App to Workspace**\n   - Click \"Install to Workspace\"\n   - Copy the \"Bot User OAuth Token\"\n\n4. **Configure Environment Variables**\n```env\nSLACK_BOT_TOKEN=xoxb-your-bot-token\nSLACK_SIGNING_SECRET=your-signing-secret\n```\n\n5. **Invite Bot to Channels**\n```\n/invite @AlertRouter\n```\n\n### PagerDuty Configuration\n\n1. **Create API Key**\n   - Go to PagerDuty â†’ Configuration â†’ API Access\n   - Create a new API key with full access\n\n2. **Get Service Integration Key**\n   - Navigate to Services â†’ Your Service â†’ Integrations\n   - Create \"Events API V2\" integration\n   - Copy the Integration Key\n\n3. **Configure Environment Variables**\n```env\nPAGERDUTY_API_KEY=your-api-key\nPAGERDUTY_EMAIL=your-email@example.com\n```\n\n---\n\n## Core Concepts\n\n### Alerts\n\nAn **alert** is a notification about an event or condition that requires attention. Alerts have:\n\n- **Source**: Where the alert came from (e.g., Prometheus, Grafana, custom app)\n- **Severity**: Critical, high, medium, or low\n- **Status**: Open, acknowledged, resolved, or suppressed\n- **Labels**: Key-value pairs for categorization (e.g., `environment: production`)\n- **Fingerprint**: Unique identifier for deduplication\n\n### Teams\n\nA **team** is a group of users responsible for handling specific types of alerts. Teams have:\n\n- **Members**: Users assigned to the team\n- **On-call Schedule**: Rotating on-call assignments\n- **Notification Channels**: Preferred communication methods\n- **Escalation Policies**: Rules for escalating unacknowledged alerts\n\n### Routing Rules\n\n**Routing rules** determine which team receives an alert based on conditions like:\n\n- Alert severity\n- Alert source\n- Label matching\n- Regex patterns\n\nRules are evaluated in priority order, and the first matching rule determines the target team.\n\n### Notification Channels\n\n**Notification channels** are the methods used to deliver alerts:\n\n- **Email**: Send alerts to team email addresses or individual members\n- **Slack**: Post alerts to Slack channels or direct messages\n- **PagerDuty**: Create incidents in PagerDuty\n\n### Escalation Policies\n\n**Escalation policies** define what happens when alerts are not acknowledged within a timeout period:\n\n- **Level 1**: Initial notification to primary team (timeout: 15 minutes)\n- **Level 2**: Escalate to secondary team (timeout: 30 minutes)\n- **Level 3**: Escalate to leadership or on-call manager\n\n### Deduplication\n\n**Deduplication** prevents multiple identical alerts from being sent. Alerts with the same fingerprint within a time window are merged into a single alert with an incremented count.\n\n---\n\n## Managing Teams\n\n### Creating a Team\n\n#### Via API\n\n```bash\ncurl -X POST http://localhost:3000/api/teams \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Platform Team\",\n    \"description\": \"Infrastructure and platform services\",\n    \"email\": \"platform@example.com\",\n    \"slackChannelId\": \"C123456789\",\n    \"pagerdutyServiceId\": \"PSERVICE1\"\n  }'\n```\n\n#### Via Dashboard\n\n1. Navigate to **Teams** â†’ **Create Team**\n2. Fill in team details:\n   - Team name\n   - Description\n   - Contact email\n   - Slack channel ID (optional)\n   - PagerDuty service ID (optional)\n3. Click **Create Team**\n\n### Adding Team Members\n\n#### Via API\n\n```bash\ncurl -X POST http://localhost:3000/api/teams/{teamId}/members \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"userId\": \"user-id-123\",\n    \"role\": \"member\"\n  }'\n```\n\n#### Via Dashboard\n\n1. Navigate to **Teams** â†’ Select team â†’ **Members**\n2. Click **Add Member**\n3. Select user from dropdown\n4. Assign role (member, lead, manager)\n5. Click **Add**\n\n### Setting On-Call Schedules\n\n#### Mark User as On-Call\n\n```bash\ncurl -X PATCH http://localhost:3000/api/teams/{teamId}/members/{userId} \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"isOnCall\": true,\n    \"onCallStart\": \"2025-11-18T00:00:00Z\",\n    \"onCallEnd\": \"2025-11-25T00:00:00Z\"\n  }'\n```\n\n#### Via Dashboard\n\n1. Navigate to **Teams** â†’ Select team â†’ **On-Call Schedule**\n2. Click **Edit Schedule**\n3. Select user and set on-call period\n4. Save changes\n\n---\n\n## Creating Routing Rules\n\nRouting rules determine how alerts are distributed to teams.\n\n### Rule Structure\n\nA routing rule consists of:\n\n- **Name**: Descriptive name (e.g., \"Production Critical Alerts\")\n- **Priority**: Higher numbers evaluated first (0-1000)\n- **Enabled**: Whether the rule is active\n- **Match Type**: `all` (AND), `any` (OR), or `regex`\n- **Conditions**: Criteria for matching alerts\n- **Target Team**: Team to receive matching alerts\n- **Notification Channels**: Which channels to use\n\n### Example: Route Critical Production Alerts\n\n```bash\ncurl -X POST http://localhost:3000/api/rules \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Production Critical Alerts\",\n    \"description\": \"Route all critical alerts from production to Platform team\",\n    \"priority\": 100,\n    \"enabled\": true,\n    \"matchType\": \"all\",\n    \"conditions\": {\n      \"severity\": [\"critical\"],\n      \"labels\": {\n        \"environment\": \"production\"\n      }\n    },\n    \"targetTeamId\": \"team-platform-id\",\n    \"notificationChannels\": [\"email\", \"slack\", \"pagerduty\"]\n  }'\n```\n\n### Example: Route Database Alerts\n\n```json\n{\n  \"name\": \"Database Alerts\",\n  \"priority\": 90,\n  \"enabled\": true,\n  \"matchType\": \"any\",\n  \"conditions\": {\n    \"source\": [\"prometheus\"],\n    \"labels\": {\n      \"component\": \"database\"\n    }\n  },\n  \"targetTeamId\": \"team-database-id\",\n  \"notificationChannels\": [\"email\", \"slack\"]\n}\n```\n\n### Example: Route by Regex Pattern\n\n```json\n{\n  \"name\": \"API Error Alerts\",\n  \"priority\": 80,\n  \"enabled\": true,\n  \"matchType\": \"regex\",\n  \"conditions\": {\n    \"title\": \".*API.*error.*\",\n    \"labels\": {\n      \"service\": \"api-.*\"\n    }\n  },\n  \"targetTeamId\": \"team-backend-id\",\n  \"notificationChannels\": [\"slack\"]\n}\n```\n\n### Rule Priority and Evaluation\n\nRules are evaluated in **descending priority order** (highest first). The **first matching rule** determines the target team.\n\n**Example Priority Scheme**:\n- **100-199**: Critical production alerts\n- **80-99**: High-priority service-specific alerts\n- **50-79**: Medium-priority alerts\n- **1-49**: Low-priority and catch-all rules\n- **0**: Default rule (no conditions, matches everything)\n\n### Testing Rules\n\nBefore enabling a rule, test it against sample alerts:\n\n```bash\ncurl -X POST http://localhost:3000/api/rules/test \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"rule\": {\n      \"matchType\": \"all\",\n      \"conditions\": {\n        \"severity\": [\"critical\"],\n        \"labels\": {\n          \"environment\": \"production\"\n        }\n      }\n    },\n    \"alert\": {\n      \"severity\": \"critical\",\n      \"labels\": {\n        \"environment\": \"production\",\n        \"service\": \"api\"\n      }\n    }\n  }'\n```\n\n**Response**:\n```json\n{\n  \"matches\": true,\n  \"explanation\": \"Alert matches all conditions\"\n}\n```\n\n---\n\n## Setting Up Notification Channels\n\n### Email Notifications\n\nEmail notifications are sent to:\n- Team email address\n- On-call team members\n- Individual users (if specified)\n\n**Email Template Customization**:\n\nEdit `src/templates/email/alert.hbs`:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Alert Notification</title>\n</head>\n<body>\n    <h2>{{ severity }} Alert: {{ title }}</h2>\n    <p><strong>Source:</strong> {{ source }}</p>\n    <p><strong>Description:</strong> {{ description }}</p>\n    <p><strong>Time:</strong> {{ createdAt }}</p>\n    <p><strong>Labels:</strong></p>\n    <ul>\n        {{#each labels}}\n        <li>{{ @key }}: {{ this }}</li>\n        {{/each}}\n    </ul>\n    <a href=\"{{ alertUrl }}\">View Alert</a>\n</body>\n</html>\n```\n\n### Slack Notifications\n\n#### 1. Configure Slack Channel\n\nWhen creating a team, specify the Slack channel ID:\n\n```json\n{\n  \"name\": \"Platform Team\",\n  \"slackChannelId\": \"C123456789\"\n}\n```\n\nTo find a channel ID:\n1. Right-click on the channel in Slack\n2. Select \"View channel details\"\n3. Scroll down to find the Channel ID\n\n#### 2. Customize Slack Message Format\n\nEdit `src/services/notificationChannels/slackProvider.ts`:\n\n```typescript\nconst message = {\n    channel: channelId,\n    text: `*${alert.severity.toUpperCase()}* Alert`,\n    blocks: [\n        {\n            type: 'header',\n            text: {\n                type: 'plain_text',\n                text: `ğŸš¨ ${alert.severity.toUpperCase()} Alert`\n            }\n        },\n        {\n            type: 'section',\n            fields: [\n                {\n                    type: 'mrkdwn',\n                    text: `*Title:*\\n${alert.title}`\n                },\n                {\n                    type: 'mrkdwn',\n                    text: `*Source:*\\n${alert.source}`\n                }\n            ]\n        },\n        {\n            type: 'section',\n            text: {\n                type: 'mrkdwn',\n                text: `*Description:*\\n${alert.description}`\n            }\n        },\n        {\n            type: 'actions',\n            elements: [\n                {\n                    type: 'button',\n                    text: {\n                        type: 'plain_text',\n                        text: 'Acknowledge'\n                    },\n                    value: alert.id,\n                    action_id: 'acknowledge_alert'\n                },\n                {\n                    type: 'button',\n                    text: {\n                        type: 'plain_text',\n                        text: 'Resolve'\n                    },\n                    value: alert.id,\n                    action_id: 'resolve_alert',\n                    style: 'primary'\n                }\n            ]\n        }\n    ]\n};\n```\n\n### PagerDuty Integration\n\n#### 1. Configure PagerDuty Service\n\nWhen creating a team, specify the PagerDuty service ID:\n\n```json\n{\n  \"name\": \"Platform Team\",\n  \"pagerdutyServiceId\": \"PSERVICE1\"\n}\n```\n\n#### 2. Severity Mapping\n\nPagerDuty incidents are created with severity mapping:\n\n- **Critical** â†’ PagerDuty P1\n- **High** â†’ PagerDuty P2\n- **Medium** â†’ PagerDuty P3\n- **Low** â†’ PagerDuty P4\n\n#### 3. Incident Synchronization\n\nWhen an alert is acknowledged or resolved in Alert Router, the corresponding PagerDuty incident is automatically updated.\n\n---\n\n## Working with Alerts\n\n### Creating Alerts\n\n#### Via API\n\n```bash\ncurl -X POST http://localhost:3000/api/alerts \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\": \"prometheus\",\n    \"externalId\": \"alert-12345\",\n    \"title\": \"High CPU Usage on prod-server-01\",\n    \"description\": \"CPU usage exceeded 90% threshold for 5 minutes\",\n    \"severity\": \"high\",\n    \"labels\": {\n      \"environment\": \"production\",\n      \"service\": \"api\",\n      \"instance\": \"prod-server-01\",\n      \"region\": \"us-east-1\"\n    },\n    \"metadata\": {\n      \"metric\": \"cpu_usage_percent\",\n      \"threshold\": 90,\n      \"current_value\": 95.3,\n      \"duration_minutes\": 5\n    }\n  }'\n```\n\n#### Via Dashboard\n\n1. Navigate to **Alerts** â†’ **Create Alert**\n2. Fill in alert details\n3. Add labels (key-value pairs)\n4. Click **Create**\n\n### Viewing Alerts\n\n#### List All Alerts\n\n```bash\ncurl http://localhost:3000/api/alerts \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n#### Filter Alerts\n\n```bash\n# By severity\ncurl \"http://localhost:3000/api/alerts?severity=critical\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n\n# By status\ncurl \"http://localhost:3000/api/alerts?status=open\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n\n# By team\ncurl \"http://localhost:3000/api/alerts?teamId=team-123\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n\n# Multiple filters\ncurl \"http://localhost:3000/api/alerts?severity=critical&status=open&environment=production\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n#### Pagination\n\n```bash\ncurl \"http://localhost:3000/api/alerts?limit=20&offset=0\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n### Acknowledging Alerts\n\n```bash\ncurl -X POST http://localhost:3000/api/alerts/{alertId}/acknowledge \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n**Response**:\n```json\n{\n  \"id\": \"alert-123\",\n  \"status\": \"acknowledged\",\n  \"acknowledgedBy\": \"user-456\",\n  \"acknowledgedAt\": \"2025-11-18T10:30:00Z\"\n}\n```\n\n### Resolving Alerts\n\n```bash\ncurl -X POST http://localhost:3000/api/alerts/{alertId}/resolve \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resolution\": \"Increased CPU capacity by adding 2 more instances\"\n  }'\n```\n\n### Suppressing Alerts\n\nTemporarily suppress alerts (e.g., during maintenance):\n\n```bash\ncurl -X POST http://localhost:3000/api/alerts/{alertId}/suppress \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"reason\": \"Scheduled maintenance window\",\n    \"suppressUntil\": \"2025-11-18T14:00:00Z\"\n  }'\n```\n\n### Alert History\n\nView complete alert history including state changes:\n\n```bash\ncurl http://localhost:3000/api/alerts/{alertId}/history \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n---\n\n## Escalation Policies\n\nEscalation policies ensure that unacknowledged critical alerts are escalated to higher-level teams or on-call managers.\n\n### Creating an Escalation Policy\n\n```bash\ncurl -X POST http://localhost:3000/api/escalation-policies \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Platform Team Escalation\",\n    \"description\": \"Escalation policy for platform alerts\",\n    \"teamId\": \"team-platform-id\",\n    \"enabled\": true,\n    \"levels\": [\n      {\n        \"level\": 1,\n        \"timeout_minutes\": 15,\n        \"target_team_id\": \"team-platform-id\",\n        \"channels\": [\"email\", \"slack\"]\n      },\n      {\n        \"level\": 2,\n        \"timeout_minutes\": 30,\n        \"target_team_id\": \"team-senior-engineers-id\",\n        \"channels\": [\"slack\", \"pagerduty\"]\n      },\n      {\n        \"level\": 3,\n        \"timeout_minutes\": 60,\n        \"target_team_id\": \"team-leadership-id\",\n        \"channels\": [\"pagerduty\"]\n      }\n    ]\n  }'\n```\n\n### How Escalation Works\n\n1. **Alert Created**: Alert is sent to Level 1 team\n2. **Timeout Check**: System checks every 5 minutes for unacknowledged alerts\n3. **Escalation Triggered**: If alert remains unacknowledged after timeout, escalate to Level 2\n4. **Repeat**: Continue escalating through levels until alert is acknowledged or final level reached\n5. **Acknowledgment**: Escalation stops when alert is acknowledged at any level\n\n### Viewing Active Escalations\n\n```bash\ncurl http://localhost:3000/api/escalation-policies \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n---\n\n## API Usage\n\n### Authentication\n\nAll API requests require JWT authentication via the `Authorization` header.\n\n#### Register a User\n\n```bash\ncurl -X POST http://localhost:3000/api/auth/register \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"user@example.com\",\n    \"username\": \"johndoe\",\n    \"password\": \"SecurePassword123!\",\n    \"fullName\": \"John Doe\"\n  }'\n```\n\n#### Login\n\n```bash\ncurl -X POST http://localhost:3000/api/auth/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"user@example.com\",\n    \"password\": \"SecurePassword123!\"\n  }'\n```\n\n**Response**:\n```json\n{\n  \"accessToken\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"refreshToken\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"user\": {\n    \"id\": \"user-123\",\n    \"email\": \"user@example.com\",\n    \"username\": \"johndoe\",\n    \"role\": \"user\"\n  }\n}\n```\n\n#### Use Access Token\n\n```bash\ncurl http://localhost:3000/api/alerts \\\n  -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n```\n\n### API Documentation\n\nFull API documentation is available via Swagger:\n\n```\nhttp://localhost:3000/api-docs\n```\n\n---\n\n## Dashboard Guide\n\nThe web dashboard provides a user-friendly interface for managing alerts, teams, and routing rules.\n\n### Dashboard Overview\n\nThe main dashboard shows:\n\n- **Active Alerts**: Count of open, acknowledged, and resolved alerts\n- **Alert Trends**: Time-series chart of alerts by severity\n- **Team Performance**: Average response times per team\n- **Notification Delivery**: Success rate by channel\n- **Recent Alerts**: List of latest alerts with quick actions\n\n### Managing Alerts\n\n1. **View All Alerts**: Navigate to **Alerts** page\n2. **Filter**: Use severity, status, team, and date filters\n3. **Acknowledge**: Click **Acknowledge** button next to alert\n4. **Resolve**: Click **Resolve** button and add resolution notes\n5. **Details**: Click alert title to view full details\n\n### Creating Teams\n\n1. Navigate to **Teams** â†’ **Create Team**\n2. Fill in team information\n3. Add members by searching for users\n4. Configure notification preferences\n5. Save team\n\n### Creating Routing Rules\n\n1. Navigate to **Rules** â†’ **Create Rule**\n2. Enter rule name and description\n3. Set priority (higher = evaluated first)\n4. Choose match type (all, any, regex)\n5. Add conditions:\n   - Severity\n   - Source\n   - Labels\n6. Select target team\n7. Choose notification channels\n8. Test rule (optional)\n9. Enable and save\n\n### Analytics\n\nNavigate to **Analytics** to view:\n\n- **Alert Volume**: Daily/weekly/monthly alert counts\n- **Response Times**: Average time to acknowledge and resolve\n- **Team Performance**: Alerts handled per team\n- **Channel Performance**: Delivery success rates\n- **MTTR**: Mean Time To Resolution\n\n---\n\n## Best Practices\n\n### Routing Rules\n\n1. **Use Clear Naming**: Name rules descriptively (e.g., \"Production Database Critical Alerts\")\n2. **Set Appropriate Priorities**: Critical alerts should have highest priority rules\n3. **Test Before Enabling**: Always test rules with sample alerts\n4. **Avoid Overlapping Rules**: Ensure rules don't conflict (first match wins)\n5. **Default Catch-All Rule**: Create a low-priority rule that matches everything as a fallback\n\n### Alert Management\n\n1. **Acknowledge Promptly**: Acknowledge alerts within 5 minutes to prevent escalation\n2. **Add Context**: When resolving, add notes about resolution steps\n3. **Use Labels Consistently**: Standardize label keys (environment, service, region)\n4. **Set Appropriate Severity**: Reserve \"critical\" for truly critical issues\n5. **Clean Up Resolved Alerts**: Archive or delete old resolved alerts periodically\n\n### Team Organization\n\n1. **Logical Grouping**: Group users by responsibility (e.g., Database Team, API Team)\n2. **On-Call Rotation**: Maintain fair on-call rotation schedules\n3. **Multiple Teams**: Users can be members of multiple teams\n4. **Team Hierarchy**: Set up escalation chains (Level 1 â†’ Level 2 â†’ Level 3)\n\n### Notification Channels\n\n1. **Channel Selection**: Use appropriate channels based on severity\n   - **Email**: Low to medium severity\n   - **Slack**: Medium to high severity\n   - **PagerDuty**: High to critical severity\n2. **Avoid Alert Fatigue**: Don't send all alerts to all channels\n3. **Test Integrations**: Regularly test Slack and PagerDuty integrations\n4. **Monitor Delivery**: Check notification delivery success rates\n\n### Security\n\n1. **Strong Passwords**: Enforce strong password policies\n2. **JWT Secrets**: Use strong, randomly generated JWT secrets\n3. **API Keys**: Rotate API keys regularly\n4. **Rate Limiting**: Enable rate limiting to prevent abuse\n5. **HTTPS Only**: Always use HTTPS in production\n\n---\n\n## Troubleshooting\n\n### Common Issues\n\n#### Alerts Not Being Routed\n\n**Symptoms**: Alerts are created but not assigned to any team\n\n**Solutions**:\n1. Check if any routing rules are enabled\n2. Verify rule conditions match alert properties\n3. Check rule priority order\n4. Create a default catch-all rule\n\n```bash\n# Check active rules\ncurl http://localhost:3000/api/rules?enabled=true \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n#### Notifications Not Sending\n\n**Symptoms**: Alerts are routed but notifications fail\n\n**Solutions**:\n\n**Email Issues**:\n1. Verify SMTP credentials in `.env`\n2. Check firewall allows SMTP port (587/465)\n3. Review logs: `docker logs alert-router | grep email`\n\n```bash\n# Test email configuration\nnpm run test:email\n```\n\n**Slack Issues**:\n1. Verify Slack bot token is valid\n2. Check bot is invited to channels\n3. Verify bot has correct permissions\n\n```bash\n# Test Slack integration\nnpm run test:slack\n```\n\n**PagerDuty Issues**:\n1. Verify API key is valid\n2. Check service ID is correct\n3. Review PagerDuty incident creation logs\n\n#### Database Connection Errors\n\n**Symptoms**: `ECONNREFUSED` or connection timeout errors\n\n**Solutions**:\n1. Verify PostgreSQL is running: `docker ps`\n2. Check DATABASE_URL format\n3. Ensure database exists: `psql -U user -l`\n4. Run migrations: `npx prisma migrate deploy`\n\n#### Redis Connection Errors\n\n**Symptoms**: Deduplication not working, caching errors\n\n**Solutions**:\n1. Verify Redis is running: `docker ps`\n2. Check REDIS_URL format\n3. Test Redis connection: `redis-cli ping`\n\n#### High Memory Usage\n\n**Symptoms**: Application consuming excessive memory\n\n**Solutions**:\n1. Enable connection pooling\n2. Adjust Prisma connection pool size\n3. Review queue size limits\n4. Monitor for memory leaks with Clinic.js\n\n```bash\n# Profile memory usage\nnpm run profile:memory\n```\n\n### Debugging\n\nEnable debug logging:\n\n```env\nLOG_LEVEL=debug\n```\n\nView application logs:\n\n```bash\n# Docker\ndocker logs -f alert-router\n\n# Local\ntail -f logs/app.log\n```\n\nEnable Prisma query logging:\n\n```typescript\n// In instrument.ts or prisma setup\nconst prisma = new PrismaClient({\n    log: ['query', 'info', 'warn', 'error'],\n});\n```\n\n### Getting Help\n\n1. **Check Logs**: Review application logs for errors\n2. **GitHub Issues**: Search for similar issues at https://github.com/your-org/alert-router/issues\n3. **Documentation**: Review API documentation at `/api-docs`\n4. **Support**: Contact support at support@example.com\n\n---\n\n## FAQ\n\n### General Questions\n\n**Q: Can I integrate with monitoring systems like Prometheus or Grafana?**\n\nA: Yes! Configure your monitoring system to send alerts to our API endpoint:\n```\nPOST http://your-domain.com/api/alerts\n```\n\n**Q: How many alerts can the system handle?**\n\nA: The system can handle 1000+ alerts per minute with proper infrastructure (PostgreSQL, Redis, multiple workers).\n\n**Q: Is there a mobile app?**\n\nA: Not yet, but it's on the roadmap. For now, use Slack or PagerDuty mobile apps for notifications.\n\n### Routing & Notifications\n\n**Q: What happens if no routing rule matches an alert?**\n\nA: If no rule matches, the alert is created but not assigned to any team. Create a default catch-all rule to prevent this.\n\n**Q: Can I route the same alert to multiple teams?**\n\nA: Currently, each alert is routed to one team. Use escalation policies to notify additional teams after a timeout.\n\n**Q: How quickly are notifications sent?**\n\nA: Notifications are sent within 5 seconds of alert creation (target p95 performance).\n\n### Deduplication\n\n**Q: How long is the deduplication window?**\n\nA: Default is 5 minutes, configurable via `DEDUPLICATION_WINDOW_MINUTES` environment variable.\n\n**Q: What happens to duplicate alerts?**\n\nA: Duplicates increment a counter on the original alert and update the \"last seen\" timestamp.\n\n### Escalation\n\n**Q: Can I skip escalation levels?**\n\nA: No, escalation proceeds sequentially through levels. Design your policy with appropriate timeout values.\n\n**Q: What stops an escalation?**\n\nA: Acknowledging or resolving the alert stops all escalation.\n\n### Security\n\n**Q: How are API keys and passwords stored?**\n\nA: Passwords are hashed with bcrypt (12 rounds). API keys are encrypted at rest.\n\n**Q: Can I use SSO/SAML for authentication?**\n\nA: SAML/SSO support is planned for a future release.\n\n**Q: Is the system GDPR compliant?**\n\nA: Yes, audit logs can be configured to anonymize personal data.\n\n### Performance\n\n**Q: How do I scale the system for high load?**\n\nA: Run multiple application instances behind a load balancer. Use PostgreSQL read replicas and Redis cluster.\n\n**Q: What are the resource requirements?**\n\nA: Minimum: 2 CPU cores, 4GB RAM. Recommended: 4+ cores, 8GB+ RAM for production.\n\n---\n\n## Conclusion\n\nYou're now ready to use the Alert Notification Router! For more advanced topics, refer to:\n\n- [Development Plan](../plan/DevelopmentPlan.md) - Architecture and implementation details\n- [Testing Plan](../testing/TestingPlan.md) - Testing strategy and test cases\n- [API Documentation](http://localhost:3000/api-docs) - Full API reference\n\nNeed help? Contact support@example.com or open an issue on GitHub.\n\n---\n\n**Version**: 1.0.0\n**Last Updated**: November 18, 2025\n**License**: MIT\n"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":13039,"cache_read_input_tokens":52682,"cache_creation":{"ephemeral_5m_input_tokens":13039,"ephemeral_1h_input_tokens":0},"output_tokens":9412,"service_tier":"standard"}},"requestId":"req_011CVFVDi7Lq6PURTK5BTeS4","type":"assistant","uuid":"6a9c8c73-a75d-4be3-8327-0692d7afbcd3","timestamp":"2025-11-18T14:11:29.708Z"}
{"parentUuid":"6a9c8c73-a75d-4be3-8327-0692d7afbcd3","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011jK5BrZL3sh4mHqYvQ1T5Y","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"feca2d7c-de46-4279-956f-f6e23ad22ed0","timestamp":"2025-11-18T14:11:29.880Z","toolUseResult":{"oldTodos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"completed","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"in_progress","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"pending","activeForm":"Creating Guide.md with user documentation"}],"newTodos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"completed","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"completed","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"in_progress","activeForm":"Creating Guide.md with user documentation"}]}}
{"type":"file-history-snapshot","messageId":"6a9c8c73-a75d-4be3-8327-0692d7afbcd3","snapshot":{"messageId":"a89c95da-4d38-4a9b-a8a1-8baeb5e10eb6","trackedFileBackups":{"docs/plan/DevelopmentPlan.md":{"backupFileName":null,"version":1,"backupTime":"2025-11-18T14:06:34.807Z"},"docs/testing/TestingPlan.md":{"backupFileName":null,"version":1,"backupTime":"2025-11-18T14:09:09.526Z"},"docs/guides/Guide.md":{"backupFileName":null,"version":1,"backupTime":"2025-11-18T14:11:29.983Z"}},"timestamp":"2025-11-18T14:01:07.522Z"},"isSnapshotUpdate":true}
{"parentUuid":"feca2d7c-de46-4279-956f-f6e23ad22ed0","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QYxAwhYApcB3wxQucmUYSs","type":"tool_result","content":"File created successfully at: /root/Claude/claude-hooks/docs/guides/Guide.md"}]},"uuid":"1f9ba91d-a07e-4269-ace5-f2e3ecdbf13c","timestamp":"2025-11-18T14:11:29.994Z","toolUseResult":{"type":"create","filePath":"/root/Claude/claude-hooks/docs/guides/Guide.md","content":"# Alert Notification Router - User Guide\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n2. [Getting Started](#getting-started)\n3. [Installation](#installation)\n4. [Configuration](#configuration)\n5. [Core Concepts](#core-concepts)\n6. [Managing Teams](#managing-teams)\n7. [Creating Routing Rules](#creating-routing-rules)\n8. [Setting Up Notification Channels](#setting-up-notification-channels)\n9. [Working with Alerts](#working-with-alerts)\n10. [Escalation Policies](#escalation-policies)\n11. [API Usage](#api-usage)\n12. [Dashboard Guide](#dashboard-guide)\n13. [Best Practices](#best-practices)\n14. [Troubleshooting](#troubleshooting)\n15. [FAQ](#faq)\n\n---\n\n## Introduction\n\n### What is Alert Notification Router?\n\nAlert Notification Router is an intelligent alert management system that automatically routes alerts to the appropriate teams based on configurable rules. It supports multiple notification channels (Email, Slack, PagerDuty), provides alert deduplication, priority handling, escalation policies, and comprehensive delivery tracking.\n\n### Key Features\n\n- **Intelligent Routing**: Automatically route alerts to the right team based on severity, source, labels, and custom conditions\n- **Multi-Channel Notifications**: Send alerts via Email, Slack, and PagerDuty\n- **Alert Deduplication**: Prevent duplicate alerts from overwhelming your teams\n- **Priority Management**: Prioritize critical alerts for faster response\n- **Escalation Policies**: Automatically escalate unacknowledged alerts to higher-level teams\n- **Delivery Tracking**: Monitor notification delivery status and retry failed deliveries\n- **Team Management**: Organize users into teams with on-call schedules\n- **Analytics Dashboard**: Track alert metrics, response times, and team performance\n\n### Who Should Use This?\n\n- **DevOps Teams**: Monitor infrastructure and application alerts\n- **SRE Teams**: Manage incident response and on-call rotations\n- **Engineering Teams**: Route alerts to appropriate service owners\n- **Operations Teams**: Centralize alert management across multiple systems\n\n---\n\n## Getting Started\n\n### Prerequisites\n\nBefore installing Alert Notification Router, ensure you have:\n\n- **Node.js** v20 or higher\n- **PostgreSQL** v15 or higher\n- **Redis** v7 or higher\n- **Docker** (optional, for containerized deployment)\n- **SMTP server** or **SendGrid account** (for email notifications)\n- **Slack workspace** (optional, for Slack notifications)\n- **PagerDuty account** (optional, for PagerDuty integration)\n\n### Quick Start (5 Minutes)\n\n1. **Clone the repository**\n```bash\ngit clone https://github.com/your-org/alert-notification-router.git\ncd alert-notification-router\n```\n\n2. **Install dependencies**\n```bash\nnpm install\n```\n\n3. **Set up environment variables**\n```bash\ncp .env.example .env\n# Edit .env with your configuration\n```\n\n4. **Start Docker services**\n```bash\ndocker-compose up -d postgres redis\n```\n\n5. **Run database migrations**\n```bash\nnpx prisma migrate deploy\n```\n\n6. **Seed initial data** (optional)\n```bash\nnpm run seed\n```\n\n7. **Start the application**\n```bash\nnpm run dev\n```\n\n8. **Access the dashboard**\nOpen your browser to `http://localhost:3000`\n\n---\n\n## Installation\n\n### Option 1: Local Development Setup\n\n#### 1. Install Dependencies\n\n```bash\nnpm install\n```\n\n#### 2. Configure Environment Variables\n\nCreate a `.env` file in the project root:\n\n```env\n# Application\nNODE_ENV=development\nPORT=3000\nAPI_BASE_URL=http://localhost:3000\n\n# Database\nDATABASE_URL=postgresql://user:password@localhost:5432/alert_router\n\n# Redis\nREDIS_URL=redis://localhost:6379\n\n# JWT Authentication\nJWT_SECRET=your-secret-key-change-this-in-production\nJWT_EXPIRY=15m\nJWT_REFRESH_EXPIRY=7d\n\n# Email Configuration\nSMTP_HOST=smtp.gmail.com\nSMTP_PORT=587\nSMTP_SECURE=false\nSMTP_USER=your-email@gmail.com\nSMTP_PASSWORD=your-app-password\nEMAIL_FROM=Alert Router <alerts@example.com>\n\n# Slack Integration\nSLACK_BOT_TOKEN=xoxb-your-bot-token\nSLACK_SIGNING_SECRET=your-signing-secret\n\n# PagerDuty Integration\nPAGERDUTY_API_KEY=your-api-key\nPAGERDUTY_EMAIL=your-email@example.com\n\n# Sentry (Error Tracking)\nSENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id\n\n# Logging\nLOG_LEVEL=info\n\n# Deduplication\nDEDUPLICATION_WINDOW_MINUTES=5\n\n# Escalation\nESCALATION_CHECK_INTERVAL_MINUTES=5\n```\n\n#### 3. Start PostgreSQL and Redis\n\nUsing Docker:\n```bash\ndocker-compose up -d postgres redis\n```\n\nOr install locally (macOS):\n```bash\nbrew install postgresql redis\nbrew services start postgresql\nbrew services start redis\n```\n\n#### 4. Run Database Migrations\n\n```bash\nnpx prisma migrate deploy\n```\n\n#### 5. Start the Application\n\n```bash\n# Development mode with hot reload\nnpm run dev\n\n# Production mode\nnpm run build\nnpm start\n```\n\n### Option 2: Docker Deployment\n\n#### 1. Build Docker Image\n\n```bash\ndocker build -t alert-router:latest .\n```\n\n#### 2. Run with Docker Compose\n\n```bash\ndocker-compose up -d\n```\n\nThis will start:\n- Application server (port 3000)\n- PostgreSQL database (port 5432)\n- Redis cache (port 6379)\n\n### Option 3: Cloud Deployment\n\n#### Deploy to AWS ECS\n\n1. Build and push Docker image to ECR\n2. Create ECS task definition\n3. Set up RDS PostgreSQL and ElastiCache Redis\n4. Configure environment variables in ECS task\n5. Create ECS service with load balancer\n\n#### Deploy to Google Cloud Run\n\n```bash\n# Build and push to GCR\ngcloud builds submit --tag gcr.io/PROJECT_ID/alert-router\n\n# Deploy to Cloud Run\ngcloud run deploy alert-router \\\n  --image gcr.io/PROJECT_ID/alert-router \\\n  --platform managed \\\n  --region us-central1 \\\n  --set-env-vars DATABASE_URL=postgresql://...\n```\n\n---\n\n## Configuration\n\n### Database Configuration\n\n#### PostgreSQL Connection\n\nThe `DATABASE_URL` environment variable configures the PostgreSQL connection:\n\n```\npostgresql://[user]:[password]@[host]:[port]/[database]?schema=public\n```\n\n**Example**:\n```\nDATABASE_URL=postgresql://admin:secure_password@localhost:5432/alert_router?schema=public\n```\n\n#### Connection Pool Settings\n\nConfigure Prisma connection pool in `prisma/schema.prisma`:\n\n```prisma\ndatasource db {\n  provider = \"postgresql\"\n  url      = env(\"DATABASE_URL\")\n}\n\ngenerator client {\n  provider = \"prisma-client-js\"\n  previewFeatures = [\"postgresqlExtensions\"]\n}\n```\n\n### Redis Configuration\n\nConfigure Redis for caching and deduplication:\n\n```env\nREDIS_URL=redis://localhost:6379\nREDIS_PASSWORD=your-redis-password  # If authentication enabled\nREDIS_TLS=false                      # Set to true for TLS connections\n```\n\n### Email Configuration\n\n#### SMTP Configuration\n\n```env\nSMTP_HOST=smtp.gmail.com\nSMTP_PORT=587\nSMTP_SECURE=false\nSMTP_USER=your-email@gmail.com\nSMTP_PASSWORD=your-app-password\nEMAIL_FROM=Alert Router <alerts@example.com>\n```\n\n#### SendGrid Configuration\n\n```env\nSENDGRID_API_KEY=SG.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nEMAIL_FROM=Alert Router <alerts@example.com>\n```\n\n### Slack Configuration\n\n1. **Create a Slack App**\n   - Go to https://api.slack.com/apps\n   - Click \"Create New App\"\n   - Choose \"From scratch\"\n   - Name your app \"Alert Router\"\n\n2. **Add Bot Token Scopes**\n   - Navigate to \"OAuth & Permissions\"\n   - Add scopes: `chat:write`, `chat:write.public`, `channels:read`, `users:read`\n\n3. **Install App to Workspace**\n   - Click \"Install to Workspace\"\n   - Copy the \"Bot User OAuth Token\"\n\n4. **Configure Environment Variables**\n```env\nSLACK_BOT_TOKEN=xoxb-your-bot-token\nSLACK_SIGNING_SECRET=your-signing-secret\n```\n\n5. **Invite Bot to Channels**\n```\n/invite @AlertRouter\n```\n\n### PagerDuty Configuration\n\n1. **Create API Key**\n   - Go to PagerDuty â†’ Configuration â†’ API Access\n   - Create a new API key with full access\n\n2. **Get Service Integration Key**\n   - Navigate to Services â†’ Your Service â†’ Integrations\n   - Create \"Events API V2\" integration\n   - Copy the Integration Key\n\n3. **Configure Environment Variables**\n```env\nPAGERDUTY_API_KEY=your-api-key\nPAGERDUTY_EMAIL=your-email@example.com\n```\n\n---\n\n## Core Concepts\n\n### Alerts\n\nAn **alert** is a notification about an event or condition that requires attention. Alerts have:\n\n- **Source**: Where the alert came from (e.g., Prometheus, Grafana, custom app)\n- **Severity**: Critical, high, medium, or low\n- **Status**: Open, acknowledged, resolved, or suppressed\n- **Labels**: Key-value pairs for categorization (e.g., `environment: production`)\n- **Fingerprint**: Unique identifier for deduplication\n\n### Teams\n\nA **team** is a group of users responsible for handling specific types of alerts. Teams have:\n\n- **Members**: Users assigned to the team\n- **On-call Schedule**: Rotating on-call assignments\n- **Notification Channels**: Preferred communication methods\n- **Escalation Policies**: Rules for escalating unacknowledged alerts\n\n### Routing Rules\n\n**Routing rules** determine which team receives an alert based on conditions like:\n\n- Alert severity\n- Alert source\n- Label matching\n- Regex patterns\n\nRules are evaluated in priority order, and the first matching rule determines the target team.\n\n### Notification Channels\n\n**Notification channels** are the methods used to deliver alerts:\n\n- **Email**: Send alerts to team email addresses or individual members\n- **Slack**: Post alerts to Slack channels or direct messages\n- **PagerDuty**: Create incidents in PagerDuty\n\n### Escalation Policies\n\n**Escalation policies** define what happens when alerts are not acknowledged within a timeout period:\n\n- **Level 1**: Initial notification to primary team (timeout: 15 minutes)\n- **Level 2**: Escalate to secondary team (timeout: 30 minutes)\n- **Level 3**: Escalate to leadership or on-call manager\n\n### Deduplication\n\n**Deduplication** prevents multiple identical alerts from being sent. Alerts with the same fingerprint within a time window are merged into a single alert with an incremented count.\n\n---\n\n## Managing Teams\n\n### Creating a Team\n\n#### Via API\n\n```bash\ncurl -X POST http://localhost:3000/api/teams \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Platform Team\",\n    \"description\": \"Infrastructure and platform services\",\n    \"email\": \"platform@example.com\",\n    \"slackChannelId\": \"C123456789\",\n    \"pagerdutyServiceId\": \"PSERVICE1\"\n  }'\n```\n\n#### Via Dashboard\n\n1. Navigate to **Teams** â†’ **Create Team**\n2. Fill in team details:\n   - Team name\n   - Description\n   - Contact email\n   - Slack channel ID (optional)\n   - PagerDuty service ID (optional)\n3. Click **Create Team**\n\n### Adding Team Members\n\n#### Via API\n\n```bash\ncurl -X POST http://localhost:3000/api/teams/{teamId}/members \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"userId\": \"user-id-123\",\n    \"role\": \"member\"\n  }'\n```\n\n#### Via Dashboard\n\n1. Navigate to **Teams** â†’ Select team â†’ **Members**\n2. Click **Add Member**\n3. Select user from dropdown\n4. Assign role (member, lead, manager)\n5. Click **Add**\n\n### Setting On-Call Schedules\n\n#### Mark User as On-Call\n\n```bash\ncurl -X PATCH http://localhost:3000/api/teams/{teamId}/members/{userId} \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"isOnCall\": true,\n    \"onCallStart\": \"2025-11-18T00:00:00Z\",\n    \"onCallEnd\": \"2025-11-25T00:00:00Z\"\n  }'\n```\n\n#### Via Dashboard\n\n1. Navigate to **Teams** â†’ Select team â†’ **On-Call Schedule**\n2. Click **Edit Schedule**\n3. Select user and set on-call period\n4. Save changes\n\n---\n\n## Creating Routing Rules\n\nRouting rules determine how alerts are distributed to teams.\n\n### Rule Structure\n\nA routing rule consists of:\n\n- **Name**: Descriptive name (e.g., \"Production Critical Alerts\")\n- **Priority**: Higher numbers evaluated first (0-1000)\n- **Enabled**: Whether the rule is active\n- **Match Type**: `all` (AND), `any` (OR), or `regex`\n- **Conditions**: Criteria for matching alerts\n- **Target Team**: Team to receive matching alerts\n- **Notification Channels**: Which channels to use\n\n### Example: Route Critical Production Alerts\n\n```bash\ncurl -X POST http://localhost:3000/api/rules \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Production Critical Alerts\",\n    \"description\": \"Route all critical alerts from production to Platform team\",\n    \"priority\": 100,\n    \"enabled\": true,\n    \"matchType\": \"all\",\n    \"conditions\": {\n      \"severity\": [\"critical\"],\n      \"labels\": {\n        \"environment\": \"production\"\n      }\n    },\n    \"targetTeamId\": \"team-platform-id\",\n    \"notificationChannels\": [\"email\", \"slack\", \"pagerduty\"]\n  }'\n```\n\n### Example: Route Database Alerts\n\n```json\n{\n  \"name\": \"Database Alerts\",\n  \"priority\": 90,\n  \"enabled\": true,\n  \"matchType\": \"any\",\n  \"conditions\": {\n    \"source\": [\"prometheus\"],\n    \"labels\": {\n      \"component\": \"database\"\n    }\n  },\n  \"targetTeamId\": \"team-database-id\",\n  \"notificationChannels\": [\"email\", \"slack\"]\n}\n```\n\n### Example: Route by Regex Pattern\n\n```json\n{\n  \"name\": \"API Error Alerts\",\n  \"priority\": 80,\n  \"enabled\": true,\n  \"matchType\": \"regex\",\n  \"conditions\": {\n    \"title\": \".*API.*error.*\",\n    \"labels\": {\n      \"service\": \"api-.*\"\n    }\n  },\n  \"targetTeamId\": \"team-backend-id\",\n  \"notificationChannels\": [\"slack\"]\n}\n```\n\n### Rule Priority and Evaluation\n\nRules are evaluated in **descending priority order** (highest first). The **first matching rule** determines the target team.\n\n**Example Priority Scheme**:\n- **100-199**: Critical production alerts\n- **80-99**: High-priority service-specific alerts\n- **50-79**: Medium-priority alerts\n- **1-49**: Low-priority and catch-all rules\n- **0**: Default rule (no conditions, matches everything)\n\n### Testing Rules\n\nBefore enabling a rule, test it against sample alerts:\n\n```bash\ncurl -X POST http://localhost:3000/api/rules/test \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"rule\": {\n      \"matchType\": \"all\",\n      \"conditions\": {\n        \"severity\": [\"critical\"],\n        \"labels\": {\n          \"environment\": \"production\"\n        }\n      }\n    },\n    \"alert\": {\n      \"severity\": \"critical\",\n      \"labels\": {\n        \"environment\": \"production\",\n        \"service\": \"api\"\n      }\n    }\n  }'\n```\n\n**Response**:\n```json\n{\n  \"matches\": true,\n  \"explanation\": \"Alert matches all conditions\"\n}\n```\n\n---\n\n## Setting Up Notification Channels\n\n### Email Notifications\n\nEmail notifications are sent to:\n- Team email address\n- On-call team members\n- Individual users (if specified)\n\n**Email Template Customization**:\n\nEdit `src/templates/email/alert.hbs`:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Alert Notification</title>\n</head>\n<body>\n    <h2>{{ severity }} Alert: {{ title }}</h2>\n    <p><strong>Source:</strong> {{ source }}</p>\n    <p><strong>Description:</strong> {{ description }}</p>\n    <p><strong>Time:</strong> {{ createdAt }}</p>\n    <p><strong>Labels:</strong></p>\n    <ul>\n        {{#each labels}}\n        <li>{{ @key }}: {{ this }}</li>\n        {{/each}}\n    </ul>\n    <a href=\"{{ alertUrl }}\">View Alert</a>\n</body>\n</html>\n```\n\n### Slack Notifications\n\n#### 1. Configure Slack Channel\n\nWhen creating a team, specify the Slack channel ID:\n\n```json\n{\n  \"name\": \"Platform Team\",\n  \"slackChannelId\": \"C123456789\"\n}\n```\n\nTo find a channel ID:\n1. Right-click on the channel in Slack\n2. Select \"View channel details\"\n3. Scroll down to find the Channel ID\n\n#### 2. Customize Slack Message Format\n\nEdit `src/services/notificationChannels/slackProvider.ts`:\n\n```typescript\nconst message = {\n    channel: channelId,\n    text: `*${alert.severity.toUpperCase()}* Alert`,\n    blocks: [\n        {\n            type: 'header',\n            text: {\n                type: 'plain_text',\n                text: `ğŸš¨ ${alert.severity.toUpperCase()} Alert`\n            }\n        },\n        {\n            type: 'section',\n            fields: [\n                {\n                    type: 'mrkdwn',\n                    text: `*Title:*\\n${alert.title}`\n                },\n                {\n                    type: 'mrkdwn',\n                    text: `*Source:*\\n${alert.source}`\n                }\n            ]\n        },\n        {\n            type: 'section',\n            text: {\n                type: 'mrkdwn',\n                text: `*Description:*\\n${alert.description}`\n            }\n        },\n        {\n            type: 'actions',\n            elements: [\n                {\n                    type: 'button',\n                    text: {\n                        type: 'plain_text',\n                        text: 'Acknowledge'\n                    },\n                    value: alert.id,\n                    action_id: 'acknowledge_alert'\n                },\n                {\n                    type: 'button',\n                    text: {\n                        type: 'plain_text',\n                        text: 'Resolve'\n                    },\n                    value: alert.id,\n                    action_id: 'resolve_alert',\n                    style: 'primary'\n                }\n            ]\n        }\n    ]\n};\n```\n\n### PagerDuty Integration\n\n#### 1. Configure PagerDuty Service\n\nWhen creating a team, specify the PagerDuty service ID:\n\n```json\n{\n  \"name\": \"Platform Team\",\n  \"pagerdutyServiceId\": \"PSERVICE1\"\n}\n```\n\n#### 2. Severity Mapping\n\nPagerDuty incidents are created with severity mapping:\n\n- **Critical** â†’ PagerDuty P1\n- **High** â†’ PagerDuty P2\n- **Medium** â†’ PagerDuty P3\n- **Low** â†’ PagerDuty P4\n\n#### 3. Incident Synchronization\n\nWhen an alert is acknowledged or resolved in Alert Router, the corresponding PagerDuty incident is automatically updated.\n\n---\n\n## Working with Alerts\n\n### Creating Alerts\n\n#### Via API\n\n```bash\ncurl -X POST http://localhost:3000/api/alerts \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source\": \"prometheus\",\n    \"externalId\": \"alert-12345\",\n    \"title\": \"High CPU Usage on prod-server-01\",\n    \"description\": \"CPU usage exceeded 90% threshold for 5 minutes\",\n    \"severity\": \"high\",\n    \"labels\": {\n      \"environment\": \"production\",\n      \"service\": \"api\",\n      \"instance\": \"prod-server-01\",\n      \"region\": \"us-east-1\"\n    },\n    \"metadata\": {\n      \"metric\": \"cpu_usage_percent\",\n      \"threshold\": 90,\n      \"current_value\": 95.3,\n      \"duration_minutes\": 5\n    }\n  }'\n```\n\n#### Via Dashboard\n\n1. Navigate to **Alerts** â†’ **Create Alert**\n2. Fill in alert details\n3. Add labels (key-value pairs)\n4. Click **Create**\n\n### Viewing Alerts\n\n#### List All Alerts\n\n```bash\ncurl http://localhost:3000/api/alerts \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n#### Filter Alerts\n\n```bash\n# By severity\ncurl \"http://localhost:3000/api/alerts?severity=critical\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n\n# By status\ncurl \"http://localhost:3000/api/alerts?status=open\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n\n# By team\ncurl \"http://localhost:3000/api/alerts?teamId=team-123\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n\n# Multiple filters\ncurl \"http://localhost:3000/api/alerts?severity=critical&status=open&environment=production\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n#### Pagination\n\n```bash\ncurl \"http://localhost:3000/api/alerts?limit=20&offset=0\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n### Acknowledging Alerts\n\n```bash\ncurl -X POST http://localhost:3000/api/alerts/{alertId}/acknowledge \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n**Response**:\n```json\n{\n  \"id\": \"alert-123\",\n  \"status\": \"acknowledged\",\n  \"acknowledgedBy\": \"user-456\",\n  \"acknowledgedAt\": \"2025-11-18T10:30:00Z\"\n}\n```\n\n### Resolving Alerts\n\n```bash\ncurl -X POST http://localhost:3000/api/alerts/{alertId}/resolve \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resolution\": \"Increased CPU capacity by adding 2 more instances\"\n  }'\n```\n\n### Suppressing Alerts\n\nTemporarily suppress alerts (e.g., during maintenance):\n\n```bash\ncurl -X POST http://localhost:3000/api/alerts/{alertId}/suppress \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"reason\": \"Scheduled maintenance window\",\n    \"suppressUntil\": \"2025-11-18T14:00:00Z\"\n  }'\n```\n\n### Alert History\n\nView complete alert history including state changes:\n\n```bash\ncurl http://localhost:3000/api/alerts/{alertId}/history \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n---\n\n## Escalation Policies\n\nEscalation policies ensure that unacknowledged critical alerts are escalated to higher-level teams or on-call managers.\n\n### Creating an Escalation Policy\n\n```bash\ncurl -X POST http://localhost:3000/api/escalation-policies \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Platform Team Escalation\",\n    \"description\": \"Escalation policy for platform alerts\",\n    \"teamId\": \"team-platform-id\",\n    \"enabled\": true,\n    \"levels\": [\n      {\n        \"level\": 1,\n        \"timeout_minutes\": 15,\n        \"target_team_id\": \"team-platform-id\",\n        \"channels\": [\"email\", \"slack\"]\n      },\n      {\n        \"level\": 2,\n        \"timeout_minutes\": 30,\n        \"target_team_id\": \"team-senior-engineers-id\",\n        \"channels\": [\"slack\", \"pagerduty\"]\n      },\n      {\n        \"level\": 3,\n        \"timeout_minutes\": 60,\n        \"target_team_id\": \"team-leadership-id\",\n        \"channels\": [\"pagerduty\"]\n      }\n    ]\n  }'\n```\n\n### How Escalation Works\n\n1. **Alert Created**: Alert is sent to Level 1 team\n2. **Timeout Check**: System checks every 5 minutes for unacknowledged alerts\n3. **Escalation Triggered**: If alert remains unacknowledged after timeout, escalate to Level 2\n4. **Repeat**: Continue escalating through levels until alert is acknowledged or final level reached\n5. **Acknowledgment**: Escalation stops when alert is acknowledged at any level\n\n### Viewing Active Escalations\n\n```bash\ncurl http://localhost:3000/api/escalation-policies \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n---\n\n## API Usage\n\n### Authentication\n\nAll API requests require JWT authentication via the `Authorization` header.\n\n#### Register a User\n\n```bash\ncurl -X POST http://localhost:3000/api/auth/register \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"user@example.com\",\n    \"username\": \"johndoe\",\n    \"password\": \"SecurePassword123!\",\n    \"fullName\": \"John Doe\"\n  }'\n```\n\n#### Login\n\n```bash\ncurl -X POST http://localhost:3000/api/auth/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"user@example.com\",\n    \"password\": \"SecurePassword123!\"\n  }'\n```\n\n**Response**:\n```json\n{\n  \"accessToken\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"refreshToken\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"user\": {\n    \"id\": \"user-123\",\n    \"email\": \"user@example.com\",\n    \"username\": \"johndoe\",\n    \"role\": \"user\"\n  }\n}\n```\n\n#### Use Access Token\n\n```bash\ncurl http://localhost:3000/api/alerts \\\n  -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n```\n\n### API Documentation\n\nFull API documentation is available via Swagger:\n\n```\nhttp://localhost:3000/api-docs\n```\n\n---\n\n## Dashboard Guide\n\nThe web dashboard provides a user-friendly interface for managing alerts, teams, and routing rules.\n\n### Dashboard Overview\n\nThe main dashboard shows:\n\n- **Active Alerts**: Count of open, acknowledged, and resolved alerts\n- **Alert Trends**: Time-series chart of alerts by severity\n- **Team Performance**: Average response times per team\n- **Notification Delivery**: Success rate by channel\n- **Recent Alerts**: List of latest alerts with quick actions\n\n### Managing Alerts\n\n1. **View All Alerts**: Navigate to **Alerts** page\n2. **Filter**: Use severity, status, team, and date filters\n3. **Acknowledge**: Click **Acknowledge** button next to alert\n4. **Resolve**: Click **Resolve** button and add resolution notes\n5. **Details**: Click alert title to view full details\n\n### Creating Teams\n\n1. Navigate to **Teams** â†’ **Create Team**\n2. Fill in team information\n3. Add members by searching for users\n4. Configure notification preferences\n5. Save team\n\n### Creating Routing Rules\n\n1. Navigate to **Rules** â†’ **Create Rule**\n2. Enter rule name and description\n3. Set priority (higher = evaluated first)\n4. Choose match type (all, any, regex)\n5. Add conditions:\n   - Severity\n   - Source\n   - Labels\n6. Select target team\n7. Choose notification channels\n8. Test rule (optional)\n9. Enable and save\n\n### Analytics\n\nNavigate to **Analytics** to view:\n\n- **Alert Volume**: Daily/weekly/monthly alert counts\n- **Response Times**: Average time to acknowledge and resolve\n- **Team Performance**: Alerts handled per team\n- **Channel Performance**: Delivery success rates\n- **MTTR**: Mean Time To Resolution\n\n---\n\n## Best Practices\n\n### Routing Rules\n\n1. **Use Clear Naming**: Name rules descriptively (e.g., \"Production Database Critical Alerts\")\n2. **Set Appropriate Priorities**: Critical alerts should have highest priority rules\n3. **Test Before Enabling**: Always test rules with sample alerts\n4. **Avoid Overlapping Rules**: Ensure rules don't conflict (first match wins)\n5. **Default Catch-All Rule**: Create a low-priority rule that matches everything as a fallback\n\n### Alert Management\n\n1. **Acknowledge Promptly**: Acknowledge alerts within 5 minutes to prevent escalation\n2. **Add Context**: When resolving, add notes about resolution steps\n3. **Use Labels Consistently**: Standardize label keys (environment, service, region)\n4. **Set Appropriate Severity**: Reserve \"critical\" for truly critical issues\n5. **Clean Up Resolved Alerts**: Archive or delete old resolved alerts periodically\n\n### Team Organization\n\n1. **Logical Grouping**: Group users by responsibility (e.g., Database Team, API Team)\n2. **On-Call Rotation**: Maintain fair on-call rotation schedules\n3. **Multiple Teams**: Users can be members of multiple teams\n4. **Team Hierarchy**: Set up escalation chains (Level 1 â†’ Level 2 â†’ Level 3)\n\n### Notification Channels\n\n1. **Channel Selection**: Use appropriate channels based on severity\n   - **Email**: Low to medium severity\n   - **Slack**: Medium to high severity\n   - **PagerDuty**: High to critical severity\n2. **Avoid Alert Fatigue**: Don't send all alerts to all channels\n3. **Test Integrations**: Regularly test Slack and PagerDuty integrations\n4. **Monitor Delivery**: Check notification delivery success rates\n\n### Security\n\n1. **Strong Passwords**: Enforce strong password policies\n2. **JWT Secrets**: Use strong, randomly generated JWT secrets\n3. **API Keys**: Rotate API keys regularly\n4. **Rate Limiting**: Enable rate limiting to prevent abuse\n5. **HTTPS Only**: Always use HTTPS in production\n\n---\n\n## Troubleshooting\n\n### Common Issues\n\n#### Alerts Not Being Routed\n\n**Symptoms**: Alerts are created but not assigned to any team\n\n**Solutions**:\n1. Check if any routing rules are enabled\n2. Verify rule conditions match alert properties\n3. Check rule priority order\n4. Create a default catch-all rule\n\n```bash\n# Check active rules\ncurl http://localhost:3000/api/rules?enabled=true \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n#### Notifications Not Sending\n\n**Symptoms**: Alerts are routed but notifications fail\n\n**Solutions**:\n\n**Email Issues**:\n1. Verify SMTP credentials in `.env`\n2. Check firewall allows SMTP port (587/465)\n3. Review logs: `docker logs alert-router | grep email`\n\n```bash\n# Test email configuration\nnpm run test:email\n```\n\n**Slack Issues**:\n1. Verify Slack bot token is valid\n2. Check bot is invited to channels\n3. Verify bot has correct permissions\n\n```bash\n# Test Slack integration\nnpm run test:slack\n```\n\n**PagerDuty Issues**:\n1. Verify API key is valid\n2. Check service ID is correct\n3. Review PagerDuty incident creation logs\n\n#### Database Connection Errors\n\n**Symptoms**: `ECONNREFUSED` or connection timeout errors\n\n**Solutions**:\n1. Verify PostgreSQL is running: `docker ps`\n2. Check DATABASE_URL format\n3. Ensure database exists: `psql -U user -l`\n4. Run migrations: `npx prisma migrate deploy`\n\n#### Redis Connection Errors\n\n**Symptoms**: Deduplication not working, caching errors\n\n**Solutions**:\n1. Verify Redis is running: `docker ps`\n2. Check REDIS_URL format\n3. Test Redis connection: `redis-cli ping`\n\n#### High Memory Usage\n\n**Symptoms**: Application consuming excessive memory\n\n**Solutions**:\n1. Enable connection pooling\n2. Adjust Prisma connection pool size\n3. Review queue size limits\n4. Monitor for memory leaks with Clinic.js\n\n```bash\n# Profile memory usage\nnpm run profile:memory\n```\n\n### Debugging\n\nEnable debug logging:\n\n```env\nLOG_LEVEL=debug\n```\n\nView application logs:\n\n```bash\n# Docker\ndocker logs -f alert-router\n\n# Local\ntail -f logs/app.log\n```\n\nEnable Prisma query logging:\n\n```typescript\n// In instrument.ts or prisma setup\nconst prisma = new PrismaClient({\n    log: ['query', 'info', 'warn', 'error'],\n});\n```\n\n### Getting Help\n\n1. **Check Logs**: Review application logs for errors\n2. **GitHub Issues**: Search for similar issues at https://github.com/your-org/alert-router/issues\n3. **Documentation**: Review API documentation at `/api-docs`\n4. **Support**: Contact support at support@example.com\n\n---\n\n## FAQ\n\n### General Questions\n\n**Q: Can I integrate with monitoring systems like Prometheus or Grafana?**\n\nA: Yes! Configure your monitoring system to send alerts to our API endpoint:\n```\nPOST http://your-domain.com/api/alerts\n```\n\n**Q: How many alerts can the system handle?**\n\nA: The system can handle 1000+ alerts per minute with proper infrastructure (PostgreSQL, Redis, multiple workers).\n\n**Q: Is there a mobile app?**\n\nA: Not yet, but it's on the roadmap. For now, use Slack or PagerDuty mobile apps for notifications.\n\n### Routing & Notifications\n\n**Q: What happens if no routing rule matches an alert?**\n\nA: If no rule matches, the alert is created but not assigned to any team. Create a default catch-all rule to prevent this.\n\n**Q: Can I route the same alert to multiple teams?**\n\nA: Currently, each alert is routed to one team. Use escalation policies to notify additional teams after a timeout.\n\n**Q: How quickly are notifications sent?**\n\nA: Notifications are sent within 5 seconds of alert creation (target p95 performance).\n\n### Deduplication\n\n**Q: How long is the deduplication window?**\n\nA: Default is 5 minutes, configurable via `DEDUPLICATION_WINDOW_MINUTES` environment variable.\n\n**Q: What happens to duplicate alerts?**\n\nA: Duplicates increment a counter on the original alert and update the \"last seen\" timestamp.\n\n### Escalation\n\n**Q: Can I skip escalation levels?**\n\nA: No, escalation proceeds sequentially through levels. Design your policy with appropriate timeout values.\n\n**Q: What stops an escalation?**\n\nA: Acknowledging or resolving the alert stops all escalation.\n\n### Security\n\n**Q: How are API keys and passwords stored?**\n\nA: Passwords are hashed with bcrypt (12 rounds). API keys are encrypted at rest.\n\n**Q: Can I use SSO/SAML for authentication?**\n\nA: SAML/SSO support is planned for a future release.\n\n**Q: Is the system GDPR compliant?**\n\nA: Yes, audit logs can be configured to anonymize personal data.\n\n### Performance\n\n**Q: How do I scale the system for high load?**\n\nA: Run multiple application instances behind a load balancer. Use PostgreSQL read replicas and Redis cluster.\n\n**Q: What are the resource requirements?**\n\nA: Minimum: 2 CPU cores, 4GB RAM. Recommended: 4+ cores, 8GB+ RAM for production.\n\n---\n\n## Conclusion\n\nYou're now ready to use the Alert Notification Router! For more advanced topics, refer to:\n\n- [Development Plan](../plan/DevelopmentPlan.md) - Architecture and implementation details\n- [Testing Plan](../testing/TestingPlan.md) - Testing strategy and test cases\n- [API Documentation](http://localhost:3000/api-docs) - Full API reference\n\nNeed help? Contact support@example.com or open an issue on GitHub.\n\n---\n\n**Version**: 1.0.0\n**Last Updated**: November 18, 2025\n**License**: MIT\n","structuredPatch":[]}}
{"parentUuid":"1f9ba91d-a07e-4269-ace5-f2e3ecdbf13c","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01QiY2i98qD3N2kb1jct4uQg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WQ5zTorFTht4yhiTG7Xg1L","name":"TodoWrite","input":{"todos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"completed","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"completed","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"completed","activeForm":"Creating Guide.md with user documentation"}]}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":9521,"cache_read_input_tokens":65721,"cache_creation":{"ephemeral_5m_input_tokens":9521,"ephemeral_1h_input_tokens":0},"output_tokens":168,"service_tier":"standard"}},"requestId":"req_011CVFVQ4Fb2nQQwPGDB3znw","type":"assistant","uuid":"548e6f48-268c-4372-b8fe-de0bb9759a93","timestamp":"2025-11-18T14:11:37.769Z"}
{"parentUuid":"548e6f48-268c-4372-b8fe-de0bb9759a93","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WQ5zTorFTht4yhiTG7Xg1L","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"19c27021-3cec-473a-abce-1c10b4ad80a2","timestamp":"2025-11-18T14:11:38.050Z","toolUseResult":{"oldTodos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"completed","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"completed","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"in_progress","activeForm":"Creating Guide.md with user documentation"}],"newTodos":[{"content":"Create DevelopmentPlan.md with architecture and implementation details","status":"completed","activeForm":"Creating DevelopmentPlan.md with architecture and implementation details"},{"content":"Create TestingPlan.md with comprehensive test strategy","status":"completed","activeForm":"Creating TestingPlan.md with comprehensive test strategy"},{"content":"Create Guide.md with user documentation","status":"completed","activeForm":"Creating Guide.md with user documentation"}]}}
{"parentUuid":"19c27021-3cec-473a-abce-1c10b4ad80a2","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01XpNc4kM2BdCbn8vZSxAJ3G","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! I've successfully created all three comprehensive documentation files for your Alert Notification Router system:\n\n## Documentation Created\n\n### 1. **DevelopmentPlan.md** â†’ `docs/plan/DevelopmentPlan.md`\nComprehensive development plan including:\n- System architecture with layered design (Routes â†’ Controllers â†’ Services â†’ Repositories)\n- Complete tech stack (Node.js, TypeScript, Express, Prisma, PostgreSQL, Redis)\n- Detailed database schema with 9 core tables and complete Prisma schema\n- RESTful API endpoints for all features\n- 10-phase implementation plan (14 weeks total)\n- Security considerations and best practices\n- Scalability and performance guidelines\n\n### 2. **TestingPlan.md** â†’ `docs/testing/TestingPlan.md`\nComprehensive testing strategy including:\n- Testing pyramid approach (70% unit, 20% integration, 10% E2E)\n- Detailed test examples for all layers (services, repositories, controllers)\n- Integration tests for API endpoints and database operations\n- End-to-end tests for complete alert workflows\n- Performance testing with Artillery and custom scripts\n- Security testing (authentication, authorization, input validation)\n- Test environment setup with Docker Compose\n- CI/CD integration with GitHub Actions\n- 80%+ code coverage goals\n\n### 3. **Guide.md** â†’ `docs/guides/Guide.md**\nComplete user documentation including:\n- Quick start guide (5-minute setup)\n- Three installation options (local, Docker, cloud deployment)\n- Configuration guide for all notification channels (Email, Slack, PagerDuty)\n- Core concepts explanation (alerts, teams, routing rules, escalation)\n- Step-by-step guides for common tasks\n- API usage examples with curl commands\n- Dashboard navigation guide\n- Best practices for routing rules, alert management, and team organization\n- Troubleshooting section with common issues and solutions\n- Comprehensive FAQ\n\n## Key Features Covered\n\nThe system includes:\n- **Intelligent routing** with configurable rules and pattern matching\n- **Multi-channel notifications** (Email, Slack, PagerDuty)\n- **Alert deduplication** using fingerprints and Redis caching\n- **Priority handling** for critical alerts\n- **Escalation policies** with multi-level escalation\n- **Delivery tracking** with retry logic\n- **Team management** with on-call schedules\n- **Analytics dashboard** with metrics and reporting\n\nAll documentation follows best practices from the backend-dev-guidelines and frontend-dev-guidelines skills, ensuring production-quality code structure and modern development patterns."}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":211,"cache_read_input_tokens":75242,"cache_creation":{"ephemeral_5m_input_tokens":211,"ephemeral_1h_input_tokens":0},"output_tokens":591,"service_tier":"standard"}},"requestId":"req_011CVFVQgTC3hNPQpgttRFqv","type":"assistant","uuid":"05ff798f-6607-49f7-a622-fab4718f8016","timestamp":"2025-11-18T14:11:54.581Z"}
{"parentUuid":"05ff798f-6607-49f7-a622-fab4718f8016","isSidechain":false,"userType":"external","cwd":"/root/Claude/claude-hooks","sessionId":"53188aba-ad34-4f11-9df7-8031d427bc6f","version":"2.0.44","gitBranch":"","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"git me"}],"hookErrors":["Failed with non-blocking status code: fatal: not in a git directory"],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2025-11-18T14:11:54.783Z","uuid":"0696dad3-11ce-488a-b926-c7a7224f2fb2","toolUseID":"fa60c030-6ade-4618-ae8f-c0406bc44f17"}
